{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Grizzly - /\u02c8\u0261\u0279\u026azli/ Framework: Command Line Interface: Grizzly is a framework to be able to easily define load scenarios, and is mainly built on-top of two other frameworks: Locust : Define user behaviour with Python code, and swarm your system with millions of simultaneous users. Behave : Uses tests written in a natural language style, backed up by Python code. Locust are a group of certain species of short-horned grasshoppers in the family Arcididae that have a swarming phase. The name grizzly was chosen based on the grasshopper Melanoplus punctulatus , also known as grizzly spur-throat grasshopper. This species prefers living in trees over grass, which is a hint to Biometria 1 , where grizzly originally was created. 1 Biometria is a member owned and central actor within the swedish forestry that performs unbiased measurement of lumber flowing between forest and industry so that all of Swedens forest owners can feel confident selling their lumber. Documentation More detailed documentation can be found here and the easiest way to get started is to check out the example . Description behave is ab used for being able to define locust load test scenarios using gherkin . A feature can contain more than one scenario and all scenarios will run in parallell. Feature: Rest API endpoint testing Background: Common properties for all scenarios Given \" 2 \" users And spawn rate is \" 2 \" user per second And stop on first failure Scenario: Authorize Given a user of type \" RestApi \" sending requests to \" https://api.example.com \" And repeat for \" 2 \" iterations And wait time inbetween requests is random between \" 0.1 \" and \" 0.3 \" seconds And value for variable \" AtomicDate.called \" is \" now | format='%Y-%m-%dT%H:%M:%S.00Z', timezone=UTC \" And value for variable \" callback_endpoint \" is \" none \" Then post request with name \" authorize \" from endpoint \" /api/v1/authorize?called={{ AtomicDate.called }} | content_type=json \" \"\"\" { \"username\": \"test\", \"password\": \"password123\", \"callback\": \"/api/v1/user/test\" } \"\"\" Then save response payload \" $.callback \" in variable \" callback_endpoint \" Then get request with name \" user info \" from endpoint \" {{ callback_endpoint }} | content_type=json \" When response payload \" $.user.name \" is not \" Test User \" stop user This makes it possible to implement load test scenarios without knowing python or how to use locust . Features A number of features that we thought locust was missing out-of-the-box has been implemented in grizzly . Test data Support for synchronous handling of test data (variables). This is extra important when running locust distributed and there is a need for each worker and user to have unique test data, that cannot be re-used. The solution is heavily inspired by Karol Brejnas locust experiments - feeding the locust . A producer is running on the master (or local) node and keeps track of what has been sent to the consumer running on a worker (or local) node. The two communicates over a seperate ZeroMQ session. When the consumer wants new test data, it sends a message to the server that it is available and for which scenario it is going to run. The producer then responds with unique test data that can be used. Statistics Listeners for both InfluxDB and Azure Application Insights are included. The later is more or less appinsights_listener.py , from the good guys at Svenska Spel , but with typing. They are useful when history of test runs is needed, or when wanting to correlate load tests with other events in the targeted environment. Load test users locust comes with a simple user for loading an HTTP(S) endpoint and due to the nature of how the integration between behave and locust works, it is not possible to use locust provided users, even for HTTP(S) targets. RestApiUser : send requests to REST API endpoinds, supports authentication with username+password or client secret ServiceBusUser : send to and receive from Azure Service Bus queues and topics MessageQueueUser : send and receive from IBM MQ queues SftpUser : send and receive files from an SFTP-server BlobStorageUser : send files to Azure Blob Storage 2 2 A pull request for functionality in the other direction is appreciated! Request log All failed requests are logged to a file which includes both header and body, both for request and response. Installation pip3 install grizzly-loadtester pip3 install grizzly-loadtester-cli Do not forget to try the example which also serves as a boilerplate scenario project. Development The easiest way to start contributing to this project is to have Visual Studio Code (with \"Remote - Containers\" extension) and docker installed. The project comes with a devcontainer , which encapsulates everything needed for a development environment. It is also possible to use a python virtual environment where requirements.txt and requirements-dev.txt is installed, and also preferbly the IBM MQ client dependencies and requirements-extras.txt .","title":"Home"},{"location":"#grizzly-zli","text":"Framework: Command Line Interface: Grizzly is a framework to be able to easily define load scenarios, and is mainly built on-top of two other frameworks: Locust : Define user behaviour with Python code, and swarm your system with millions of simultaneous users. Behave : Uses tests written in a natural language style, backed up by Python code. Locust are a group of certain species of short-horned grasshoppers in the family Arcididae that have a swarming phase. The name grizzly was chosen based on the grasshopper Melanoplus punctulatus , also known as grizzly spur-throat grasshopper. This species prefers living in trees over grass, which is a hint to Biometria 1 , where grizzly originally was created. 1 Biometria is a member owned and central actor within the swedish forestry that performs unbiased measurement of lumber flowing between forest and industry so that all of Swedens forest owners can feel confident selling their lumber.","title":"Grizzly - /\u02c8\u0261\u0279\u026azli/"},{"location":"#documentation","text":"More detailed documentation can be found here and the easiest way to get started is to check out the example .","title":"Documentation"},{"location":"#description","text":"behave is ab used for being able to define locust load test scenarios using gherkin . A feature can contain more than one scenario and all scenarios will run in parallell. Feature: Rest API endpoint testing Background: Common properties for all scenarios Given \" 2 \" users And spawn rate is \" 2 \" user per second And stop on first failure Scenario: Authorize Given a user of type \" RestApi \" sending requests to \" https://api.example.com \" And repeat for \" 2 \" iterations And wait time inbetween requests is random between \" 0.1 \" and \" 0.3 \" seconds And value for variable \" AtomicDate.called \" is \" now | format='%Y-%m-%dT%H:%M:%S.00Z', timezone=UTC \" And value for variable \" callback_endpoint \" is \" none \" Then post request with name \" authorize \" from endpoint \" /api/v1/authorize?called={{ AtomicDate.called }} | content_type=json \" \"\"\" { \"username\": \"test\", \"password\": \"password123\", \"callback\": \"/api/v1/user/test\" } \"\"\" Then save response payload \" $.callback \" in variable \" callback_endpoint \" Then get request with name \" user info \" from endpoint \" {{ callback_endpoint }} | content_type=json \" When response payload \" $.user.name \" is not \" Test User \" stop user This makes it possible to implement load test scenarios without knowing python or how to use locust .","title":"Description"},{"location":"#features","text":"A number of features that we thought locust was missing out-of-the-box has been implemented in grizzly .","title":"Features"},{"location":"#test-data","text":"Support for synchronous handling of test data (variables). This is extra important when running locust distributed and there is a need for each worker and user to have unique test data, that cannot be re-used. The solution is heavily inspired by Karol Brejnas locust experiments - feeding the locust . A producer is running on the master (or local) node and keeps track of what has been sent to the consumer running on a worker (or local) node. The two communicates over a seperate ZeroMQ session. When the consumer wants new test data, it sends a message to the server that it is available and for which scenario it is going to run. The producer then responds with unique test data that can be used.","title":"Test data"},{"location":"#statistics","text":"Listeners for both InfluxDB and Azure Application Insights are included. The later is more or less appinsights_listener.py , from the good guys at Svenska Spel , but with typing. They are useful when history of test runs is needed, or when wanting to correlate load tests with other events in the targeted environment.","title":"Statistics"},{"location":"#load-test-users","text":"locust comes with a simple user for loading an HTTP(S) endpoint and due to the nature of how the integration between behave and locust works, it is not possible to use locust provided users, even for HTTP(S) targets. RestApiUser : send requests to REST API endpoinds, supports authentication with username+password or client secret ServiceBusUser : send to and receive from Azure Service Bus queues and topics MessageQueueUser : send and receive from IBM MQ queues SftpUser : send and receive files from an SFTP-server BlobStorageUser : send files to Azure Blob Storage 2 2 A pull request for functionality in the other direction is appreciated!","title":"Load test users"},{"location":"#request-log","text":"All failed requests are logged to a file which includes both header and body, both for request and response.","title":"Request log"},{"location":"#installation","text":"pip3 install grizzly-loadtester pip3 install grizzly-loadtester-cli Do not forget to try the example which also serves as a boilerplate scenario project.","title":"Installation"},{"location":"#development","text":"The easiest way to start contributing to this project is to have Visual Studio Code (with \"Remote - Containers\" extension) and docker installed. The project comes with a devcontainer , which encapsulates everything needed for a development environment. It is also possible to use a python virtual environment where requirements.txt and requirements-dev.txt is installed, and also preferbly the IBM MQ client dependencies and requirements-extras.txt .","title":"Development"},{"location":"example/","text":"Example The directory example/ is an working project that sends requests to public REST API endpoints, please do not abuse these . Structure The project must have the follwoing structure: . \u2514\u2500\u2500 features \u251c\u2500\u2500 environment.py \u251c\u2500\u2500 test.feature \u251c\u2500\u2500 requests \u2502 \u2514\u2500\u2500 ... \u2514\u2500\u2500 steps \u2514\u2500\u2500 steps.py In this example there are two requirements*.txt files. The reason is that requirements.txt will be copied and installed in the container image if grizzly-cli is used. The container image should not contain grizzly-cli and should be installed where scenarios are started from. After installing grizzly-cli the easiest way to get a correct project structure is to use the builtin init subcommand: grizzly-cli init my-grizzly-project cd my-grizzly-project/ Environment features/environment.py should contain: from grizzly.environment import * This file can contain overloading of behave hooks to trigger events that should happen during different stages of running a feature file. from grizzly.environment import before_feature as grizzly_before_feature , after_feature as grizzly_after_feature , before_scenario , after_scenario , before_step def before_feature ( context : Context , * args : Tuple [ Any , ... ], ** kwargs : Dict [ str , Any ]) -> None : # custom code that should run before feature file is started, e.g. notify something that a test # is started grizzly_before_feature ( context , * args , ** kwargs ) def after_feature ( context : Context , feature : Feature , * args : Tuple [ Any , ... ], ** kwargs : Dict [ str , Any ]) -> None : grizzly_after_feature ( context , feature , * args , ** kwargs ) # custom code that should run before feature file is started, e.g. notify something that a test # is finished Steps features/steps/steps.py should contain: from grizzly.steps import * This is where custom step implementation can be added, then should look something like: from behave.runner import Context from behave import then # pylint: disable=no-name-in-module from grizzly.steps import * from grizzly.context import GrizzlyContext @then ( u 'this custom step should be executed' ) def step_custom_the_custom_step ( context : Context ) -> None : grizzly = cast ( GrizzlyContext , context . grizzly ) # custom step implementation Request templates features/requests can contain jinja2 templates used in requests. E.g., if the feature file contains the following step: Then send request \" payload.j2.json \" Then features/requests/payload.j2.json needs to exist. Get First do a sparse checkout of the example/ directory in the repository. If you have git older than 2.25.0 , follow these instructions on stackoverflow.com . Bash PowerShell mkdir grizzly-example cd grizzly-example git init git remote add -f origin https://github.com/Biometria-se/grizzly.git git sparse-checkout init git sparse-checkout set example/ git pull origin main rm -rf .git/ cd example/ mkdir grizzly-example cd .\\ grizzly-example \\ git init git remote add -f origin https :// github . com / Biometria-se / grizzly . git git sparse-checkout init git sparse-checkout set example / git pull origin main rm -Recurse -Force .\\. git \\ cd .\\ example \\ Create an python virtual environment and install dependencies: Bash PowerShell python3 -m venv .env source .env/bin/activate pip3 install -r requirements.txt pip3 install grizzly-loadtester-cli python3 -m venv . env .\\. env \\ Scripts \\ activate pip3 install -r .\\ requirements . txt pip3 install grizzly-loadtester-cli If you do not already have an working \"IBM MQ\" client setup and run grizzly-cli in local mode you will not be able to use MessageQueueUser . See grizzly-cli/static/Containerfile on how to get these. When that is done you need to install the extra dependencies: pip3 install grizzly-loadtester [ mq ] Run grizzly has some runtime features which is easiliest handled by using the grizzly-cli . It provides a simple command line interface wrapping the behave command, for providing initial variable values, configuration etc. To run the example, in local mode: Bash PowerShell grizzly-cli run -e environments/example.yaml local features/example.feature grizzly-cli run -e .\\ environments \\ example . yaml local .\\ features \\ example . feature And in distributed mode (requires docker and docker-compose in PATH ): Bash PowerShell grizzly-cli run -e environments/example.yaml dist features/example.feature grizzly-cli run -e .\\ environments \\ example . yaml dist .\\ features \\ example . feature","title":"Example"},{"location":"example/#example","text":"The directory example/ is an working project that sends requests to public REST API endpoints, please do not abuse these .","title":"Example"},{"location":"example/#structure","text":"The project must have the follwoing structure: . \u2514\u2500\u2500 features \u251c\u2500\u2500 environment.py \u251c\u2500\u2500 test.feature \u251c\u2500\u2500 requests \u2502 \u2514\u2500\u2500 ... \u2514\u2500\u2500 steps \u2514\u2500\u2500 steps.py In this example there are two requirements*.txt files. The reason is that requirements.txt will be copied and installed in the container image if grizzly-cli is used. The container image should not contain grizzly-cli and should be installed where scenarios are started from. After installing grizzly-cli the easiest way to get a correct project structure is to use the builtin init subcommand: grizzly-cli init my-grizzly-project cd my-grizzly-project/","title":"Structure"},{"location":"example/#environment","text":"features/environment.py should contain: from grizzly.environment import * This file can contain overloading of behave hooks to trigger events that should happen during different stages of running a feature file. from grizzly.environment import before_feature as grizzly_before_feature , after_feature as grizzly_after_feature , before_scenario , after_scenario , before_step def before_feature ( context : Context , * args : Tuple [ Any , ... ], ** kwargs : Dict [ str , Any ]) -> None : # custom code that should run before feature file is started, e.g. notify something that a test # is started grizzly_before_feature ( context , * args , ** kwargs ) def after_feature ( context : Context , feature : Feature , * args : Tuple [ Any , ... ], ** kwargs : Dict [ str , Any ]) -> None : grizzly_after_feature ( context , feature , * args , ** kwargs ) # custom code that should run before feature file is started, e.g. notify something that a test # is finished","title":"Environment"},{"location":"example/#steps","text":"features/steps/steps.py should contain: from grizzly.steps import * This is where custom step implementation can be added, then should look something like: from behave.runner import Context from behave import then # pylint: disable=no-name-in-module from grizzly.steps import * from grizzly.context import GrizzlyContext @then ( u 'this custom step should be executed' ) def step_custom_the_custom_step ( context : Context ) -> None : grizzly = cast ( GrizzlyContext , context . grizzly ) # custom step implementation","title":"Steps"},{"location":"example/#request-templates","text":"features/requests can contain jinja2 templates used in requests. E.g., if the feature file contains the following step: Then send request \" payload.j2.json \" Then features/requests/payload.j2.json needs to exist.","title":"Request templates"},{"location":"example/#get","text":"First do a sparse checkout of the example/ directory in the repository. If you have git older than 2.25.0 , follow these instructions on stackoverflow.com . Bash PowerShell mkdir grizzly-example cd grizzly-example git init git remote add -f origin https://github.com/Biometria-se/grizzly.git git sparse-checkout init git sparse-checkout set example/ git pull origin main rm -rf .git/ cd example/ mkdir grizzly-example cd .\\ grizzly-example \\ git init git remote add -f origin https :// github . com / Biometria-se / grizzly . git git sparse-checkout init git sparse-checkout set example / git pull origin main rm -Recurse -Force .\\. git \\ cd .\\ example \\ Create an python virtual environment and install dependencies: Bash PowerShell python3 -m venv .env source .env/bin/activate pip3 install -r requirements.txt pip3 install grizzly-loadtester-cli python3 -m venv . env .\\. env \\ Scripts \\ activate pip3 install -r .\\ requirements . txt pip3 install grizzly-loadtester-cli If you do not already have an working \"IBM MQ\" client setup and run grizzly-cli in local mode you will not be able to use MessageQueueUser . See grizzly-cli/static/Containerfile on how to get these. When that is done you need to install the extra dependencies: pip3 install grizzly-loadtester [ mq ]","title":"Get"},{"location":"example/#run","text":"grizzly has some runtime features which is easiliest handled by using the grizzly-cli . It provides a simple command line interface wrapping the behave command, for providing initial variable values, configuration etc. To run the example, in local mode: Bash PowerShell grizzly-cli run -e environments/example.yaml local features/example.feature grizzly-cli run -e .\\ environments \\ example . yaml local .\\ features \\ example . feature And in distributed mode (requires docker and docker-compose in PATH ): Bash PowerShell grizzly-cli run -e environments/example.yaml dist features/example.feature grizzly-cli run -e .\\ environments \\ example . yaml dist .\\ features \\ example . feature","title":"Run"},{"location":"command-line-interface/changelog/","text":"Changelog v3.0.2 bb270a82 : changed grizzly_cli.SCENARIOS to a list to get guaranteed insertion order (#42) v3.0.1 df5a4902 : --yes argument to automagically answer yes on any questions 0b57d739 : subcommand is not set for command init 43ccba6b : do not sort scenarios by name, iterate in the order they are defined dd4b5e7b : adaptations for Biometria-se/grizzly#71 v3.0.0 267ee8df : restructuring commands c1170417 : step expression for number of users can be singular (#37) v2.1.6 803b3f3a : users per scenario is calculated incorrectly (#36) 065b1e5c : documentation of IBM_MQ_LIB_HOST environment variable (#35) e73174b2 : make sure that it is possible to generate licenses documentation (#34) a574b5c4 : github action action-push-tag@v1 is broken (#33) v2.1.5 e3eb9073 : no smoothed timeline in test summary 2d706e0f : --add-host if overridden IBM_MQ_LIB_HOST is using host.docker.internal (#31) v2.1.4 220924f6 : fix failing tests 45fc7718 : possible to override host where IBM MQ lib redist package should be downloaded from d34ebbf8 : script for generating a license summary (#29) v2.1.3 49116c42 : check if container image should be built with or without mq libraries 50ec4869 : check if grizzly-loadtester is installed with any extras 447f677e : Containerfile updated to have MQ libraries as optional 64b2131a : unable to use cache functionality of setup-python@v2 241bdb22 : fix for Biometria-se/grizzly#73 340cfd18 : only run code quality workflow on 3.10 on windows e11c1b09 : docker-compose v2 and v1 compatible in instructions 1db75e0b : base on 3.10-slim instead of alpine a7dc5ce6 : add --no-tty argument to run dist 8d3d83ee : more dynamic creation of sub command parsers 03652ae8 : build package based on metadata only v2.1.2 344bc53b : remove debug prints that fell through quality control v2.1.1 d41cde5c : added missing dependency (#24) v2.1.0 4feb4ec5 : build grizzly container image based on locust container image version that the project depends on 4e3ec441 : implementation of getting dependencies version 4ffc4535 : WIP: get grizzly and locust version from project 64b5eaef : Feature/spring 2022 cleanup (#22) v2.0.4 c9c0c24b : fix tty size in container (#20) v2.0.3 234e9c05 : getattr retrives value of registry in args, but if it is None (#19) v2.0.2 37da0e73 : Feature/build parser (#18) 7c64bd0b : added arguments for controlling compose health checks (#17) v2.0.1 83b08112 : build broken for 2.0.0 (#16) v2.0.0 d624baa7 : Feature/run windows 57 (#15) f20dccfa : too greedy gitignore rule resulted in missing new workflow (#14) 724bd70e : Feature/argument refactor (#13) 97ab0e45 : refreshed devcontainer (#12) v1.1.1 ae46c7a6 : do not expose locust webui port (8089) in compose file (#11) v1.1.0 9be8b64b : Feature/validate iterations prompt (#10) v1.0.9 2cd470ae : remove locust user (uid 1000) when building grizzly container image (#9) v1.0.8 cca24c6b : create a user with uid/gid matching user that executes grizzly-cli (#8) v1.0.7 4bee4c7b : get IBM MQ client logs when running distributed (#7) v1.0.6 746d7219 : expose internal environment variables in execution context (#6) v1.0.5 824f163d : lock locust image version to version of locust used by grizzly v1.0.4 f8fd5c9d : ask for value expression can have more than one keyword (#5) v1.0.3 c0eacc1a : set MTU in docker-compose network to the same value as the default bridge has 964e6993 : updated pylint configuration v1.0.2 0d5ec1ba : also get tags ffd52159 : change development version to 0.0.0 v1.0.1 7fc1fa1b : set ulimit nofile to min recommended value for locust","title":"Changelog"},{"location":"command-line-interface/changelog/#changelog","text":"","title":"Changelog"},{"location":"command-line-interface/changelog/#v302","text":"bb270a82 : changed grizzly_cli.SCENARIOS to a list to get guaranteed insertion order (#42)","title":"v3.0.2"},{"location":"command-line-interface/changelog/#v301","text":"df5a4902 : --yes argument to automagically answer yes on any questions 0b57d739 : subcommand is not set for command init 43ccba6b : do not sort scenarios by name, iterate in the order they are defined dd4b5e7b : adaptations for Biometria-se/grizzly#71","title":"v3.0.1"},{"location":"command-line-interface/changelog/#v300","text":"267ee8df : restructuring commands c1170417 : step expression for number of users can be singular (#37)","title":"v3.0.0"},{"location":"command-line-interface/changelog/#v216","text":"803b3f3a : users per scenario is calculated incorrectly (#36) 065b1e5c : documentation of IBM_MQ_LIB_HOST environment variable (#35) e73174b2 : make sure that it is possible to generate licenses documentation (#34) a574b5c4 : github action action-push-tag@v1 is broken (#33)","title":"v2.1.6"},{"location":"command-line-interface/changelog/#v215","text":"e3eb9073 : no smoothed timeline in test summary 2d706e0f : --add-host if overridden IBM_MQ_LIB_HOST is using host.docker.internal (#31)","title":"v2.1.5"},{"location":"command-line-interface/changelog/#v214","text":"220924f6 : fix failing tests 45fc7718 : possible to override host where IBM MQ lib redist package should be downloaded from d34ebbf8 : script for generating a license summary (#29)","title":"v2.1.4"},{"location":"command-line-interface/changelog/#v213","text":"49116c42 : check if container image should be built with or without mq libraries 50ec4869 : check if grizzly-loadtester is installed with any extras 447f677e : Containerfile updated to have MQ libraries as optional 64b2131a : unable to use cache functionality of setup-python@v2 241bdb22 : fix for Biometria-se/grizzly#73 340cfd18 : only run code quality workflow on 3.10 on windows e11c1b09 : docker-compose v2 and v1 compatible in instructions 1db75e0b : base on 3.10-slim instead of alpine a7dc5ce6 : add --no-tty argument to run dist 8d3d83ee : more dynamic creation of sub command parsers 03652ae8 : build package based on metadata only","title":"v2.1.3"},{"location":"command-line-interface/changelog/#v212","text":"344bc53b : remove debug prints that fell through quality control","title":"v2.1.2"},{"location":"command-line-interface/changelog/#v211","text":"d41cde5c : added missing dependency (#24)","title":"v2.1.1"},{"location":"command-line-interface/changelog/#v210","text":"4feb4ec5 : build grizzly container image based on locust container image version that the project depends on 4e3ec441 : implementation of getting dependencies version 4ffc4535 : WIP: get grizzly and locust version from project 64b5eaef : Feature/spring 2022 cleanup (#22)","title":"v2.1.0"},{"location":"command-line-interface/changelog/#v204","text":"c9c0c24b : fix tty size in container (#20)","title":"v2.0.4"},{"location":"command-line-interface/changelog/#v203","text":"234e9c05 : getattr retrives value of registry in args, but if it is None (#19)","title":"v2.0.3"},{"location":"command-line-interface/changelog/#v202","text":"37da0e73 : Feature/build parser (#18) 7c64bd0b : added arguments for controlling compose health checks (#17)","title":"v2.0.2"},{"location":"command-line-interface/changelog/#v201","text":"83b08112 : build broken for 2.0.0 (#16)","title":"v2.0.1"},{"location":"command-line-interface/changelog/#v200","text":"d624baa7 : Feature/run windows 57 (#15) f20dccfa : too greedy gitignore rule resulted in missing new workflow (#14) 724bd70e : Feature/argument refactor (#13) 97ab0e45 : refreshed devcontainer (#12)","title":"v2.0.0"},{"location":"command-line-interface/changelog/#v111","text":"ae46c7a6 : do not expose locust webui port (8089) in compose file (#11)","title":"v1.1.1"},{"location":"command-line-interface/changelog/#v110","text":"9be8b64b : Feature/validate iterations prompt (#10)","title":"v1.1.0"},{"location":"command-line-interface/changelog/#v109","text":"2cd470ae : remove locust user (uid 1000) when building grizzly container image (#9)","title":"v1.0.9"},{"location":"command-line-interface/changelog/#v108","text":"cca24c6b : create a user with uid/gid matching user that executes grizzly-cli (#8)","title":"v1.0.8"},{"location":"command-line-interface/changelog/#v107","text":"4bee4c7b : get IBM MQ client logs when running distributed (#7)","title":"v1.0.7"},{"location":"command-line-interface/changelog/#v106","text":"746d7219 : expose internal environment variables in execution context (#6)","title":"v1.0.6"},{"location":"command-line-interface/changelog/#v105","text":"824f163d : lock locust image version to version of locust used by grizzly","title":"v1.0.5"},{"location":"command-line-interface/changelog/#v104","text":"f8fd5c9d : ask for value expression can have more than one keyword (#5)","title":"v1.0.4"},{"location":"command-line-interface/changelog/#v103","text":"c0eacc1a : set MTU in docker-compose network to the same value as the default bridge has 964e6993 : updated pylint configuration","title":"v1.0.3"},{"location":"command-line-interface/changelog/#v102","text":"0d5ec1ba : also get tags ffd52159 : change development version to 0.0.0","title":"v1.0.2"},{"location":"command-line-interface/changelog/#v101","text":"7fc1fa1b : set ulimit nofile to min recommended value for locust","title":"v1.0.1"},{"location":"command-line-interface/licenses/","text":"Licenses The MIT License (MIT) Copyright \u00a9 2021 Biometria Ekonomiska F\u00f6rening Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \u201cSoftware\u201d), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \u201cAS IS\u201d, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Third party licenses Python dependencies Name Version License coverage 6.4 Apache Software License requests 2.27.1 Apache Software License requests-mock 1.9.3 Apache Software License types-requests 2.27.29 Apache Software License types-urllib3 1.26.15 Apache Software License packaging 21.3 Apache Software License; BSD License python-dateutil 2.8.2 Apache Software License; BSD License Jinja2 3.1.2 BSD License MarkupSafe 2.1.1 BSD License behave 1.2.6 BSD License dill 0.3.5.1 BSD License idna 3.3 BSD License lazy-object-proxy 1.7.1 BSD License parse 1.19.0 BSD License parse-type 0.6.0 BSD License wrapt 1.14.1 BSD License pytest-timeout 2.1.0 DFSG approved; MIT License pylint 2.13.9 GNU General Public License v2 (GPLv2) astroid 2.11.5 GNU Lesser General Public License v2 (LGPLv2) chardet 4.0.0 GNU Library or Lesser General Public License (LGPL) DataProperty 0.55.0 MIT License atomicwrites 1.4.0 MIT License attrs 21.4.0 MIT License charset-normalizer 2.0.12 MIT License flake8 4.0.1 MIT License iniconfig 1.1.1 MIT License isort 5.10.1 MIT License mbstrdecoder 1.1.0 MIT License mccabe 0.6.1 MIT License mypy 0.960 MIT License mypy-extensions 0.4.3 MIT License pathvalidate 2.5.0 MIT License platformdirs 2.5.2 MIT License pluggy 1.0.0 MIT License py 1.11.0 MIT License pycodestyle 2.8.0 MIT License pyflakes 2.4.0 MIT License pyparsing 3.0.9 MIT License pytablewriter 0.64.2 MIT License pytest 7.1.2 MIT License pytest-cov 3.0.0 MIT License pytest-mock 3.7.0 MIT License pytz 2022.1 MIT License six 1.16.0 MIT License tabledata 1.3.0 MIT License tcolorpy 0.1.2 MIT License tomli 2.0.1 MIT License typepy 1.3.0 MIT License urllib3 1.26.9 MIT License certifi 2022.5.18.1 Mozilla Public License 2.0 (MPL 2.0)","title":"Licenses"},{"location":"command-line-interface/licenses/#licenses","text":"","title":"Licenses"},{"location":"command-line-interface/licenses/#the-mit-license-mit","text":"Copyright \u00a9 2021 Biometria Ekonomiska F\u00f6rening Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \u201cSoftware\u201d), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \u201cAS IS\u201d, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"The MIT License (MIT)"},{"location":"command-line-interface/licenses/#third-party-licenses","text":"","title":"Third party licenses"},{"location":"command-line-interface/licenses/#python-dependencies","text":"Name Version License coverage 6.4 Apache Software License requests 2.27.1 Apache Software License requests-mock 1.9.3 Apache Software License types-requests 2.27.29 Apache Software License types-urllib3 1.26.15 Apache Software License packaging 21.3 Apache Software License; BSD License python-dateutil 2.8.2 Apache Software License; BSD License Jinja2 3.1.2 BSD License MarkupSafe 2.1.1 BSD License behave 1.2.6 BSD License dill 0.3.5.1 BSD License idna 3.3 BSD License lazy-object-proxy 1.7.1 BSD License parse 1.19.0 BSD License parse-type 0.6.0 BSD License wrapt 1.14.1 BSD License pytest-timeout 2.1.0 DFSG approved; MIT License pylint 2.13.9 GNU General Public License v2 (GPLv2) astroid 2.11.5 GNU Lesser General Public License v2 (LGPLv2) chardet 4.0.0 GNU Library or Lesser General Public License (LGPL) DataProperty 0.55.0 MIT License atomicwrites 1.4.0 MIT License attrs 21.4.0 MIT License charset-normalizer 2.0.12 MIT License flake8 4.0.1 MIT License iniconfig 1.1.1 MIT License isort 5.10.1 MIT License mbstrdecoder 1.1.0 MIT License mccabe 0.6.1 MIT License mypy 0.960 MIT License mypy-extensions 0.4.3 MIT License pathvalidate 2.5.0 MIT License platformdirs 2.5.2 MIT License pluggy 1.0.0 MIT License py 1.11.0 MIT License pycodestyle 2.8.0 MIT License pyflakes 2.4.0 MIT License pyparsing 3.0.9 MIT License pytablewriter 0.64.2 MIT License pytest 7.1.2 MIT License pytest-cov 3.0.0 MIT License pytest-mock 3.7.0 MIT License pytz 2022.1 MIT License six 1.16.0 MIT License tabledata 1.3.0 MIT License tcolorpy 0.1.2 MIT License tomli 2.0.1 MIT License typepy 1.3.0 MIT License urllib3 1.26.9 MIT License certifi 2022.5.18.1 Mozilla Public License 2.0 (MPL 2.0)","title":"Python dependencies"},{"location":"command-line-interface/usage/","text":"grizzly-cli The command line interface for grizzly, which makes it easer to start a test with all features of grizzly wrapped up nicely. Installing it is a matter of: pip install grizzly-loadtester-cli Enable bash completion by adding the following to your shell profile: eval \" $( grizzly-cli --bash-completion ) \" Usage grizzly-cli [ -h ] [ --version [{ all }]] { init,local,dist } ... Positional arguments argument default help command Optional arguments argument default help --version print version of command line interface, and exit. add argument all to get versions of dependencies grizzly-cli init Create a skeleton project with required structure and files. Usage grizzly-cli init [ -h ] [ --grizzly-version GRIZZLY_VERSION ] [ --with-mq ] [ -y ] project Positional arguments argument default help project project name, a directory will be created with this name Optional arguments argument default help --grizzly-version specify which grizzly version to use for project, default is latest --with-mq False if grizzly should be installed with IBM MQ support (external dependencies excluded) -y, --yes False automagically answer yes on any questions grizzly-cli local Commands for running grizzly in local mode. Usage grizzly-cli local [ -h ] { run } ... Positional arguments argument default help subcommand grizzly-cli local run Execute load test scenarios specified in a feature file. Usage grizzly-cli local run [ -h ] [ --verbose ] [ -T TESTDATA_VARIABLE ] [ -y ] [ -e ENVIRONMENT_FILE ] file Positional arguments argument default help file path to feature file with one or more scenarios Optional arguments argument default help --verbose False changes the log level to DEBUG , regardless of what it says in the feature file. gives more verbose logging that can be useful when troubleshooting a problem with a scenario. -T, --testdata-variable specified in the format <name>=<value> . avoids being asked for an initial value for a scenario variable. -y, --yes False answer yes on any questions that would require confirmation -e, --environment-file configuration file with environment specific information grizzly-cli dist Commands for running grizzly i distributed mode. Usage grizzly-cli dist [ -h ] [ --workers WORKERS ] [ --id ID ] [ --limit-nofile LIMIT_NOFILE ] [ --health-retries HEALTH_RETRIES ] [ --health-timeout HEALTH_TIMEOUT ] [ --health-interval HEALTH_INTERVAL ] [ --registry REGISTRY ] [ --tty ] [ --force-build | --build | --validate-config ] { build,run } ... Positional arguments argument default help subcommand Optional arguments argument default help --workers 1 how many instances of the workers container that should be created --id unique identifier suffixed to compose project, should be used when the same user needs to run more than one instance of grizzly-cli --limit-nofile 10001 set system limit \"number of open files\" --health-retries 3 set number of retries for health check of master container --health-timeout 3 set timeout in seconds for health check of master container --health-interval 5 set interval in seconds between health checks of master container --registry push built image to this registry, if the registry has authentication you need to login first --tty False start containers with a TTY enabled --force-build False force rebuild the grizzly projects container image (no cache) --build False rebuild the grizzly projects container images (with cache) --validate-config False validate and print compose project file grizzly-cli dist build Build grizzly compose project container image before running test. If worker nodes runs on different physical computers, it is mandatory to build the images before hand and push to a registry. If image includes IBM MQ native dependencies, the build time increases due to download times. It is possible to self-host the archive and override the download host with environment variable IBM_MQ_LIB_HOST . Usage grizzly-cli dist build [ -h ] [ --no-cache ] [ --registry REGISTRY ] Optional arguments argument default help --no-cache False build container image with out cache (full build) --registry push built image to this registry, if the registry has authentication you need to login first grizzly-cli dist run Execute load test scenarios specified in a feature file. Usage grizzly-cli dist run [ -h ] [ --verbose ] [ -T TESTDATA_VARIABLE ] [ -y ] [ -e ENVIRONMENT_FILE ] file Positional arguments argument default help file path to feature file with one or more scenarios Optional arguments argument default help --verbose False changes the log level to DEBUG , regardless of what it says in the feature file. gives more verbose logging that can be useful when troubleshooting a problem with a scenario. -T, --testdata-variable specified in the format <name>=<value> . avoids being asked for an initial value for a scenario variable. -y, --yes False answer yes on any questions that would require confirmation -e, --environment-file configuration file with environment specific information","title":"Usage"},{"location":"command-line-interface/usage/#grizzly-cli","text":"The command line interface for grizzly, which makes it easer to start a test with all features of grizzly wrapped up nicely. Installing it is a matter of: pip install grizzly-loadtester-cli Enable bash completion by adding the following to your shell profile: eval \" $( grizzly-cli --bash-completion ) \"","title":"grizzly-cli"},{"location":"command-line-interface/usage/#usage","text":"grizzly-cli [ -h ] [ --version [{ all }]] { init,local,dist } ...","title":"Usage"},{"location":"command-line-interface/usage/#positional-arguments","text":"argument default help command","title":"Positional arguments"},{"location":"command-line-interface/usage/#optional-arguments","text":"argument default help --version print version of command line interface, and exit. add argument all to get versions of dependencies","title":"Optional arguments"},{"location":"command-line-interface/usage/#grizzly-cli-init","text":"Create a skeleton project with required structure and files.","title":"grizzly-cli init"},{"location":"command-line-interface/usage/#usage_1","text":"grizzly-cli init [ -h ] [ --grizzly-version GRIZZLY_VERSION ] [ --with-mq ] [ -y ] project","title":"Usage"},{"location":"command-line-interface/usage/#positional-arguments_1","text":"argument default help project project name, a directory will be created with this name","title":"Positional arguments"},{"location":"command-line-interface/usage/#optional-arguments_1","text":"argument default help --grizzly-version specify which grizzly version to use for project, default is latest --with-mq False if grizzly should be installed with IBM MQ support (external dependencies excluded) -y, --yes False automagically answer yes on any questions","title":"Optional arguments"},{"location":"command-line-interface/usage/#grizzly-cli-local","text":"Commands for running grizzly in local mode.","title":"grizzly-cli local"},{"location":"command-line-interface/usage/#usage_2","text":"grizzly-cli local [ -h ] { run } ...","title":"Usage"},{"location":"command-line-interface/usage/#positional-arguments_2","text":"argument default help subcommand","title":"Positional arguments"},{"location":"command-line-interface/usage/#grizzly-cli-local-run","text":"Execute load test scenarios specified in a feature file.","title":"grizzly-cli local run"},{"location":"command-line-interface/usage/#usage_3","text":"grizzly-cli local run [ -h ] [ --verbose ] [ -T TESTDATA_VARIABLE ] [ -y ] [ -e ENVIRONMENT_FILE ] file","title":"Usage"},{"location":"command-line-interface/usage/#positional-arguments_3","text":"argument default help file path to feature file with one or more scenarios","title":"Positional arguments"},{"location":"command-line-interface/usage/#optional-arguments_2","text":"argument default help --verbose False changes the log level to DEBUG , regardless of what it says in the feature file. gives more verbose logging that can be useful when troubleshooting a problem with a scenario. -T, --testdata-variable specified in the format <name>=<value> . avoids being asked for an initial value for a scenario variable. -y, --yes False answer yes on any questions that would require confirmation -e, --environment-file configuration file with environment specific information","title":"Optional arguments"},{"location":"command-line-interface/usage/#grizzly-cli-dist","text":"Commands for running grizzly i distributed mode.","title":"grizzly-cli dist"},{"location":"command-line-interface/usage/#usage_4","text":"grizzly-cli dist [ -h ] [ --workers WORKERS ] [ --id ID ] [ --limit-nofile LIMIT_NOFILE ] [ --health-retries HEALTH_RETRIES ] [ --health-timeout HEALTH_TIMEOUT ] [ --health-interval HEALTH_INTERVAL ] [ --registry REGISTRY ] [ --tty ] [ --force-build | --build | --validate-config ] { build,run } ...","title":"Usage"},{"location":"command-line-interface/usage/#positional-arguments_4","text":"argument default help subcommand","title":"Positional arguments"},{"location":"command-line-interface/usage/#optional-arguments_3","text":"argument default help --workers 1 how many instances of the workers container that should be created --id unique identifier suffixed to compose project, should be used when the same user needs to run more than one instance of grizzly-cli --limit-nofile 10001 set system limit \"number of open files\" --health-retries 3 set number of retries for health check of master container --health-timeout 3 set timeout in seconds for health check of master container --health-interval 5 set interval in seconds between health checks of master container --registry push built image to this registry, if the registry has authentication you need to login first --tty False start containers with a TTY enabled --force-build False force rebuild the grizzly projects container image (no cache) --build False rebuild the grizzly projects container images (with cache) --validate-config False validate and print compose project file","title":"Optional arguments"},{"location":"command-line-interface/usage/#grizzly-cli-dist-build","text":"Build grizzly compose project container image before running test. If worker nodes runs on different physical computers, it is mandatory to build the images before hand and push to a registry. If image includes IBM MQ native dependencies, the build time increases due to download times. It is possible to self-host the archive and override the download host with environment variable IBM_MQ_LIB_HOST .","title":"grizzly-cli dist build"},{"location":"command-line-interface/usage/#usage_5","text":"grizzly-cli dist build [ -h ] [ --no-cache ] [ --registry REGISTRY ]","title":"Usage"},{"location":"command-line-interface/usage/#optional-arguments_4","text":"argument default help --no-cache False build container image with out cache (full build) --registry push built image to this registry, if the registry has authentication you need to login first","title":"Optional arguments"},{"location":"command-line-interface/usage/#grizzly-cli-dist-run","text":"Execute load test scenarios specified in a feature file.","title":"grizzly-cli dist run"},{"location":"command-line-interface/usage/#usage_6","text":"grizzly-cli dist run [ -h ] [ --verbose ] [ -T TESTDATA_VARIABLE ] [ -y ] [ -e ENVIRONMENT_FILE ] file","title":"Usage"},{"location":"command-line-interface/usage/#positional-arguments_5","text":"argument default help file path to feature file with one or more scenarios","title":"Positional arguments"},{"location":"command-line-interface/usage/#optional-arguments_5","text":"argument default help --verbose False changes the log level to DEBUG , regardless of what it says in the feature file. gives more verbose logging that can be useful when troubleshooting a problem with a scenario. -T, --testdata-variable specified in the format <name>=<value> . avoids being asked for an initial value for a scenario variable. -y, --yes False answer yes on any questions that would require confirmation -e, --environment-file configuration file with environment specific information","title":"Optional arguments"},{"location":"framework/changelog/","text":"Changelog v2.4.0 8e026ad8 : updated dependencies (#115) 5c747f53 : request wait task (#114) 6684c357 : TimerTask to measure \"response time\" for a group of tasks (#113) 5ceca1e2 : bug fixes in BlobStorageClient.put and scenario iterator (#112) 53ed0ad5 : remove debug print statement (#111) 4f0f01f7 : sort request statistics per scenario (#110) 35091c96 : grizzly.tasks.client must have a name (#109) v2.3.1 c754a8aa : support ISO 8601 formated DateTime and Time (#107) e33cd941 : client task ibm messagequeue (#103) eabe7b8f : possibility to implement custom (non-grizzly) atomic variables (#102) e4193dd4 : possibility to register custom locust message types and handlers (#101) 13b6c444 : scenario statistics (#98) ba37b60a : validating response step expression updated (#97) 89149d9d : \"end to end\" (E2E) test cases (#95) v2.3.0 b4fc150f : Change scenario hash to numerical index (#94) 6ecc7ab3 : support for parallell tasks (#92) 2f7025d9 : make tests runnable on windows (#91) v2.2.1 0ae1b373 : automagically check pypi for package url if unknown (#90) e6ef9d8f : install additional script dependencies correct (#89) c0a53532 : add support for requirements-script.txt to pip-sync wrapper (#88) 67f3d269 : install and cache script requirements (#87) ddd9929c : restructuring of code-quality workflow (#86) v2.2.0 d45b62d1 : github action action-push-tag@v1 is broken (#85) 283fe3fe : bug fix for iterations to stop when not finishing (#84) 0ed596f2 : Feature/clients tasks (#81) 6e6496ed : create docs/licenses if it does not exist, before trying to write md file (#79) 0dd489a3 : restructure of documentation (#78) v2.1.0 c4260a9e : Feature/response handlers (#77) 8278d17a : step to set user metadata/header key values (#75) 11de9b7f : clearer job name in code-quality workflow (#70) b6845b79 : Feature/issue 64 pep518 (#69) fbd96cfa : Feature/issue 61 pytz (#68) v2.0.0 af5e639b : twine: command not found (#67) 052a5ab9 : Feature/dependency update round 2 (#66) d4a3b935 : Feature/mq heartbeat (#65) 884b6761 : Feature/dependencies update (#63) 02c88045 : Plain text transformer fix, plus added rendering of date offset value (#62) 001cc5e5 : Bug/until task aborts (#60) v1.5.3 7c2b7a91 : Feature/cli docs (#59) a53f9159 : Bug/until stops too soon (#58) f53bb8b8 : removed debug print statements (#56) fb9f4933 : removed debug print statements (#56) v1.5.2 fb9f4933 : removed debug print statements (#56) v1.5.1 a2857569 : verify_certificates bug fixed (#55) v1.5.0 1c57c7f0 : Feature/restart scenario (#54) 9326218f : MQ concurrency fix (#53) cc178860 : renamed grizzly.tasks to grizzly.scenarios (#52) 281e9beb : fixed bug in parse_arguments if an argument value contained comma (#51) v1.4.4 e13ff471 : Feature/date parse task (#50) d16ef8e1 : handle exceptions during until retries (#49) 0994f9af : increased test coverage (#48) eaaeab22 : Fix for doing retry upon receiving MQRC_TRUNCATED_MSG_FAILED while browsing messages (#47) 88202428 : support for templating in arguments in condition (#46) v1.4.3 3e47adbd : fixed alignment i scenario summary (#45) v1.4.2 e976144b : Bug/async messaged logging (#44) b4b0be63 : Feature/request until (#42) v1.4.1 e6d8fb3f : fix for ensuring correct data type in metric written to influx (#41) v1.4.0 26b81305 : print start and stop date and time when finished (#40) 4aef0eef : request response_time fixes (#39) fb95268f : updated dependencies and devcontainer (#38) f98d904d : Feature/scenario info (#37) v1.3.1 73827bf4 : error logging in transformer class (#35) 3e5e03aa : init racecondition (#36) dd0c75a5 : support for request template files in combination with data tables (#34) 8d56f4fe : Feature/parameterize more (#33) v1.3.0 60f39988 : transparent support for setting content type in endpoint (#32) 423bc994 : expression support for service bus functionality (#31) 2e2695df : support for offset in AtomicDate (#30) 41b78e89 : AtomicMessageQueue content type support (#29) 979d4bbb : unified arguments handling through out grizzly (#28) 6fad96e4 : simplified AtomicMessageQueue and AtomicServiceBus (#27) 64888c05 : implementation of getter tasks (http) (#26) 2d6862d7 : Restored dummy_pymqi.py, the added stuff wasn't needed 4f21a8d3 : MessageQueueUser: get messages that matches expression 1e1edc44 : run code quality workflow when PR is updated 6dc839c9 : corrected sentence in documentation for SleepTask v1.2.0 6ee5fffe : added documentation for the different task types 1b91d79b : implementation of AtomicServiceBus variable b867d471 : ServiceBus support in async-messaged 83c0ac9c : refactoring of grizzly_extras.messagequeue 9b9953e6 : included mypy extension in devcontainer aea0c288 : implemented RECEIVE for ServiceBusUser b046b60c : Changed spawn_rate to float and fixed tests 3ce0b102 : Changed spawn rate from int to float a789a71d : Added support for user weight 29f7d047 : updated atomic variables getting value and arguments 81ccbed1 : change log level for grizzly_extras if started with verbose v1.1.0 b78be958 : new task to parse data b2ed98a1 : XmlTransformer: match parts of a document, and dump it to string 9c55e5a3 : move testdata production if variable has on_consumer = True cfe9875b : specify external dependencies for users and variables in the objects themself 2140fe79 : new variable AtomicMessageQueue 1f6dba03 : refactoring for clearer distinction between utils and step helpers. 99fab953 : fixing empty changelog in workflow@github c5ddeeb9 : generate changelog when building documentation 5e595637 : fixed missed float -> SleepTask change in test 2c688554 : improved base for adding different types of tasks cb8db862 : reafactor LocustContext to GrizzlyContext 3f1137b9 : refactoring of grizzly.tasks bd3382e0 : refactoring RequestContext to RequestTask 031a9595 : handle edge cases with Getitem nodes ca7c17d7 : handle Getitem nodes when parsing templates for variables a1cabb31 : only try to remove secrets from dicts 1145a651 : possibility to store json objects/list in variables v1.0.1 dae7be58 : Corrected string comparison operator 4b8a8470 : Adjusted test for messagequeue bd9bb977 : Fix for being able to log MQ request payload cc5dfff6 : updated mkdocs to 1.2.3 due to CVE-2021-40978 604f5704 : fixed url","title":"Changelog"},{"location":"framework/changelog/#changelog","text":"","title":"Changelog"},{"location":"framework/changelog/#v240","text":"8e026ad8 : updated dependencies (#115) 5c747f53 : request wait task (#114) 6684c357 : TimerTask to measure \"response time\" for a group of tasks (#113) 5ceca1e2 : bug fixes in BlobStorageClient.put and scenario iterator (#112) 53ed0ad5 : remove debug print statement (#111) 4f0f01f7 : sort request statistics per scenario (#110) 35091c96 : grizzly.tasks.client must have a name (#109)","title":"v2.4.0"},{"location":"framework/changelog/#v231","text":"c754a8aa : support ISO 8601 formated DateTime and Time (#107) e33cd941 : client task ibm messagequeue (#103) eabe7b8f : possibility to implement custom (non-grizzly) atomic variables (#102) e4193dd4 : possibility to register custom locust message types and handlers (#101) 13b6c444 : scenario statistics (#98) ba37b60a : validating response step expression updated (#97) 89149d9d : \"end to end\" (E2E) test cases (#95)","title":"v2.3.1"},{"location":"framework/changelog/#v230","text":"b4fc150f : Change scenario hash to numerical index (#94) 6ecc7ab3 : support for parallell tasks (#92) 2f7025d9 : make tests runnable on windows (#91)","title":"v2.3.0"},{"location":"framework/changelog/#v221","text":"0ae1b373 : automagically check pypi for package url if unknown (#90) e6ef9d8f : install additional script dependencies correct (#89) c0a53532 : add support for requirements-script.txt to pip-sync wrapper (#88) 67f3d269 : install and cache script requirements (#87) ddd9929c : restructuring of code-quality workflow (#86)","title":"v2.2.1"},{"location":"framework/changelog/#v220","text":"d45b62d1 : github action action-push-tag@v1 is broken (#85) 283fe3fe : bug fix for iterations to stop when not finishing (#84) 0ed596f2 : Feature/clients tasks (#81) 6e6496ed : create docs/licenses if it does not exist, before trying to write md file (#79) 0dd489a3 : restructure of documentation (#78)","title":"v2.2.0"},{"location":"framework/changelog/#v210","text":"c4260a9e : Feature/response handlers (#77) 8278d17a : step to set user metadata/header key values (#75) 11de9b7f : clearer job name in code-quality workflow (#70) b6845b79 : Feature/issue 64 pep518 (#69) fbd96cfa : Feature/issue 61 pytz (#68)","title":"v2.1.0"},{"location":"framework/changelog/#v200","text":"af5e639b : twine: command not found (#67) 052a5ab9 : Feature/dependency update round 2 (#66) d4a3b935 : Feature/mq heartbeat (#65) 884b6761 : Feature/dependencies update (#63) 02c88045 : Plain text transformer fix, plus added rendering of date offset value (#62) 001cc5e5 : Bug/until task aborts (#60)","title":"v2.0.0"},{"location":"framework/changelog/#v153","text":"7c2b7a91 : Feature/cli docs (#59) a53f9159 : Bug/until stops too soon (#58) f53bb8b8 : removed debug print statements (#56) fb9f4933 : removed debug print statements (#56)","title":"v1.5.3"},{"location":"framework/changelog/#v152","text":"fb9f4933 : removed debug print statements (#56)","title":"v1.5.2"},{"location":"framework/changelog/#v151","text":"a2857569 : verify_certificates bug fixed (#55)","title":"v1.5.1"},{"location":"framework/changelog/#v150","text":"1c57c7f0 : Feature/restart scenario (#54) 9326218f : MQ concurrency fix (#53) cc178860 : renamed grizzly.tasks to grizzly.scenarios (#52) 281e9beb : fixed bug in parse_arguments if an argument value contained comma (#51)","title":"v1.5.0"},{"location":"framework/changelog/#v144","text":"e13ff471 : Feature/date parse task (#50) d16ef8e1 : handle exceptions during until retries (#49) 0994f9af : increased test coverage (#48) eaaeab22 : Fix for doing retry upon receiving MQRC_TRUNCATED_MSG_FAILED while browsing messages (#47) 88202428 : support for templating in arguments in condition (#46)","title":"v1.4.4"},{"location":"framework/changelog/#v143","text":"3e47adbd : fixed alignment i scenario summary (#45)","title":"v1.4.3"},{"location":"framework/changelog/#v142","text":"e976144b : Bug/async messaged logging (#44) b4b0be63 : Feature/request until (#42)","title":"v1.4.2"},{"location":"framework/changelog/#v141","text":"e6d8fb3f : fix for ensuring correct data type in metric written to influx (#41)","title":"v1.4.1"},{"location":"framework/changelog/#v140","text":"26b81305 : print start and stop date and time when finished (#40) 4aef0eef : request response_time fixes (#39) fb95268f : updated dependencies and devcontainer (#38) f98d904d : Feature/scenario info (#37)","title":"v1.4.0"},{"location":"framework/changelog/#v131","text":"73827bf4 : error logging in transformer class (#35) 3e5e03aa : init racecondition (#36) dd0c75a5 : support for request template files in combination with data tables (#34) 8d56f4fe : Feature/parameterize more (#33)","title":"v1.3.1"},{"location":"framework/changelog/#v130","text":"60f39988 : transparent support for setting content type in endpoint (#32) 423bc994 : expression support for service bus functionality (#31) 2e2695df : support for offset in AtomicDate (#30) 41b78e89 : AtomicMessageQueue content type support (#29) 979d4bbb : unified arguments handling through out grizzly (#28) 6fad96e4 : simplified AtomicMessageQueue and AtomicServiceBus (#27) 64888c05 : implementation of getter tasks (http) (#26) 2d6862d7 : Restored dummy_pymqi.py, the added stuff wasn't needed 4f21a8d3 : MessageQueueUser: get messages that matches expression 1e1edc44 : run code quality workflow when PR is updated 6dc839c9 : corrected sentence in documentation for SleepTask","title":"v1.3.0"},{"location":"framework/changelog/#v120","text":"6ee5fffe : added documentation for the different task types 1b91d79b : implementation of AtomicServiceBus variable b867d471 : ServiceBus support in async-messaged 83c0ac9c : refactoring of grizzly_extras.messagequeue 9b9953e6 : included mypy extension in devcontainer aea0c288 : implemented RECEIVE for ServiceBusUser b046b60c : Changed spawn_rate to float and fixed tests 3ce0b102 : Changed spawn rate from int to float a789a71d : Added support for user weight 29f7d047 : updated atomic variables getting value and arguments 81ccbed1 : change log level for grizzly_extras if started with verbose","title":"v1.2.0"},{"location":"framework/changelog/#v110","text":"b78be958 : new task to parse data b2ed98a1 : XmlTransformer: match parts of a document, and dump it to string 9c55e5a3 : move testdata production if variable has on_consumer = True cfe9875b : specify external dependencies for users and variables in the objects themself 2140fe79 : new variable AtomicMessageQueue 1f6dba03 : refactoring for clearer distinction between utils and step helpers. 99fab953 : fixing empty changelog in workflow@github c5ddeeb9 : generate changelog when building documentation 5e595637 : fixed missed float -> SleepTask change in test 2c688554 : improved base for adding different types of tasks cb8db862 : reafactor LocustContext to GrizzlyContext 3f1137b9 : refactoring of grizzly.tasks bd3382e0 : refactoring RequestContext to RequestTask 031a9595 : handle edge cases with Getitem nodes ca7c17d7 : handle Getitem nodes when parsing templates for variables a1cabb31 : only try to remove secrets from dicts 1145a651 : possibility to store json objects/list in variables","title":"v1.1.0"},{"location":"framework/changelog/#v101","text":"dae7be58 : Corrected string comparison operator 4b8a8470 : Adjusted test for messagequeue bd9bb977 : Fix for being able to log MQ request payload cc5dfff6 : updated mkdocs to 1.2.3 due to CVE-2021-40978 604f5704 : fixed url","title":"v1.0.1"},{"location":"framework/licenses/","text":"Licenses The MIT License (MIT) Copyright \u00a9 2021 Biometria Ekonomiska F\u00f6rening Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \u201cSoftware\u201d), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \u201cAS IS\u201d, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Third party licenses Python dependencies Name Version License PyNaCl 1.5.0 Apache License 2.0 bcrypt 3.2.2 Apache Software License bleach 5.0.0 Apache Software License coverage 6.4 Apache Software License ghp-import 2.1.0 Apache Software License google-api-core 2.8.0 Apache Software License google-auth 2.6.6 Apache Software License googleapis-common-protos 1.56.1 Apache Software License importlib-metadata 4.11.4 Apache Software License jsonpath-ng 1.5.3 Apache Software License msgpack 1.0.3 Apache Software License opencensus 0.9.0 Apache Software License opencensus-context 0.1.2 Apache Software License opencensus-ext-azure 1.1.4 Apache Software License readme-renderer 35.0 Apache Software License requests 2.27.1 Apache Software License requests-toolbelt 0.9.1 Apache Software License rfc3986 2.0.0 Apache Software License rsa 4.8 Apache Software License twine 3.8.0 Apache Software License types-Jinja2 2.11.9 Apache Software License types-MarkupSafe 1.1.10 Apache Software License types-PyYAML 5.4.12 Apache Software License types-backports 0.1.3 Apache Software License types-cryptography 3.3.21 Apache Software License types-paramiko 2.10.0 Apache Software License types-python-dateutil 2.8.16 Apache Software License types-requests 2.27.28 Apache Software License types-urllib3 1.26.14 Apache Software License tzdata 2022.1 Apache Software License watchdog 2.1.8 Apache Software License yapf 0.32.0 Apache Software License cryptography 37.0.2 Apache Software License; BSD License packaging 21.3 Apache Software License; BSD License python-dateutil 2.8.2 Apache Software License; BSD License ply 3.11 BSD Flask 2.1.2 BSD License Flask-BasicAuth 0.2.0 BSD License Jinja2 3.1.2 BSD License Markdown 3.3.7 BSD License MarkupSafe 2.1.1 BSD License Pygments 2.12.0 BSD License SecretStorage 3.3.2 BSD License Werkzeug 2.1.2 BSD License aenum 3.1.11 BSD License astunparse 1.6.3 BSD License behave 1.2.6 BSD License click 8.1.3 BSD License colorama 0.4.4 BSD License decorator 5.1.1 BSD License dill 0.3.5.1 BSD License idna 3.3 BSD License isodate 0.6.1 BSD License itsdangerous 2.1.2 BSD License lazy-object-proxy 1.7.1 BSD License lxml 4.8.0 BSD License mkdocs 1.3.0 BSD License oauthlib 3.2.0 BSD License parse 1.19.0 BSD License parse-type 0.6.0 BSD License pip-tools 6.6.2 BSD License psutil 5.9.1 BSD License pyasn1 0.4.8 BSD License pyasn1-modules 0.2.8 BSD License pycparser 2.21 BSD License requests-oauthlib 1.3.1 BSD License setproctitle 1.2.3 BSD License webencodings 0.5.1 BSD License wrapt 1.14.1 BSD License docutils 0.18.1 BSD License; GNU General Public License (GPL); Public Domain; Python Software Foundation License pyzmq 22.3.0 BSD License; GNU Library or Lesser General Public License (LGPL) pytest-timeout 2.1.0 DFSG approved; MIT License pylint 2.13.9 GNU General Public License v2 (GPLv2) astroid 2.11.5 GNU Lesser General Public License v2 (LGPLv2) chardet 4.0.0 GNU Library or Lesser General Public License (LGPL) paramiko 2.11.0 GNU Library or Lesser General Public License (LGPL) geventhttpclient 1.5.3 LICENSE-MIT Brotli 1.0.9 MIT License ConfigArgParse 1.5.3 MIT License DataProperty 0.55.0 MIT License Deprecated 1.2.13 MIT License Flask-Cors 3.0.10 MIT License PyJWT 2.4.0 MIT License PyYAML 5.4.1 MIT License atomicwrites 1.4.0 MIT License attrs 21.4.0 MIT License azure-common 1.1.28 MIT License azure-core 1.22.1 MIT License azure-identity 1.10.0 MIT License azure-servicebus 7.6.1 MIT License azure-storage-blob 12.11.0 MIT License build 0.8.0 MIT License cachetools 5.1.0 MIT License cffi 1.15.0 MIT License charset-normalizer 2.0.12 MIT License databind 1.5.2 MIT License databind.core 1.5.2 MIT License databind.json 1.5.2 MIT License docspec 2.0.1 MIT License docspec-python 2.0.1 MIT License docstring-parser 0.11 MIT License flake8 4.0.1 MIT License gevent 21.12.0 MIT License greenlet 1.1.2 MIT License influxdb 5.3.1 MIT License iniconfig 1.1.1 MIT License isort 5.10.1 MIT License jeepney 0.8.0 MIT License locust 2.9.0 MIT License mbstrdecoder 1.1.0 MIT License mccabe 0.6.1 MIT License mergedeep 1.3.4 MIT License mkdocs-material 8.2.15 MIT License mkdocs-material-extensions 1.0.3 MIT License msal 1.17.0 MIT License msal-extensions 1.0.0 MIT License msrest 0.6.21 MIT License mypy 0.960 MIT License mypy-extensions 0.4.3 MIT License nr.util 0.8.11 MIT License pathvalidate 2.5.0 MIT License pep517 0.12.0 MIT License pkginfo 1.8.2 MIT License platformdirs 2.5.2 MIT License pluggy 1.0.0 MIT License py 1.11.0 MIT License pycodestyle 2.8.0 MIT License pydoc-markdown 4.6.3 MIT License pyflakes 2.4.0 MIT License pymdown-extensions 9.4 MIT License pyparsing 3.0.9 MIT License pytablewriter 0.64.2 MIT License pytest 7.1.2 MIT License pytest-cov 3.0.0 MIT License pytest-mock 3.7.0 MIT License pytz 2022.1 MIT License pyyaml-env-tag 0.1 MIT License roundrobin 0.0.2 MIT License six 1.16.0 MIT License tabledata 1.3.0 MIT License tcolorpy 0.1.2 MIT License tomli 2.0.1 MIT License tomli-w 1.0.0 MIT License typepy 1.3.0 MIT License uamqp 1.5.3 MIT License urllib3 1.26.9 MIT License zipp 3.8.0 MIT License tqdm 4.64.0 MIT License; Mozilla Public License 2.0 (MPL 2.0) keyring 23.5.1 MIT License; Python Software Foundation License certifi 2022.5.18.1 Mozilla Public License 2.0 (MPL 2.0) portalocker 2.4.0 PSF typing-extensions 3.10.0.2 Python Software Foundation License protobuf 4.21.0 UNKNOWN zope.event 4.5.0 Zope Public License zope.interface 5.4.0 Zope Public License Native dependencies Container images (both grizzly runtime and Microsoft Visual Code devcontainer) contains dependencies from IBM MQ Redistributable Components . The redistributable license terms may be found in the relevant IBM MQ Program license agreement, which may be found at the IBM Software License Agreements website, or in licenses/ directory in the archive .","title":"Licenses"},{"location":"framework/licenses/#licenses","text":"","title":"Licenses"},{"location":"framework/licenses/#the-mit-license-mit","text":"Copyright \u00a9 2021 Biometria Ekonomiska F\u00f6rening Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \u201cSoftware\u201d), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \u201cAS IS\u201d, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"The MIT License (MIT)"},{"location":"framework/licenses/#third-party-licenses","text":"","title":"Third party licenses"},{"location":"framework/licenses/#python-dependencies","text":"Name Version License PyNaCl 1.5.0 Apache License 2.0 bcrypt 3.2.2 Apache Software License bleach 5.0.0 Apache Software License coverage 6.4 Apache Software License ghp-import 2.1.0 Apache Software License google-api-core 2.8.0 Apache Software License google-auth 2.6.6 Apache Software License googleapis-common-protos 1.56.1 Apache Software License importlib-metadata 4.11.4 Apache Software License jsonpath-ng 1.5.3 Apache Software License msgpack 1.0.3 Apache Software License opencensus 0.9.0 Apache Software License opencensus-context 0.1.2 Apache Software License opencensus-ext-azure 1.1.4 Apache Software License readme-renderer 35.0 Apache Software License requests 2.27.1 Apache Software License requests-toolbelt 0.9.1 Apache Software License rfc3986 2.0.0 Apache Software License rsa 4.8 Apache Software License twine 3.8.0 Apache Software License types-Jinja2 2.11.9 Apache Software License types-MarkupSafe 1.1.10 Apache Software License types-PyYAML 5.4.12 Apache Software License types-backports 0.1.3 Apache Software License types-cryptography 3.3.21 Apache Software License types-paramiko 2.10.0 Apache Software License types-python-dateutil 2.8.16 Apache Software License types-requests 2.27.28 Apache Software License types-urllib3 1.26.14 Apache Software License tzdata 2022.1 Apache Software License watchdog 2.1.8 Apache Software License yapf 0.32.0 Apache Software License cryptography 37.0.2 Apache Software License; BSD License packaging 21.3 Apache Software License; BSD License python-dateutil 2.8.2 Apache Software License; BSD License ply 3.11 BSD Flask 2.1.2 BSD License Flask-BasicAuth 0.2.0 BSD License Jinja2 3.1.2 BSD License Markdown 3.3.7 BSD License MarkupSafe 2.1.1 BSD License Pygments 2.12.0 BSD License SecretStorage 3.3.2 BSD License Werkzeug 2.1.2 BSD License aenum 3.1.11 BSD License astunparse 1.6.3 BSD License behave 1.2.6 BSD License click 8.1.3 BSD License colorama 0.4.4 BSD License decorator 5.1.1 BSD License dill 0.3.5.1 BSD License idna 3.3 BSD License isodate 0.6.1 BSD License itsdangerous 2.1.2 BSD License lazy-object-proxy 1.7.1 BSD License lxml 4.8.0 BSD License mkdocs 1.3.0 BSD License oauthlib 3.2.0 BSD License parse 1.19.0 BSD License parse-type 0.6.0 BSD License pip-tools 6.6.2 BSD License psutil 5.9.1 BSD License pyasn1 0.4.8 BSD License pyasn1-modules 0.2.8 BSD License pycparser 2.21 BSD License requests-oauthlib 1.3.1 BSD License setproctitle 1.2.3 BSD License webencodings 0.5.1 BSD License wrapt 1.14.1 BSD License docutils 0.18.1 BSD License; GNU General Public License (GPL); Public Domain; Python Software Foundation License pyzmq 22.3.0 BSD License; GNU Library or Lesser General Public License (LGPL) pytest-timeout 2.1.0 DFSG approved; MIT License pylint 2.13.9 GNU General Public License v2 (GPLv2) astroid 2.11.5 GNU Lesser General Public License v2 (LGPLv2) chardet 4.0.0 GNU Library or Lesser General Public License (LGPL) paramiko 2.11.0 GNU Library or Lesser General Public License (LGPL) geventhttpclient 1.5.3 LICENSE-MIT Brotli 1.0.9 MIT License ConfigArgParse 1.5.3 MIT License DataProperty 0.55.0 MIT License Deprecated 1.2.13 MIT License Flask-Cors 3.0.10 MIT License PyJWT 2.4.0 MIT License PyYAML 5.4.1 MIT License atomicwrites 1.4.0 MIT License attrs 21.4.0 MIT License azure-common 1.1.28 MIT License azure-core 1.22.1 MIT License azure-identity 1.10.0 MIT License azure-servicebus 7.6.1 MIT License azure-storage-blob 12.11.0 MIT License build 0.8.0 MIT License cachetools 5.1.0 MIT License cffi 1.15.0 MIT License charset-normalizer 2.0.12 MIT License databind 1.5.2 MIT License databind.core 1.5.2 MIT License databind.json 1.5.2 MIT License docspec 2.0.1 MIT License docspec-python 2.0.1 MIT License docstring-parser 0.11 MIT License flake8 4.0.1 MIT License gevent 21.12.0 MIT License greenlet 1.1.2 MIT License influxdb 5.3.1 MIT License iniconfig 1.1.1 MIT License isort 5.10.1 MIT License jeepney 0.8.0 MIT License locust 2.9.0 MIT License mbstrdecoder 1.1.0 MIT License mccabe 0.6.1 MIT License mergedeep 1.3.4 MIT License mkdocs-material 8.2.15 MIT License mkdocs-material-extensions 1.0.3 MIT License msal 1.17.0 MIT License msal-extensions 1.0.0 MIT License msrest 0.6.21 MIT License mypy 0.960 MIT License mypy-extensions 0.4.3 MIT License nr.util 0.8.11 MIT License pathvalidate 2.5.0 MIT License pep517 0.12.0 MIT License pkginfo 1.8.2 MIT License platformdirs 2.5.2 MIT License pluggy 1.0.0 MIT License py 1.11.0 MIT License pycodestyle 2.8.0 MIT License pydoc-markdown 4.6.3 MIT License pyflakes 2.4.0 MIT License pymdown-extensions 9.4 MIT License pyparsing 3.0.9 MIT License pytablewriter 0.64.2 MIT License pytest 7.1.2 MIT License pytest-cov 3.0.0 MIT License pytest-mock 3.7.0 MIT License pytz 2022.1 MIT License pyyaml-env-tag 0.1 MIT License roundrobin 0.0.2 MIT License six 1.16.0 MIT License tabledata 1.3.0 MIT License tcolorpy 0.1.2 MIT License tomli 2.0.1 MIT License tomli-w 1.0.0 MIT License typepy 1.3.0 MIT License uamqp 1.5.3 MIT License urllib3 1.26.9 MIT License zipp 3.8.0 MIT License tqdm 4.64.0 MIT License; Mozilla Public License 2.0 (MPL 2.0) keyring 23.5.1 MIT License; Python Software Foundation License certifi 2022.5.18.1 Mozilla Public License 2.0 (MPL 2.0) portalocker 2.4.0 PSF typing-extensions 3.10.0.2 Python Software Foundation License protobuf 4.21.0 UNKNOWN zope.event 4.5.0 Zope Public License zope.interface 5.4.0 Zope Public License","title":"Python dependencies"},{"location":"framework/licenses/#native-dependencies","text":"Container images (both grizzly runtime and Microsoft Visual Code devcontainer) contains dependencies from IBM MQ Redistributable Components . The redistributable license terms may be found in the relevant IBM MQ Program license agreement, which may be found at the IBM Software License Agreements website, or in licenses/ directory in the archive .","title":"Native dependencies"},{"location":"framework/usage/load-users/blob-storage/","text":"grizzly.users.blobstorage Put files to Azure Blob Storage. Request methods Supports the following request methods: send put Format Format of host is the following: [DefaultEndpointsProtocol=]https;EndpointSuffix=<hostname>;AccountName=<account name>;AccountKey=<account key> endpoint in the request is the name of the blob storage container. Name of the targeted file in the container is either name or based on the file name of source . Examples Example of how to use it in a scenario: Given a user of type \" BlobStorage \" load testing \" DefaultEndpointsProtocol=https;EndpointSuffix=core.windows.net;AccountName=examplestorage;AccountKey=xxxyyyyzzz== \" Then send request \" test/blob.file \" to endpoint \" azure-blobstorage-container-name \"","title":"Blob Storage"},{"location":"framework/usage/load-users/blob-storage/#grizzlyusersblobstorage","text":"Put files to Azure Blob Storage.","title":"grizzly.users.blobstorage"},{"location":"framework/usage/load-users/blob-storage/#request-methods","text":"Supports the following request methods: send put","title":"Request methods"},{"location":"framework/usage/load-users/blob-storage/#format","text":"Format of host is the following: [DefaultEndpointsProtocol=]https;EndpointSuffix=<hostname>;AccountName=<account name>;AccountKey=<account key> endpoint in the request is the name of the blob storage container. Name of the targeted file in the container is either name or based on the file name of source .","title":"Format"},{"location":"framework/usage/load-users/blob-storage/#examples","text":"Example of how to use it in a scenario: Given a user of type \" BlobStorage \" load testing \" DefaultEndpointsProtocol=https;EndpointSuffix=core.windows.net;AccountName=examplestorage;AccountKey=xxxyyyyzzz== \" Then send request \" test/blob.file \" to endpoint \" azure-blobstorage-container-name \"","title":"Examples"},{"location":"framework/usage/load-users/message-queue/","text":"grizzly.users.messagequeue Get and put messages on with IBM MQ queues. User is based on pymqi for communicating with IBM MQ. However pymqi uses native libraries which gevent (used by locust ) cannot patch, which causes any calls in pymqi to block the rest of locust . To get around this, the user implementation communicates with a stand-alone process via zmq, which in turn communicates with IBM MQ. async-messaged starts automagically when a scenario uses MessageQueueUser and pymqi dependencies are installed. Request methods Supports the following request methods: send put get receive Format Format of host is the following: mq://<hostname>:<port>/?QueueManager=<queue manager name>&Channel=<channel name> endpoint in the request is the name of an MQ queue. This can also be combined with an expression, if a specific message is to be retrieved from the queue. The format of endpoint is: queue:<queue_name>[, expression:<expression>] Where <expression> can be a XPath or jsonpath expression, depending on the specified content type. See example below. Examples Example of how to use it in a scenario: Given a user of type \" MessageQueue \" load testing \" mq://mq.example.com/?QueueManager=QM01&Channel=SRVCONN01 \" Then put request \" test/queue-message.j2.json \" with name \" queue-message \" to endpoint \" queue:INCOMING.MESSAGES \" Get message Default behavior is to fail directly if there is no message on the queue. If the request should wait until a message is available, set the time it should wait with message.wait (seconds) context variable. To keep the connection alive during longer waiting periods, a heartbeat interval can be configured using the connection.heartbeat_interval (seconds) context variable (default 300). Given a user of type \" MessageQueue \" load testing \" mq://mq.example.com/?QueueManager=QM01&Channel=SRVCONN01 \" And set context variable \" message.wait \" to \" 5 \" Then get request with name \" get-queue-message \" from endpoint \" queue:INCOMING.MESSAGES \" In this example, the request will not fail if there is a message on queue within 5 seconds. Get message with expression When specifying an expression, the messages on the queue are first browsed. If any message matches the expression, it is later consumed from the queue. If no matching message was found during browsing, it is repeated again after a slight delay, up until the specified message.wait seconds has elapsed. To use expressions, a content type must be specified for the get request, e.g. application/xml : Given a user of type \" MessageQueue \" load testing \" mq://mq.example.com/?QueueManager=QM01&Channel=SRVCONN01 \" And set context variable \" message.wait \" to \" 5 \" Then get request with name \" get-specific-queue-message \" from endpoint \" queue:INCOMING.MESSAGES, expression: //document[@id='abc123'] \" And set response content type to \" application/xml \" Authentication Username and password Given a user of type \" MessageQueue \" load testing \" mq://mqm:admin@mq.example.com/?QueueManager=QM01&Channel=SRVCONN01 \" And set context variable \" auth.username \" to \" <username> \" And set context variable \" auth.password \" to \" <password> \" With TLS A key repository (3 files; .kdb , .rdb and .sth ) for the user is needed, and is specified with auth.key_file excluding the file extension. Given a user of type \" MessageQueue \" load testing \" mq://mqm:admin@mq.example.com/?QueueManager=QM01&Channel=SRVCONN01 \" And set context variable \" auth.username \" to \" <username> \" And set context variable \" auth.password \" to \" <password> \" And set context variable \" auth.key_file \" to \" <path to key file, excl. file extension> \" Default SSL cipher is ECDHE_RSA_AES_256_GCM_SHA384 , change it by setting auth.ssl_cipher context variable. Default certificate label is set to auth.username , change it by setting auth.cert_label context variable.","title":"Message Queue"},{"location":"framework/usage/load-users/message-queue/#grizzlyusersmessagequeue","text":"Get and put messages on with IBM MQ queues. User is based on pymqi for communicating with IBM MQ. However pymqi uses native libraries which gevent (used by locust ) cannot patch, which causes any calls in pymqi to block the rest of locust . To get around this, the user implementation communicates with a stand-alone process via zmq, which in turn communicates with IBM MQ. async-messaged starts automagically when a scenario uses MessageQueueUser and pymqi dependencies are installed.","title":"grizzly.users.messagequeue"},{"location":"framework/usage/load-users/message-queue/#request-methods","text":"Supports the following request methods: send put get receive","title":"Request methods"},{"location":"framework/usage/load-users/message-queue/#format","text":"Format of host is the following: mq://<hostname>:<port>/?QueueManager=<queue manager name>&Channel=<channel name> endpoint in the request is the name of an MQ queue. This can also be combined with an expression, if a specific message is to be retrieved from the queue. The format of endpoint is: queue:<queue_name>[, expression:<expression>] Where <expression> can be a XPath or jsonpath expression, depending on the specified content type. See example below.","title":"Format"},{"location":"framework/usage/load-users/message-queue/#examples","text":"Example of how to use it in a scenario: Given a user of type \" MessageQueue \" load testing \" mq://mq.example.com/?QueueManager=QM01&Channel=SRVCONN01 \" Then put request \" test/queue-message.j2.json \" with name \" queue-message \" to endpoint \" queue:INCOMING.MESSAGES \"","title":"Examples"},{"location":"framework/usage/load-users/message-queue/#get-message","text":"Default behavior is to fail directly if there is no message on the queue. If the request should wait until a message is available, set the time it should wait with message.wait (seconds) context variable. To keep the connection alive during longer waiting periods, a heartbeat interval can be configured using the connection.heartbeat_interval (seconds) context variable (default 300). Given a user of type \" MessageQueue \" load testing \" mq://mq.example.com/?QueueManager=QM01&Channel=SRVCONN01 \" And set context variable \" message.wait \" to \" 5 \" Then get request with name \" get-queue-message \" from endpoint \" queue:INCOMING.MESSAGES \" In this example, the request will not fail if there is a message on queue within 5 seconds.","title":"Get message"},{"location":"framework/usage/load-users/message-queue/#get-message-with-expression","text":"When specifying an expression, the messages on the queue are first browsed. If any message matches the expression, it is later consumed from the queue. If no matching message was found during browsing, it is repeated again after a slight delay, up until the specified message.wait seconds has elapsed. To use expressions, a content type must be specified for the get request, e.g. application/xml : Given a user of type \" MessageQueue \" load testing \" mq://mq.example.com/?QueueManager=QM01&Channel=SRVCONN01 \" And set context variable \" message.wait \" to \" 5 \" Then get request with name \" get-specific-queue-message \" from endpoint \" queue:INCOMING.MESSAGES, expression: //document[@id='abc123'] \" And set response content type to \" application/xml \"","title":"Get message with expression"},{"location":"framework/usage/load-users/message-queue/#authentication","text":"","title":"Authentication"},{"location":"framework/usage/load-users/message-queue/#username-and-password","text":"Given a user of type \" MessageQueue \" load testing \" mq://mqm:admin@mq.example.com/?QueueManager=QM01&Channel=SRVCONN01 \" And set context variable \" auth.username \" to \" <username> \" And set context variable \" auth.password \" to \" <password> \"","title":"Username and password"},{"location":"framework/usage/load-users/message-queue/#with-tls","text":"A key repository (3 files; .kdb , .rdb and .sth ) for the user is needed, and is specified with auth.key_file excluding the file extension. Given a user of type \" MessageQueue \" load testing \" mq://mqm:admin@mq.example.com/?QueueManager=QM01&Channel=SRVCONN01 \" And set context variable \" auth.username \" to \" <username> \" And set context variable \" auth.password \" to \" <password> \" And set context variable \" auth.key_file \" to \" <path to key file, excl. file extension> \" Default SSL cipher is ECDHE_RSA_AES_256_GCM_SHA384 , change it by setting auth.ssl_cipher context variable. Default certificate label is set to auth.username , change it by setting auth.cert_label context variable.","title":"With TLS"},{"location":"framework/usage/load-users/rest-api/","text":"grizzly.users.restapi Communicates with HTTP and HTTPS, with built-in support for Azure authenticated endpoints. Request methods Supports the following request methods: get put post Format Format of host is the following: http[s]://<hostname> Examples Example on how to use it in a scenario: Given a user of type \" RestApi \" load testing \" https://api.example.com \" Then post request \" test/request.j2.json \" to endpoint \" /api/test \" Then get request from endpoint \" /api/test \" To change how often the token should be refreshed, default is 3000 seconds: And set context variable \" auth.refresh_time \" to \" 3500 \" Authentication Client secret Given a user of type \" RestApi \" load testing \" https://api.example.com \" And set context variable \" auth.client.tenant \" \" <tenant name/guid> \" And set context variable \" auth.client.id \" to \" <client id> \" And set context variable \" auth.client.secret \" to \" <client secret> \" And set context variable \" auth.client.resource \" to \" <resource url/guid> \" Username and password auth.user.redirect_uri needs to correspond to the endpoint that the client secret is registrered for. Given a user of type \" RestApi \" load testing \" https://api.example.com \" And set context variable \" auth.client.id \" to \" <client id> \" And set context variable \" auth.user.username \" to \" alice@example.onmicrosoft.com \" And set context variable \" auth.user.password \" to \" HemL1gaArn3! \" And set context variable \" auth.user.redirect_uri \" to \" /app-registrered-redirect-uri \"","title":"Rest API"},{"location":"framework/usage/load-users/rest-api/#grizzlyusersrestapi","text":"Communicates with HTTP and HTTPS, with built-in support for Azure authenticated endpoints.","title":"grizzly.users.restapi"},{"location":"framework/usage/load-users/rest-api/#request-methods","text":"Supports the following request methods: get put post","title":"Request methods"},{"location":"framework/usage/load-users/rest-api/#format","text":"Format of host is the following: http[s]://<hostname>","title":"Format"},{"location":"framework/usage/load-users/rest-api/#examples","text":"Example on how to use it in a scenario: Given a user of type \" RestApi \" load testing \" https://api.example.com \" Then post request \" test/request.j2.json \" to endpoint \" /api/test \" Then get request from endpoint \" /api/test \" To change how often the token should be refreshed, default is 3000 seconds: And set context variable \" auth.refresh_time \" to \" 3500 \"","title":"Examples"},{"location":"framework/usage/load-users/rest-api/#authentication","text":"","title":"Authentication"},{"location":"framework/usage/load-users/rest-api/#client-secret","text":"Given a user of type \" RestApi \" load testing \" https://api.example.com \" And set context variable \" auth.client.tenant \" \" <tenant name/guid> \" And set context variable \" auth.client.id \" to \" <client id> \" And set context variable \" auth.client.secret \" to \" <client secret> \" And set context variable \" auth.client.resource \" to \" <resource url/guid> \"","title":"Client secret"},{"location":"framework/usage/load-users/rest-api/#username-and-password","text":"auth.user.redirect_uri needs to correspond to the endpoint that the client secret is registrered for. Given a user of type \" RestApi \" load testing \" https://api.example.com \" And set context variable \" auth.client.id \" to \" <client id> \" And set context variable \" auth.user.username \" to \" alice@example.onmicrosoft.com \" And set context variable \" auth.user.password \" to \" HemL1gaArn3! \" And set context variable \" auth.user.redirect_uri \" to \" /app-registrered-redirect-uri \"","title":"Username and password"},{"location":"framework/usage/load-users/secure-file-transfer-protocol/","text":"grizzly.users.sftp Communicates with Secure File Transport Protocol. Warning : Both local and remote files will be overwritten if they already exists. Downloaded files will be stored in requests/download . Request methods Supports the following request methods: put get Format Format of host is the following: sftp://<host>[:<port>] Examples Example of how to use it in a scenario: Given a user of type \" Sftp \" load testing \" sftp://sftp.example.com \" And set context variable \" auth.username \" to \" bob \" And set context variable \" auth.password \" to \" great-scott-42-file-bar \" Then put request \" test/blob.file \" to endpoint \" /pub/blobs \" Then get request from endpoint \" /pub/blobs/blob.file \"","title":"Secure File Transfer Protocol"},{"location":"framework/usage/load-users/secure-file-transfer-protocol/#grizzlyuserssftp","text":"Communicates with Secure File Transport Protocol. Warning : Both local and remote files will be overwritten if they already exists. Downloaded files will be stored in requests/download .","title":"grizzly.users.sftp"},{"location":"framework/usage/load-users/secure-file-transfer-protocol/#request-methods","text":"Supports the following request methods: put get","title":"Request methods"},{"location":"framework/usage/load-users/secure-file-transfer-protocol/#format","text":"Format of host is the following: sftp://<host>[:<port>]","title":"Format"},{"location":"framework/usage/load-users/secure-file-transfer-protocol/#examples","text":"Example of how to use it in a scenario: Given a user of type \" Sftp \" load testing \" sftp://sftp.example.com \" And set context variable \" auth.username \" to \" bob \" And set context variable \" auth.password \" to \" great-scott-42-file-bar \" Then put request \" test/blob.file \" to endpoint \" /pub/blobs \" Then get request from endpoint \" /pub/blobs/blob.file \"","title":"Examples"},{"location":"framework/usage/load-users/service-bus/","text":"grizzly.users.servicebus Send and receive messages on Azure Service Bus queues and topics. Note : If message.wait is not set, azure.servicebus will wait until there is a message available, and hence block the scenario. Warning : Do not use expression to filter messages unless you do not care about the messages that does not match the expression. If you do care about them, you should setup a subscription to do the filtering in Azure. User is based on azure.servicebus for communicating with Azure Service Bus. But creating a connection and session towards a queue or a topic is a costly operation, and caching of the session was causing problems with gevent due to the sockets blocking and hence locust/grizzly was blocking when finished. To get around this, the user implementation communicates with a stand-alone process via zmq, which in turn communicates with Azure Service Bus. async-messaged starts automagically when a scenario uses the ServiceBusUser . Request methods Supports the following request methods: send receive Format Format of host is the following: [Endpoint=]sb://<hostname>/;SharedAccessKeyName=<shared key name>;SharedAccessKey=<shared key> endpoint in the request must have the prefix queue: or topic: followed by the name of the targeted type. When receiving messages from a topic, the argument subscription: is mandatory. The format of endpoint is: [queue|topic]:<endpoint name>[, subscription:<subscription name>][, expression:<expression>] Where <expression> can be a XPath or jsonpath expression, depending on the specified content type. This argument is only allowed when receiving messages. See example below. Examples Example of how to use it in a scenario: Given a user of type \" ServiceBus \" load testing \" sb://sb.example.com/;SharedAccessKeyName=authorization-key;SharedAccessKey=c2VjcmV0LXN0dWZm \" And set context variable \" message.wait \" to \" 5 \" Then send request \" queue-send \" to endpoint \" queue:shared-queue \" Then send request \" topic-send \" to endpoint \" topic:shared-topic \" Then receive request \" queue-recv \" from endpoint \" queue:shared-queue \" Then receive request \" topic-recv \" from endpoint \" topic:shared-topic, subscription:my-subscription \" Get message with expression When specifying an expression, the messages on the endpoint is first peeked on. If any message matches the expression, it is later consumed from the endpoint. If no matching messages was found when peeking, it is repeated again after a slight delay, up until the specified message.wait seconds has elapsed. To use expressions, a content type must be specified for the request, e.g. application/xml . Given a user of type \" ServiceBus \" load testing \" sb://sb.example.com/;SharedAccessKeyName=authorization-key;SharedAccessKey=c2VjcmV0LXN0dWZm \" And set context variable \" message.wait \" to \" 5 \" Then receive request \" queue-recv \" from endpoint \" queue:shared-queue, expression:$.document[?(@.name=='TPM report')].id \" And set response content type to \" application/json \" Then receive request \" topic-recv \" from endpoint \" topic:shared-topic, subscription:my-subscription, expression:/documents/document[@name='TPM Report']/id/text() \" And set response content type to \" application/xml \"","title":"Service Bus"},{"location":"framework/usage/load-users/service-bus/#grizzlyusersservicebus","text":"Send and receive messages on Azure Service Bus queues and topics. Note : If message.wait is not set, azure.servicebus will wait until there is a message available, and hence block the scenario. Warning : Do not use expression to filter messages unless you do not care about the messages that does not match the expression. If you do care about them, you should setup a subscription to do the filtering in Azure. User is based on azure.servicebus for communicating with Azure Service Bus. But creating a connection and session towards a queue or a topic is a costly operation, and caching of the session was causing problems with gevent due to the sockets blocking and hence locust/grizzly was blocking when finished. To get around this, the user implementation communicates with a stand-alone process via zmq, which in turn communicates with Azure Service Bus. async-messaged starts automagically when a scenario uses the ServiceBusUser .","title":"grizzly.users.servicebus"},{"location":"framework/usage/load-users/service-bus/#request-methods","text":"Supports the following request methods: send receive","title":"Request methods"},{"location":"framework/usage/load-users/service-bus/#format","text":"Format of host is the following: [Endpoint=]sb://<hostname>/;SharedAccessKeyName=<shared key name>;SharedAccessKey=<shared key> endpoint in the request must have the prefix queue: or topic: followed by the name of the targeted type. When receiving messages from a topic, the argument subscription: is mandatory. The format of endpoint is: [queue|topic]:<endpoint name>[, subscription:<subscription name>][, expression:<expression>] Where <expression> can be a XPath or jsonpath expression, depending on the specified content type. This argument is only allowed when receiving messages. See example below.","title":"Format"},{"location":"framework/usage/load-users/service-bus/#examples","text":"Example of how to use it in a scenario: Given a user of type \" ServiceBus \" load testing \" sb://sb.example.com/;SharedAccessKeyName=authorization-key;SharedAccessKey=c2VjcmV0LXN0dWZm \" And set context variable \" message.wait \" to \" 5 \" Then send request \" queue-send \" to endpoint \" queue:shared-queue \" Then send request \" topic-send \" to endpoint \" topic:shared-topic \" Then receive request \" queue-recv \" from endpoint \" queue:shared-queue \" Then receive request \" topic-recv \" from endpoint \" topic:shared-topic, subscription:my-subscription \"","title":"Examples"},{"location":"framework/usage/load-users/service-bus/#get-message-with-expression","text":"When specifying an expression, the messages on the endpoint is first peeked on. If any message matches the expression, it is later consumed from the endpoint. If no matching messages was found when peeking, it is repeated again after a slight delay, up until the specified message.wait seconds has elapsed. To use expressions, a content type must be specified for the request, e.g. application/xml . Given a user of type \" ServiceBus \" load testing \" sb://sb.example.com/;SharedAccessKeyName=authorization-key;SharedAccessKey=c2VjcmV0LXN0dWZm \" And set context variable \" message.wait \" to \" 5 \" Then receive request \" queue-recv \" from endpoint \" queue:shared-queue, expression:$.document[?(@.name=='TPM report')].id \" And set response content type to \" application/json \" Then receive request \" topic-recv \" from endpoint \" topic:shared-topic, subscription:my-subscription, expression:/documents/document[@name='TPM Report']/id/text() \" And set response content type to \" application/xml \"","title":"Get message with expression"},{"location":"framework/usage/steps/background/setup/","text":"grizzly.steps.background.setup This module contains step implementations that configures the load test scenario with parameters applicable for all scenarios. step_setup_save_statistics @given ( u 'save statistics to \" {url} \"' ) def step_setup_save_statistics ( context : Context , url : str ) -> None Sets an URL where locust statistics should be sent. It has support for InfluxDB and Azure Application Insights endpoints. For InfluxDB the following format must be used: For Azure Application Insights the following format must be used: influxdb://[<username>:<password>@]<hostname>[:<port>]/<database>?TargetEnviroment=<target environment>[&Testplan=<test plan>] [&TargetEnvironment=<target environment>][&ProfileName=<profile name>][&Description=<description>] insights://?InstrumentationKey=<instrumentation key>&IngestionEndpoint=<ingestion endpoint>[&Testplan=<test plan>] insights://<ingestion endpoint>/?InstrumentationKey=<instrumentation key>[&Testplan=<test plan>] And save statistics to \" influxdb://grizzly:secret-password@influx.example.com/grizzly-statistics \" And save statistics to \" insights://?IngestionEndpoint=https://insights.example.com&Testplan=grizzly-statistics&InstrumentationKey=asdfasdfasdf= \" And save statistics to \" insights://insights.example.com/?Testplan=grizzly-statistics&InstrumentationKey=asdfasdfasdf= \" And save statistics to \" influxdb://$conf::statistics.username:$conf::statistics.password@influx.example.com/$conf::statistics.database \" Arguments : url str - URL for statistics endpoint step_setup_log_level @given ( u 'log level is \" {log_level} \"' ) def step_setup_log_level ( context : Context , log_level : str ) -> None Configure log level for grizzly . Default value is INFO , by changing to DEBUG there is more information what grizzly is doing behind the curtains. And log level is \" DEBUG \" Arguments : log_level str - allowed values INFO , DEBUG , WARNING och ERROR step_setup_run_time @given ( u 'run for maximum \" {timespan} \"' ) def step_setup_run_time ( context : Context , timespan : str ) -> None Configures the time period a headless test should run for. If available test data is infinite, the test will run forever if this step is not used. And run for maximum \" 1h \" Arguments : timespan str - description of how long the test should run for, e.g. 10s, 1h, 40m etc. step_setup_set_global_context_variable @given ( u 'set global context variable \" {variable} \" to \" {value} \"' ) def step_setup_set_global_context_variable ( context : Context , variable : str , value : str ) -> None Create a global variable in the context. Depending on which type of user a scenario is configured for, different variables are available. Check grizzly.users documentation for which context variables are available for each user. This step can be used if the feature file has multiple scenarios and all of them have the same context variables. Variable names can contain (one ore more) dot ( . ) or slash ( / ) to indicate that the variable is in a structure. All names will also be converted to lower case. E.g. token.url and token/URL results in: Space in variable names is also allowed and will then be translated to an underscore ( _ ) E.g. Client ID results in client_id . Data type of values will be guessed, if not explicitly specified by the type of variable used ( Atomic* ). E.g. the last two examples above will result in: { ' t oke n ' : { 'url' : '<value>' } } And set global context variable \" token.url \" to \" http://example.com/api/auth \" And set global context variable \" token/client_id \" to \" aaaa-bbbb-cccc-dddd \" And set global context variable \" token/client secret \" to \" aasdfasdfasdf== \" And set global context variable \" token.resource \" to \" 0000-aaaaaaa-1111-1111-1111 \" And set global context variable \" log_all_requests \" to \" True \" And set global context variable \" validate_certificates \" to \" False \" And set global context variable \" run_id \" to \" 13 \" { 'valida te _cer t i f ica tes ' : False , 'ru n _id' : 13 } Arguments : variable str - variable name, as used in templates value str - variable value","title":"Setup"},{"location":"framework/usage/steps/background/setup/#grizzlystepsbackgroundsetup","text":"This module contains step implementations that configures the load test scenario with parameters applicable for all scenarios.","title":"grizzly.steps.background.setup"},{"location":"framework/usage/steps/background/setup/#step_setup_save_statistics","text":"@given ( u 'save statistics to \" {url} \"' ) def step_setup_save_statistics ( context : Context , url : str ) -> None Sets an URL where locust statistics should be sent. It has support for InfluxDB and Azure Application Insights endpoints. For InfluxDB the following format must be used: For Azure Application Insights the following format must be used: influxdb://[<username>:<password>@]<hostname>[:<port>]/<database>?TargetEnviroment=<target environment>[&Testplan=<test plan>] [&TargetEnvironment=<target environment>][&ProfileName=<profile name>][&Description=<description>] insights://?InstrumentationKey=<instrumentation key>&IngestionEndpoint=<ingestion endpoint>[&Testplan=<test plan>] insights://<ingestion endpoint>/?InstrumentationKey=<instrumentation key>[&Testplan=<test plan>] And save statistics to \" influxdb://grizzly:secret-password@influx.example.com/grizzly-statistics \" And save statistics to \" insights://?IngestionEndpoint=https://insights.example.com&Testplan=grizzly-statistics&InstrumentationKey=asdfasdfasdf= \" And save statistics to \" insights://insights.example.com/?Testplan=grizzly-statistics&InstrumentationKey=asdfasdfasdf= \" And save statistics to \" influxdb://$conf::statistics.username:$conf::statistics.password@influx.example.com/$conf::statistics.database \" Arguments : url str - URL for statistics endpoint","title":"step_setup_save_statistics"},{"location":"framework/usage/steps/background/setup/#step_setup_log_level","text":"@given ( u 'log level is \" {log_level} \"' ) def step_setup_log_level ( context : Context , log_level : str ) -> None Configure log level for grizzly . Default value is INFO , by changing to DEBUG there is more information what grizzly is doing behind the curtains. And log level is \" DEBUG \" Arguments : log_level str - allowed values INFO , DEBUG , WARNING och ERROR","title":"step_setup_log_level"},{"location":"framework/usage/steps/background/setup/#step_setup_run_time","text":"@given ( u 'run for maximum \" {timespan} \"' ) def step_setup_run_time ( context : Context , timespan : str ) -> None Configures the time period a headless test should run for. If available test data is infinite, the test will run forever if this step is not used. And run for maximum \" 1h \" Arguments : timespan str - description of how long the test should run for, e.g. 10s, 1h, 40m etc.","title":"step_setup_run_time"},{"location":"framework/usage/steps/background/setup/#step_setup_set_global_context_variable","text":"@given ( u 'set global context variable \" {variable} \" to \" {value} \"' ) def step_setup_set_global_context_variable ( context : Context , variable : str , value : str ) -> None Create a global variable in the context. Depending on which type of user a scenario is configured for, different variables are available. Check grizzly.users documentation for which context variables are available for each user. This step can be used if the feature file has multiple scenarios and all of them have the same context variables. Variable names can contain (one ore more) dot ( . ) or slash ( / ) to indicate that the variable is in a structure. All names will also be converted to lower case. E.g. token.url and token/URL results in: Space in variable names is also allowed and will then be translated to an underscore ( _ ) E.g. Client ID results in client_id . Data type of values will be guessed, if not explicitly specified by the type of variable used ( Atomic* ). E.g. the last two examples above will result in: { ' t oke n ' : { 'url' : '<value>' } } And set global context variable \" token.url \" to \" http://example.com/api/auth \" And set global context variable \" token/client_id \" to \" aaaa-bbbb-cccc-dddd \" And set global context variable \" token/client secret \" to \" aasdfasdfasdf== \" And set global context variable \" token.resource \" to \" 0000-aaaaaaa-1111-1111-1111 \" And set global context variable \" log_all_requests \" to \" True \" And set global context variable \" validate_certificates \" to \" False \" And set global context variable \" run_id \" to \" 13 \" { 'valida te _cer t i f ica tes ' : False , 'ru n _id' : 13 } Arguments : variable str - variable name, as used in templates value str - variable value","title":"step_setup_set_global_context_variable"},{"location":"framework/usage/steps/background/shapes/","text":"grizzly.steps.background.shapes This module contains step implementations that describes the actual load all scenarios in a feature will generate. step_shapes_user_count @given ( u '\" {value} \" {grammar:UserGramaticalNumber}' ) def step_shapes_user_count ( context : Context , value : str , ** kwargs : Dict [ str , Any ]) -> None Set number of users that will generate load. Given \" 5 \" users Given \" 1 \" user Given \" {{ user_count }} \" Arguments : user_count int - Number of users locust should create step_shapes_spawn_rate @given ( u 'spawn rate is \" {value} \" {grammar:UserGramaticalNumber} per second' ) def step_shapes_spawn_rate ( context : Context , value : str , ** kwargs : Dict [ str , Any ]) -> None Set rate in which locust shall swarm new user instances. And spawn rate is \" 5 \" users per second And spawn rate is \" 1 \" user per second And spawn rate is \" 0.1 \" users per second Arguments : spawn_rate float - number of users per second","title":"Shapes"},{"location":"framework/usage/steps/background/shapes/#grizzlystepsbackgroundshapes","text":"This module contains step implementations that describes the actual load all scenarios in a feature will generate.","title":"grizzly.steps.background.shapes"},{"location":"framework/usage/steps/background/shapes/#step_shapes_user_count","text":"@given ( u '\" {value} \" {grammar:UserGramaticalNumber}' ) def step_shapes_user_count ( context : Context , value : str , ** kwargs : Dict [ str , Any ]) -> None Set number of users that will generate load. Given \" 5 \" users Given \" 1 \" user Given \" {{ user_count }} \" Arguments : user_count int - Number of users locust should create","title":"step_shapes_user_count"},{"location":"framework/usage/steps/background/shapes/#step_shapes_spawn_rate","text":"@given ( u 'spawn rate is \" {value} \" {grammar:UserGramaticalNumber} per second' ) def step_shapes_spawn_rate ( context : Context , value : str , ** kwargs : Dict [ str , Any ]) -> None Set rate in which locust shall swarm new user instances. And spawn rate is \" 5 \" users per second And spawn rate is \" 1 \" user per second And spawn rate is \" 0.1 \" users per second Arguments : spawn_rate float - number of users per second","title":"step_shapes_spawn_rate"},{"location":"framework/usage/steps/scenario/response/","text":"grizzly.steps.scenario.response This module contains step implementations that handles request responses. step_response_save_matches @then ( u 'save response {target:ResponseTarget} \" {expression} \" that matches \" {match_with} \" in variable \" {variable} \"' ) def step_response_save_matches ( context : Context , target : ResponseTarget , expression : str , match_with : str , variable : str ) -> None Save specified parts of a response, either from meta data (header) or payload (body), in a variable. With this step it is possible to change variable values and as such use values from a response later on in the load test. This step will fail if the specified expression has no match or more than one match. # only token is matched and saved in TOKEN, by using regexp match groups And value for variable \" TOKEN \" is \" none \" Then save response metadata \" $.Authentication \" that matches \" Bearer (.*)$ \" in variabel \" TOKEN \" # the whole value is saved, as long as Authentication starts with \"Bearer\" And value for variable \" HEADER_AUTHENTICATION \" is \" none \" Then save response metadata \" $.Authentication \" that matches \" ^Bearer .*$ \" in variable \" HEADER_AUTHENTICATION \" # only the numerical suffix is saved in the variable And value for variable \" AtomicIntegerIncrementer.measurermentId \" is \" 1 \" Then save response payload \" $.measurement.id \" that matches \" ^cpu([\\\\d]+)$ \" in \" measurementId \" # the whole value is saved, as long as the value starts with \"cpu\" And value for variable \" measurementId \" is \" 0 \" Then save response payload \" $.measurement.id \" that matches \" ^cpu[\\\\d]+$ \" in \" measurementId \" # xpath example And value for variable \" xmlMeasurementId \" is \" none \" Then save response payload \" //measurement[0]/id/text() | content_type=xml \" that matches \" ^cpu[\\\\d]+$ \" in \" xmlMeasurementId \" Arguments : target enum - \"metadata\" or \"payload\", depending on which part of the response should be used expression str - JSON path or XPath expression for finding the property match_with str - static value or a regular expression variable str - name of the already initialized variable to save the value in step_response_save @then ( u 'save response {target:ResponseTarget} \" {expression} \" in variable \" {variable} \"' ) def step_response_save ( context : Context , target : ResponseTarget , expression : str , variable : str ) -> None Save metadata (header) or payload (body) value from a response in a variable. This step is the same as step_response_save_matches if match_with is set to .* . With this step it is possible to change variable values and as such use values from a response later on in the load test. This step will fail if the specified expression has no match or more than one match. Then save response metadata \" $.Authentication \" in variable \" HEADER_AUTHENTICATION \" Then save response payload \" $.Result.ShipmentId \" in variable \" ShipmentId \" Then save response payload \" //measurement[0]/id/text() \" in \" xmlMeasurementId \" Arguments : target enum - \"metadata\" or \"payload\", depending on which part of the response should be used expression str - JSON path or XPath expression for finding the property variable str - name of the already initialized variable to save the value in step_response_validate @when ( u 'response {target:ResponseTarget} \" {expression} \" {condition:Condition} \" {match_with} \" fail request' ) def step_response_validate ( context : Context , target : ResponseTarget , expression : str , condition : bool , match_with : str ) -> None Fails the request based on the value of a response meta data (header) or payload (body). How the step will fail is based on step And ... on failure . If this step is not present, the default behaviour is to continue the scenario. And restart scenario on failure When response metadata \" $.['content-type'] \" is not \" .*application/json.* \" fail request When response metadata \" $.['x-test-command'] \" is \" abort \" fail request When response metadata \" $.Authentication \" is not \" Bearer .*$ \" fail request And stop user on failure When response payload \" $.measurement.id \" is not \" cpu[0-9]+ \" fail request When response payload \" $.success \" is \" false \" fail request When response payload \" /root/measurement[@id= \"cpu\" ]/success/text() \" is \" 'false' \" fail request Arguments : target enum - \"metadata\" or \"payload\", depending on which part of the response should be used expression str - JSON path or XPath expression for finding the property condition enum - \"is\" or \"is not\" depending on negative or postive matching match_with str - static value or a regular expression step_response_allow_status_codes @then ( u 'allow response status codes \" {status_list} \"' ) def step_response_allow_status_codes ( context : Context , status_list : str ) -> None Set allowed response status codes for the latest defined request in the scenario. By default 200 is the only allowed respoonse status code. By prefixing a code with minus ( - ), it will be removed from the list of allowed response status codes. Then get request with name \" test-get-1 \" from endpoint \" /api/test \" And allow response status \" 200,302 \" Then get request with name \" test-failed-get-2 \" from endpoint \" /api/non-existing \" And allow response status \" -200,404 \" Arguments : status_list str - comma separated list of integers step_response_allow_status_codes_table @then ( u 'allow response status codes' ) def step_response_allow_status_codes_table ( context : Context ) -> None Set allowed response status codes for the latest defined requests based on a data table. Specifies a comma separeated list of allowed return codes for the latest requests in a data table. By default 200 is the only allowed respoonse status code. By prefixing a code with minus ( - ), it will be removed from the list of allowed response status codes. Number of rows in the table specifies which of the latest defined requests the allowed response status codes should map to. The table must have the column header status . Then get request with name \" test-get-1 \" from endpoint \" /api/test \" Then get request with name \" test-get-2 \" from endpoint \" /api/test \" And allow response status | status | | 200, 302 | | 200,404 | Allowed response status codes for test-get-1 is now 200 and 302 , and for test-get-2 is now 200 and 404 . step_response_content_type @then ( u 'set response content type to \"{content_type:TransformerContentType}\"' ) def step_response_content_type ( context : Context , content_type : TransformerContentType ) -> None Set the content type of a response, instead of guessing it. This is applicable when there is a step_response_validate or step_response_save is included in the scenario, and is valid only for the latest defined request. And set response content type to \" json \" And set response content type to \" application/json \" And set response content type to \" xml \" And set response content type to \" application/xml \" And set response content type to \" plain \" And set response content type to \" text/plain \" Arguments : content_type TransformerContentType - expected content type of response","title":"Response"},{"location":"framework/usage/steps/scenario/response/#grizzlystepsscenarioresponse","text":"This module contains step implementations that handles request responses.","title":"grizzly.steps.scenario.response"},{"location":"framework/usage/steps/scenario/response/#step_response_save_matches","text":"@then ( u 'save response {target:ResponseTarget} \" {expression} \" that matches \" {match_with} \" in variable \" {variable} \"' ) def step_response_save_matches ( context : Context , target : ResponseTarget , expression : str , match_with : str , variable : str ) -> None Save specified parts of a response, either from meta data (header) or payload (body), in a variable. With this step it is possible to change variable values and as such use values from a response later on in the load test. This step will fail if the specified expression has no match or more than one match. # only token is matched and saved in TOKEN, by using regexp match groups And value for variable \" TOKEN \" is \" none \" Then save response metadata \" $.Authentication \" that matches \" Bearer (.*)$ \" in variabel \" TOKEN \" # the whole value is saved, as long as Authentication starts with \"Bearer\" And value for variable \" HEADER_AUTHENTICATION \" is \" none \" Then save response metadata \" $.Authentication \" that matches \" ^Bearer .*$ \" in variable \" HEADER_AUTHENTICATION \" # only the numerical suffix is saved in the variable And value for variable \" AtomicIntegerIncrementer.measurermentId \" is \" 1 \" Then save response payload \" $.measurement.id \" that matches \" ^cpu([\\\\d]+)$ \" in \" measurementId \" # the whole value is saved, as long as the value starts with \"cpu\" And value for variable \" measurementId \" is \" 0 \" Then save response payload \" $.measurement.id \" that matches \" ^cpu[\\\\d]+$ \" in \" measurementId \" # xpath example And value for variable \" xmlMeasurementId \" is \" none \" Then save response payload \" //measurement[0]/id/text() | content_type=xml \" that matches \" ^cpu[\\\\d]+$ \" in \" xmlMeasurementId \" Arguments : target enum - \"metadata\" or \"payload\", depending on which part of the response should be used expression str - JSON path or XPath expression for finding the property match_with str - static value or a regular expression variable str - name of the already initialized variable to save the value in","title":"step_response_save_matches"},{"location":"framework/usage/steps/scenario/response/#step_response_save","text":"@then ( u 'save response {target:ResponseTarget} \" {expression} \" in variable \" {variable} \"' ) def step_response_save ( context : Context , target : ResponseTarget , expression : str , variable : str ) -> None Save metadata (header) or payload (body) value from a response in a variable. This step is the same as step_response_save_matches if match_with is set to .* . With this step it is possible to change variable values and as such use values from a response later on in the load test. This step will fail if the specified expression has no match or more than one match. Then save response metadata \" $.Authentication \" in variable \" HEADER_AUTHENTICATION \" Then save response payload \" $.Result.ShipmentId \" in variable \" ShipmentId \" Then save response payload \" //measurement[0]/id/text() \" in \" xmlMeasurementId \" Arguments : target enum - \"metadata\" or \"payload\", depending on which part of the response should be used expression str - JSON path or XPath expression for finding the property variable str - name of the already initialized variable to save the value in","title":"step_response_save"},{"location":"framework/usage/steps/scenario/response/#step_response_validate","text":"@when ( u 'response {target:ResponseTarget} \" {expression} \" {condition:Condition} \" {match_with} \" fail request' ) def step_response_validate ( context : Context , target : ResponseTarget , expression : str , condition : bool , match_with : str ) -> None Fails the request based on the value of a response meta data (header) or payload (body). How the step will fail is based on step And ... on failure . If this step is not present, the default behaviour is to continue the scenario. And restart scenario on failure When response metadata \" $.['content-type'] \" is not \" .*application/json.* \" fail request When response metadata \" $.['x-test-command'] \" is \" abort \" fail request When response metadata \" $.Authentication \" is not \" Bearer .*$ \" fail request And stop user on failure When response payload \" $.measurement.id \" is not \" cpu[0-9]+ \" fail request When response payload \" $.success \" is \" false \" fail request When response payload \" /root/measurement[@id= \"cpu\" ]/success/text() \" is \" 'false' \" fail request Arguments : target enum - \"metadata\" or \"payload\", depending on which part of the response should be used expression str - JSON path or XPath expression for finding the property condition enum - \"is\" or \"is not\" depending on negative or postive matching match_with str - static value or a regular expression","title":"step_response_validate"},{"location":"framework/usage/steps/scenario/response/#step_response_allow_status_codes","text":"@then ( u 'allow response status codes \" {status_list} \"' ) def step_response_allow_status_codes ( context : Context , status_list : str ) -> None Set allowed response status codes for the latest defined request in the scenario. By default 200 is the only allowed respoonse status code. By prefixing a code with minus ( - ), it will be removed from the list of allowed response status codes. Then get request with name \" test-get-1 \" from endpoint \" /api/test \" And allow response status \" 200,302 \" Then get request with name \" test-failed-get-2 \" from endpoint \" /api/non-existing \" And allow response status \" -200,404 \" Arguments : status_list str - comma separated list of integers","title":"step_response_allow_status_codes"},{"location":"framework/usage/steps/scenario/response/#step_response_allow_status_codes_table","text":"@then ( u 'allow response status codes' ) def step_response_allow_status_codes_table ( context : Context ) -> None Set allowed response status codes for the latest defined requests based on a data table. Specifies a comma separeated list of allowed return codes for the latest requests in a data table. By default 200 is the only allowed respoonse status code. By prefixing a code with minus ( - ), it will be removed from the list of allowed response status codes. Number of rows in the table specifies which of the latest defined requests the allowed response status codes should map to. The table must have the column header status . Then get request with name \" test-get-1 \" from endpoint \" /api/test \" Then get request with name \" test-get-2 \" from endpoint \" /api/test \" And allow response status | status | | 200, 302 | | 200,404 | Allowed response status codes for test-get-1 is now 200 and 302 , and for test-get-2 is now 200 and 404 .","title":"step_response_allow_status_codes_table"},{"location":"framework/usage/steps/scenario/response/#step_response_content_type","text":"@then ( u 'set response content type to \"{content_type:TransformerContentType}\"' ) def step_response_content_type ( context : Context , content_type : TransformerContentType ) -> None Set the content type of a response, instead of guessing it. This is applicable when there is a step_response_validate or step_response_save is included in the scenario, and is valid only for the latest defined request. And set response content type to \" json \" And set response content type to \" application/json \" And set response content type to \" xml \" And set response content type to \" application/xml \" And set response content type to \" plain \" And set response content type to \" text/plain \" Arguments : content_type TransformerContentType - expected content type of response","title":"step_response_content_type"},{"location":"framework/usage/steps/scenario/results/","text":"grizzly.steps.scenario.results This module contains step implementations that validates the response results for all requests in a scenario. step_results_fail_ratio @when ( u 'fail ratio is greater than \" {fail_ratio:d} \" % f ail scenario' ) def step_results_fail_ratio ( context : Context , fail_ratio : int ) -> None Set how many percentages of requests that are allowed to fail before the whole scenario will be set as failed. This step cannot be used in combination with step_setup_stop_user_on_failure or step_setup_restart_scenario_on_failure . Default behavior is not to validate the result for a scenario based on failed requests. When fail ratio is greater than \" 8 \"% fail scenario Arguments : fail_ratio int - percentage of requests that are allowed to fail step_results_avg_response_time @when ( u 'average response time is greater than \" {avg_response_time:d} \" milliseconds fail scenario' ) def step_results_avg_response_time ( context : Context , avg_response_time : int ) -> None Set the average response time (milliseconds) that all requests in a scenario must be below for it to pass. Default behavior is not to validate the result for a scenario based on average response time. When average response time is greater than \" 200 \" milliseconds fail scenario Arguments : avg_response_time int - allowed average response time in milliseconds step_results_response_time_percentile @when ( u 'response time percentile \" {percentile:d} \" % i s greater than \" {response_time:d} \" milliseconds fail scenario' ) def step_results_response_time_percentile ( context : Context , percentile : float , response_time : int ) -> None Set the response time that a specified percentile of the requests needs to be below for the scenario to pass. Default behavior is not to validate the result for a scenario based on percetile response times. When response time percentile \" 95 \"% is greater than \" 200 \" milliseconds fail scenario Arguments : percentile int - percentile to validate (1-100) response_time int - response time in milliseconds","title":"Results"},{"location":"framework/usage/steps/scenario/results/#grizzlystepsscenarioresults","text":"This module contains step implementations that validates the response results for all requests in a scenario.","title":"grizzly.steps.scenario.results"},{"location":"framework/usage/steps/scenario/results/#step_results_fail_ratio","text":"@when ( u 'fail ratio is greater than \" {fail_ratio:d} \" % f ail scenario' ) def step_results_fail_ratio ( context : Context , fail_ratio : int ) -> None Set how many percentages of requests that are allowed to fail before the whole scenario will be set as failed. This step cannot be used in combination with step_setup_stop_user_on_failure or step_setup_restart_scenario_on_failure . Default behavior is not to validate the result for a scenario based on failed requests. When fail ratio is greater than \" 8 \"% fail scenario Arguments : fail_ratio int - percentage of requests that are allowed to fail","title":"step_results_fail_ratio"},{"location":"framework/usage/steps/scenario/results/#step_results_avg_response_time","text":"@when ( u 'average response time is greater than \" {avg_response_time:d} \" milliseconds fail scenario' ) def step_results_avg_response_time ( context : Context , avg_response_time : int ) -> None Set the average response time (milliseconds) that all requests in a scenario must be below for it to pass. Default behavior is not to validate the result for a scenario based on average response time. When average response time is greater than \" 200 \" milliseconds fail scenario Arguments : avg_response_time int - allowed average response time in milliseconds","title":"step_results_avg_response_time"},{"location":"framework/usage/steps/scenario/results/#step_results_response_time_percentile","text":"@when ( u 'response time percentile \" {percentile:d} \" % i s greater than \" {response_time:d} \" milliseconds fail scenario' ) def step_results_response_time_percentile ( context : Context , percentile : float , response_time : int ) -> None Set the response time that a specified percentile of the requests needs to be below for the scenario to pass. Default behavior is not to validate the result for a scenario based on percetile response times. When response time percentile \" 95 \"% is greater than \" 200 \" milliseconds fail scenario Arguments : percentile int - percentile to validate (1-100) response_time int - response time in milliseconds","title":"step_results_response_time_percentile"},{"location":"framework/usage/steps/scenario/setup/","text":"grizzly.steps.scenario.setup This module contains step implementations that setup the load test scenario with parameters that is going to be used in the scenario they are defined in. step_setup_set_context_variable @given ( u 'set context variable \" {variable} \" to \" {value} \"' ) def step_setup_set_context_variable ( context : Context , variable : str , value : str ) -> None Set a variable in the scenario context. Variable name can contain (one or more) dot ( . ) or slash ( / ) to indicate that the variable has a nested structure. E.g. token.url and token/url results in: It is also possible to have spaces in a variable name, they will then be replaced with underscore ( _ ), and name will be converted to lowercase. E.g. Client ID results in client_id { ' t oke n ' : { 'url' : '<value>' } } And set context variable \" token.url \" to \" https://example.com/api/auth \" And set context variable \" token/client_id \" to \" aaaa-bbbb-cccc-dddd \" And set context variable \" token/client secret \" to \" aasdfasdfasdf== \" And set context variable \" token.resource \" to \" 0000-aaaaaaa-1111-1111-1111 \" And set context variable \" log_all_requests \" to \" True \" And set context variable \" validate_certificates \" to \" False \" Arguments : variable str - name, can contain . and / value str - value, data type will be guessed and casted step_setup_iterations @given ( u 'repeat for \" {value} \" {iteration_number:IterationGramaticalNumber}' ) def step_setup_iterations ( context : Context , value : str , iteration_number : str ) -> None Set how many iterations of the requests in the scenario should execute. Default value is 1 . A value of 0 means to run until all test data is consumed, or that the (optional) specified runtime for the scenario is reached. And repeat for \" 10 \" iterations And repeat for \" 1 \" iteration And value for variable \" leveranser \" is \" 100 \" And repeat for \" {{ leveranser * 0.25 }} \" iterations Arguments : iterations int - number of iterations of the scenario step_setup_variable_value @given ( u 'value for variable \" {name} \" is \" {value} \"' ) def step_setup_variable_value ( context : Context , name : str , value : str ) -> None Initialize a variable. Use this step to initialize a variable that should have the same [start] value for every run of the scenario. Data type for the value of the variable is based on the type of variable. If the variable is an \" Atomic* \"-variable then the value needs to match the format and type that the variable has implemented. If it is a non \" Atomic* \"-variable grizzly will try to guess the data type. E.g.: * \"10\" becomes int * \"1.0\" becomes float * \"True\" becomes bool * everything else becomes str It is possible to set the value of a variable based on another variable, which can be usable if you have a variable in multiple scenarios which all should have the same initial value. And value for variable \" HelloWorld \" is \" default \" Feature: Background: And ask for value of variable \" messageID \" Scenario: And value for variable \" AtomicIntegerIncrementer.mid1 \" is \" {{ messageID }} \" Arguments : name str - variable name value Any - initial value step_setup_set_variable_alias @given ( u 'set alias \" {alias} \" for variable \" {variable} \"' ) def step_setup_set_variable_alias ( context : Context , alias : str , variable : str ) -> None Create an alias for a variable that points to another structure in the context. This is useful if you have test data that somehow should change the behavior for a user, e.g. username and password. Assumed that the file users.csv contains the columns username and password ; without the alias step it would look like the following structure in the context: With the alias step it will be transformed to this: Variables in payload templates are not allowed to have an alias. And value for variable \" AtomicCsvRow.users \" is \" users.csv | repeat=True \" And set alias \" auth.user.username \" for variable \" AtomicCsvRow.users.username \" And set alias \" auth.user.password \" for variable \" AtomicCsvRow.users.password \" { \"variables\" : { \"AtomicCsvRow\" : { \"users\" : { \"username\" : \"username\" , \"password\" : \"password\" } } } } { \"auth\" : { \"user\" : { \"username\" : \"username\" , \"password\" : \"password\" } } } Arguments : alias str - which node in the context that should get the value of variable variable str - an already initialized variable that should be renamed step_setup_log_all_requests @given ( u 'log all requests' ) def step_setup_log_all_requests ( context : Context ) -> None Set if all requests should be logged to a file. By default only failed requests (and responses) will be logged. And log all requests step_setup_stop_user_on_failure @given ( u 'stop user on failure' ) def step_setup_stop_user_on_failure ( context : Context ) -> None Stop user if a request fails. Default behavior is to continue the scenario if a request fails. And stop user on failure step_setup_restart_scenario_on_failure @given ( u 'restart scenario on failure' ) def step_setup_restart_scenario_on_failure ( context : Context ) -> None Restart scenario, from first task, if a request fails. Default behavior is to continue the scenario if a request fails. And restart scenario on failure step_setup_metadata @given ( u 'metadata \" {key} \" is \" {value} \"' ) def step_setup_metadata ( context : Context , key : str , value : str ) -> None Set a metadata (header) value to be used by the user when sending requests. ```gherkin And metadata \"Content-Type\" is \"application/xml\" And metadata \"Ocp-Apim-Subscription-Key\" is \"9asdf00asdf00adsf034\"","title":"Setup"},{"location":"framework/usage/steps/scenario/setup/#grizzlystepsscenariosetup","text":"This module contains step implementations that setup the load test scenario with parameters that is going to be used in the scenario they are defined in.","title":"grizzly.steps.scenario.setup"},{"location":"framework/usage/steps/scenario/setup/#step_setup_set_context_variable","text":"@given ( u 'set context variable \" {variable} \" to \" {value} \"' ) def step_setup_set_context_variable ( context : Context , variable : str , value : str ) -> None Set a variable in the scenario context. Variable name can contain (one or more) dot ( . ) or slash ( / ) to indicate that the variable has a nested structure. E.g. token.url and token/url results in: It is also possible to have spaces in a variable name, they will then be replaced with underscore ( _ ), and name will be converted to lowercase. E.g. Client ID results in client_id { ' t oke n ' : { 'url' : '<value>' } } And set context variable \" token.url \" to \" https://example.com/api/auth \" And set context variable \" token/client_id \" to \" aaaa-bbbb-cccc-dddd \" And set context variable \" token/client secret \" to \" aasdfasdfasdf== \" And set context variable \" token.resource \" to \" 0000-aaaaaaa-1111-1111-1111 \" And set context variable \" log_all_requests \" to \" True \" And set context variable \" validate_certificates \" to \" False \" Arguments : variable str - name, can contain . and / value str - value, data type will be guessed and casted","title":"step_setup_set_context_variable"},{"location":"framework/usage/steps/scenario/setup/#step_setup_iterations","text":"@given ( u 'repeat for \" {value} \" {iteration_number:IterationGramaticalNumber}' ) def step_setup_iterations ( context : Context , value : str , iteration_number : str ) -> None Set how many iterations of the requests in the scenario should execute. Default value is 1 . A value of 0 means to run until all test data is consumed, or that the (optional) specified runtime for the scenario is reached. And repeat for \" 10 \" iterations And repeat for \" 1 \" iteration And value for variable \" leveranser \" is \" 100 \" And repeat for \" {{ leveranser * 0.25 }} \" iterations Arguments : iterations int - number of iterations of the scenario","title":"step_setup_iterations"},{"location":"framework/usage/steps/scenario/setup/#step_setup_variable_value","text":"@given ( u 'value for variable \" {name} \" is \" {value} \"' ) def step_setup_variable_value ( context : Context , name : str , value : str ) -> None Initialize a variable. Use this step to initialize a variable that should have the same [start] value for every run of the scenario. Data type for the value of the variable is based on the type of variable. If the variable is an \" Atomic* \"-variable then the value needs to match the format and type that the variable has implemented. If it is a non \" Atomic* \"-variable grizzly will try to guess the data type. E.g.: * \"10\" becomes int * \"1.0\" becomes float * \"True\" becomes bool * everything else becomes str It is possible to set the value of a variable based on another variable, which can be usable if you have a variable in multiple scenarios which all should have the same initial value. And value for variable \" HelloWorld \" is \" default \" Feature: Background: And ask for value of variable \" messageID \" Scenario: And value for variable \" AtomicIntegerIncrementer.mid1 \" is \" {{ messageID }} \" Arguments : name str - variable name value Any - initial value","title":"step_setup_variable_value"},{"location":"framework/usage/steps/scenario/setup/#step_setup_set_variable_alias","text":"@given ( u 'set alias \" {alias} \" for variable \" {variable} \"' ) def step_setup_set_variable_alias ( context : Context , alias : str , variable : str ) -> None Create an alias for a variable that points to another structure in the context. This is useful if you have test data that somehow should change the behavior for a user, e.g. username and password. Assumed that the file users.csv contains the columns username and password ; without the alias step it would look like the following structure in the context: With the alias step it will be transformed to this: Variables in payload templates are not allowed to have an alias. And value for variable \" AtomicCsvRow.users \" is \" users.csv | repeat=True \" And set alias \" auth.user.username \" for variable \" AtomicCsvRow.users.username \" And set alias \" auth.user.password \" for variable \" AtomicCsvRow.users.password \" { \"variables\" : { \"AtomicCsvRow\" : { \"users\" : { \"username\" : \"username\" , \"password\" : \"password\" } } } } { \"auth\" : { \"user\" : { \"username\" : \"username\" , \"password\" : \"password\" } } } Arguments : alias str - which node in the context that should get the value of variable variable str - an already initialized variable that should be renamed","title":"step_setup_set_variable_alias"},{"location":"framework/usage/steps/scenario/setup/#step_setup_log_all_requests","text":"@given ( u 'log all requests' ) def step_setup_log_all_requests ( context : Context ) -> None Set if all requests should be logged to a file. By default only failed requests (and responses) will be logged. And log all requests","title":"step_setup_log_all_requests"},{"location":"framework/usage/steps/scenario/setup/#step_setup_stop_user_on_failure","text":"@given ( u 'stop user on failure' ) def step_setup_stop_user_on_failure ( context : Context ) -> None Stop user if a request fails. Default behavior is to continue the scenario if a request fails. And stop user on failure","title":"step_setup_stop_user_on_failure"},{"location":"framework/usage/steps/scenario/setup/#step_setup_restart_scenario_on_failure","text":"@given ( u 'restart scenario on failure' ) def step_setup_restart_scenario_on_failure ( context : Context ) -> None Restart scenario, from first task, if a request fails. Default behavior is to continue the scenario if a request fails. And restart scenario on failure","title":"step_setup_restart_scenario_on_failure"},{"location":"framework/usage/steps/scenario/setup/#step_setup_metadata","text":"@given ( u 'metadata \" {key} \" is \" {value} \"' ) def step_setup_metadata ( context : Context , key : str , value : str ) -> None Set a metadata (header) value to be used by the user when sending requests. ```gherkin And metadata \"Content-Type\" is \"application/xml\" And metadata \"Ocp-Apim-Subscription-Key\" is \"9asdf00asdf00adsf034\"","title":"step_setup_metadata"},{"location":"framework/usage/steps/scenario/tasks/","text":"grizzly.steps.scenario.tasks This module contains step implementations that describes requests sent by user_class_name targeting host . step_task_request_with_name_to_endpoint_until @then ( u '{method:Method} request with name \" {name} \" from endpoint \" {endpoint} \" until \" {condition} \"' ) def step_task_request_with_name_to_endpoint_until ( context : Context , method : RequestMethod , name : str , endpoint : str , condition : str ) -> None Creates a named request to an endpoint on host and repeat it until condition is true in the response. content_type will be removed from the actual endpoint value. condition is a JSON- or Xpath expression, that also has support for \"grizzly style\" arguments: Endpoint Arguments : retries (int): maximum number of times to repeat the request if condition is not met (default 3 ) wait (float): number of seconds to wait between retries (default 1.0 ) Then get request with name \" test-get \" from endpoint \" /api/test | content_type=json \" until \" $.`this`[?success==true] \" Then receive request with name \" test-receive \" from endpoint \" queue:receive-queue | content_type=xml \" until \" /header/success[. == 'True'] \" Arguments : method RequestMethod - type of request name str - name of the requests in logs, can contain variables direction RequestDirection - one of to or from depending on the value of method endpoint str - URI relative to host in the scenario, can contain variables and in certain cases user_class_name specific parameters step_task_request_text_with_name_to_endpoint @then ( u '{method:Method} request with name \" {name} \" {direction:Direction} endpoint \" {endpoint} \"' ) def step_task_request_text_with_name_to_endpoint ( context : Context , method : RequestMethod , name : str , direction : RequestDirection , endpoint : str ) -> None Creates a named request to an endpoint on host , where optional payload is defined directly in the feature file. If method in the expression is get or receive ; the direction must be from . If method in the expression is post , pust , or send ; the direction must be to , and payload defined in the feature file. endpoint has support for setting response content type as a parameter: content_type will be removed from the actual endpoint value. Then post request with name \" test-post \" to endpoint \" /api/test \" \"\"\" { \"test\": \"hello world\" } \"\"\" Then put request with name \" test-put \" to endpoint \" /api/test \" \"\"\" { \"test\": \"hello world\" } \"\"\" Then get request with name \" test-get \" from endpoint \" /api/test \" Then send request with name \" test-send \" to endpoint \" queue:receive-queue \" \"\"\" { \"value\": \"do something\" } \"\"\" Then receive request with name \" test-receive \" from endpoint \" queue:receive-queue \" Then receive request with name \" test-receive \" from endpoint \" queue:receive-queue | content_type=xml \" # same as Then receive request with name \" test-receive \" from endpoint \" queue:receive-queue \" And set response content type to \" xml \" Arguments : method RequestMethod - type of request name str - name of the requests in logs, can contain variables direction RequestDirection - one of to or from depending on the value of method endpoint str - URI relative to host in the scenario, can contain variables and in certain cases user_class_name specific parameters step_task_request_file_with_name_endpoint @then ( u '{method:Method} request \" {source} \" with name \" {name} \" to endpoint \" {endpoint} \"' ) def step_task_request_file_with_name_endpoint ( context : Context , method : RequestMethod , source : str , name : str , endpoint : str ) -> None Creates a named request to an endpoint on host , where the payload is defined in a template file. endpoint has support for setting response content type as a parameter: content_type will be removed from the actual endpoint value. Then send request \" test/request.j2.json \" with name \" test-send \" to endpoint \" queue:receive-queue \" Then post request \" test/request.j2.json \" with name \" test-post \" to endpoint \" /api/test \" Then put request \" test/request.j2.json \" with name \" test-put \" to endpoint \" /api/test \" Then put request \" test/request.j2.json \" with name \" test-put \" to endpoint \" /api/test | content_type=json \" # same as Then put request \" test/request.j2.json \" with name \" test-put \" to endpoint \" /api/test \" And set response content type to \" application/json \" Arguments : method RequestMethod - type of request source str - path to a template file relative to the directory requests/ , which must exist in the directory the feature file is located name str - name of the requests in logs, can contain variables endpoint str - URI relative to host in the scenario, can contain variables and in certain cases user_class_name specific parameters step_task_request_file_with_name @then ( u '{method:Method} request \" {source} \" with name \" {name} \"' ) def step_task_request_file_with_name ( context : Context , method : RequestMethod , source : str , name : str ) -> None Creates a named request to the same endpoint as previous request, where the payload is defined in a template file. endpoint has support for setting response content type as a parameter: content_type will be removed from the actual endpoint value. Then post request \" test/request1.j2.json \" with name \" test-post1 \" to endpoint \" /api/test \" Then post request \" test/request2.j2.json \" with name \" test-post2 \" # same as Then post request \" test/request1.j2.json \" with name \" test-post1 \" to endpoint \" /api/test \" Then post request \" test/request2.j2.json \" with name \" test-post2 \" to endpoint \" /api/test \" Then post request \" test/request1.j2.json \" with name \" test-post1 \" to endpoint \" /api/test | content_type=json \" # same as Then post request \" test/request1.j2.json \" with name \" test-post1 \" to endpoint \" /api/test \" And set response content type to \" application/json \" Arguments : method RequestMethod - type of request source str - path to a template file relative to the directory requests/ , which must exist in the directory the feature file is located name str - name of the requests in logs, can contain variables step_task_request_text_with_name @then ( u '{method:Method} request with name \" {name} \"' ) def step_task_request_text_with_name ( context : Context , method : RequestMethod , name : str ) -> None Creates a named request to the same endpoint as previous request, where optional payload is defined directly in the feature file. If method in the expression is post , put or send the payload in the request must be defined directly in the feature file after the step. This step is useful if method and endpoint are the same as previous request, but the payload should be different. Then post request with name \" test-post-1 \" to endpoint \" /api/test \" \"\"\" { \"value\": \"hello world!\" } \"\"\" Then post request with name \" test-post-2 \" \"\"\" { \"value\": \"i have good news!\" } \"\"\" # same as Then post request with name \" test-post-1 \" to endpoint \" /api/test \" \"\"\" { \"value\": \"hello world!\" } \"\"\" Then post request with name \" test-post-2 \" to endpoint \" /api/test \" \"\"\" { \"value\": \"i have good news!\" } \"\"\" Then get request with name \" test-get-1 \" from endpoint \" /api/test \" Then get request with name \" test-get-2 \" # same as Then get request with name \" test-get-1 \" from endpoint \" /api/test \" Then get request with name \" test-get-2 \" from endpoint \" /api/test \" Arguments : method RequestMethod - type of request name str - name of the requests in logs, can contain variables step_task_wait_seconds @then ( u 'wait for \" {wait_time:f} \" seconds' ) def step_task_wait_seconds ( context : Context , wait_time : float ) -> None Create an explicit wait (task) in the scenario. The scenario will wait the time specified (seconds) on top of what has been defined in step_setup_wait_time . Above combinations of steps will result in a wait time between 3 and 4 seconds for the first request that is defined after the Then wait for... -step. And wait time inbetween requests is random between \" 1.5 \" and \" 2.5 \" seconds ... Then wait for \" 1.5 \" seconds Arguments : wait_time float - wait time in seconds step_task_print_message @then ( u 'print message \" {message} \"' ) def step_task_print_message ( context : Context , message : str ) -> None Print a message in the scenario. Useful for visualizing values of variables. The message can be a jinja template, and any variables will be rendered at the time the task executes. And print message \" context_variable='{{ context_variable }}' Arguments : message str - message to print step_task_transform @then ( u 'parse \" {content} \" as \"{content_type:ContentType}\" and save value of \" {expression} \" in variable \" {variable} \"' ) def step_task_transform ( context : Context , content : str , content_type : TransformerContentType , expression : str , variable : str ) -> None Parse (part of) a JSON object or a XML document and extract a specific value from that and save into a variable. This can be especially useful in combination with AtomicMessageQueue variable. And value for variable \" document_id \" is \" None \" And value for variable \" document_title \" is \" None \" And value for variable \" document \" is \" {\\ \"document\\\" : {\\ \"id\\\" : \\ \"DOCUMENT_ 8843 - 1 \\\" , \\ \"title\\\" : \\ \"TPM Report 2021 \\\" }} \" ... Then parse \" {{ document }} \" as \" json \" and save value of \" $.document.id \" in variable \" document_id \" Then parse \" {{ document }} \" as \" json \" and save value of \" $.document.title \" in variable \" document_title \" Arguments : contents str - contents to parse, supports templating or a static string content_type TransformerContentType - MIME type of contents expression str - JSON or XPath expression for specific value in contents variable str - name of variable to save value to, must have been initialized step_task_client_get_endpoint @then ( u 'get \" {endpoint} \" with name \" {name} \" and save response in \" {variable} \"' ) def step_task_client_get_endpoint ( context : Context , endpoint : str , name : str , variable : str ) -> None Get information from another host or endpoint than the scenario is load testing and save the response in a variable. Task implementations are found in grizzly.task.clients and each implementation is looked up through the scheme in the specified endpoint. If the endpoint is a variable, one have to manually specify the endpoint scheme even though the resolved variable contains the scheme. In this case the manually specified scheme will be removed to the endpoint actually used by the task. Then get \" https://www.example.org/example.json \" with name \" example-1 \" and save response in \" example_openapi \" Then get \" http://{{ endpoint }} \" with name \" example-2 \" and save response in \" endpoint_result \" Arguments : endpoint str - information about where to get information, see the specific getter task implementations for more information name str - name of the request, used in request statistics variable str - name of, initialized, variable where response will be saved in step_task_client_put_endpoint_file_destination @then ( u 'put \" {source} \" to \" {endpoint} \" with name \" {name} \" as \" {destination} \"' ) def step_task_client_put_endpoint_file_destination ( context : Context , source : str , endpoint : str , name : str , destination : str ) -> None Put information to another host or endpoint than the scenario is load testing, source being a file. Task implementations are found in grizzly.task.clients and each implementation is looked up through the scheme in the specified endpoint. If the endpoint is a variable, one have to manually specify the endpoint scheme even though the resolved variable contains the scheme. In this case the manually specified scheme will be removed to the endpoint actually used by the task. Then put \" test-file.json \" to \" bs://my-storage?AccountKey=aaaabbb=&Container=my-container \" with name \" upload-file \" as \" uploaded-test-file.json \" Arguments : source str - relative path to file in feature/requests , supports templating endpoint str - information about where to get information, see the specific getter task implementations for more information name str - name of the request, used in request statistics destination str - name of source on the destination step_task_client_put_endpoint_file @then ( u 'put \" {source} \" to \" {endpoint} \" with name \" {name} \"' ) def step_task_client_put_endpoint_file ( context : Context , source : str , endpoint : str , name : str ) -> None Put information to another host or endpoint than the scenario is load testing, source being a file. Task implementations are found in grizzly.task.clients and each implementation is looked up through the scheme in the specified endpoint. If the endpoint is a variable, one have to manually specify the endpoint scheme even though the resolved variable contains the scheme. In this case the manually specified scheme will be removed to the endpoint actually used by the task. Then put \" test-file.json \" to \" bs://my-storage?AccountKey=aaaabbb=&Container=my-container \" with name \" upload-file \" Arguments : source str - relative path to file in feature/requests , supports templating endpoint str - information about where to get information, see the specific getter task implementations for more information name str - name of the request, used in request statistics step_task_date @then ( u 'parse date \" {value} \" and save in variable \" {variable} \"' ) def step_task_date ( context : Context , value : str , variable : str ) -> None Parses a datetime string and transforms it according to specified arguments. This step is useful when changes has to be made to a datetime representation during an iteration of a scenario. Endpoint Arguments : At least one of the following optional arguments must be specified: format str - a python strftime format string , this argument is required timezone str (optional) - a valid timezone name offset str (optional) - a time span string describing the offset, Y = years, M = months, D = days, h = hours, m = minutes, s = seconds, e.g. 1Y-2M10D ... And value for variable \" date1 \" is \" none \" And value for variable \" date2 \" is \" none \" And value for variable \" date3 \" is \" none \" And value for variable \" AtomicDate.test \" is \" now \" Then parse date \" 2022-01-17 12:21:37 | timezone=UTC, format= \"%Y-%m-%dT%H:%M:%S.%f\" , offset=1D \" and save in variable \" date1 \" Then parse date \" {{ AtomicDate.test }} | offset=-1D \" and save in variable \" date2 \" Then parse date \" {{ datetime.now() }} | offset=1Y \" and save in variable \" date3 \" Arguments : value str - datetime string and arguments variable str - name of, initialized, variable where response will be saved in step_task_async_group_start @given ( u 'an async request group with name \" {name} \"' ) def step_task_async_group_start ( context : Context , name : str ) -> None Creates a group of requests that should be executed asynchronously. All requests tasks created after this step will be added to the request group, until the group is closed. In this example, the put and get requests will run asynchronously, and both requests will block following requests until both are finished. Given an async request group with name \" async-group-1 \" Then post request with name \" test-post-2 \" to endpoint \" /api/test \" \"\"\" { \"value\": \"i have good news!\" } \"\"\" Then get request with name \" test-get-1 \" from endpoint \" /api/test \" And close async request group Arguments : name str - name of the group, will be used in locust statistics step_task_async_group_close @then ( u 'close async request group' ) def step_task_async_group_close ( context : Context ) -> None Closes an open async request group, to end the \"boxing\" of requests that should run asynchronously. Must be preceeded by the expression `Given an async request group with name...\" expression, and one or more requests expressions. Given an async request group with name \" async-group-1 \" Then post request with name \" test-post-2 \" to endpoint \" /api/test \" \"\"\" { \"value\": \"i have good news!\" } \"\"\" Then get request with name \" test-get-1 \" from endpoint \" /api/test \" And close async request group step_task_timer_start @then ( u 'start timer with name \" {name} \"' ) def step_task_timer_start ( context : Context , name : str ) -> None Start a timer to measure the \"request time\" for all tasks between the start and stop of the timer. Then start timer with name \" parsing-xml \" ... And stop timer with name \" parsing-xml \" step_task_timer_stop @then ( u 'stop timer with name \" {name} \"' ) def step_task_timer_stop ( context : Context , name : str ) -> None Stop a timer to measure the \"request time\" for all tasks between the start and stop of the timer. Then start timer with name \" parsing-xml \" ... And stop timer with name \" parsing-xml \" step_task_request_wait_between @given ( u 'wait \" {min_time:g} .. {max_time:g} \" seconds between tasks' ) def step_task_request_wait_between ( context : Context , min_time : float , max_time : float ) -> None Set number of, randomly, seconds the user will wait between executing tasks. And wait \" 1.4..1.7 \" seconds between tasks # wait between 1.4 and 1.7 seconds Then get request with name \" test-get-1 \" from endpoint \" ... \" # wait between 1.4 and 1.7 seconds Then get request with name \" test-get-2 \" from endpoint \" ... \" # wait between 1.4 and 1.7 seconds And wait \" 0.1 \" seconds between tasks # wait 0.1 seconds Then get request with name \" test-get-3 \" from endpoint \" ... \" # wait 0.1 seconds ... step_task_request_wait_constant @given ( u 'wait \" {time:g} \" seconds between tasks' ) def step_task_request_wait_constant ( context : Context , time : float ) -> None Set number of, constant, seconds the user will wait between executing tasks. And wait \" 1.4 \" seconds between tasks # wait 1.4 seconds Then get request with name \" test-get-1 \" from endpoint \" ... \" # wait 1.4 seconds Then get request with name \" test-get-2 \" from endpoint \" ... \" # wait 1.4 seconds And wait \" 0.1 \" seconds between tasks # wait 0.1 seconds Then get request with name \" test-get-3 \" from endpoint \" ... \" # wait 0.1 seconds ...","title":"Tasks"},{"location":"framework/usage/steps/scenario/tasks/#grizzlystepsscenariotasks","text":"This module contains step implementations that describes requests sent by user_class_name targeting host .","title":"grizzly.steps.scenario.tasks"},{"location":"framework/usage/steps/scenario/tasks/#step_task_request_with_name_to_endpoint_until","text":"@then ( u '{method:Method} request with name \" {name} \" from endpoint \" {endpoint} \" until \" {condition} \"' ) def step_task_request_with_name_to_endpoint_until ( context : Context , method : RequestMethod , name : str , endpoint : str , condition : str ) -> None Creates a named request to an endpoint on host and repeat it until condition is true in the response. content_type will be removed from the actual endpoint value. condition is a JSON- or Xpath expression, that also has support for \"grizzly style\" arguments: Endpoint Arguments : retries (int): maximum number of times to repeat the request if condition is not met (default 3 ) wait (float): number of seconds to wait between retries (default 1.0 ) Then get request with name \" test-get \" from endpoint \" /api/test | content_type=json \" until \" $.`this`[?success==true] \" Then receive request with name \" test-receive \" from endpoint \" queue:receive-queue | content_type=xml \" until \" /header/success[. == 'True'] \" Arguments : method RequestMethod - type of request name str - name of the requests in logs, can contain variables direction RequestDirection - one of to or from depending on the value of method endpoint str - URI relative to host in the scenario, can contain variables and in certain cases user_class_name specific parameters","title":"step_task_request_with_name_to_endpoint_until"},{"location":"framework/usage/steps/scenario/tasks/#step_task_request_text_with_name_to_endpoint","text":"@then ( u '{method:Method} request with name \" {name} \" {direction:Direction} endpoint \" {endpoint} \"' ) def step_task_request_text_with_name_to_endpoint ( context : Context , method : RequestMethod , name : str , direction : RequestDirection , endpoint : str ) -> None Creates a named request to an endpoint on host , where optional payload is defined directly in the feature file. If method in the expression is get or receive ; the direction must be from . If method in the expression is post , pust , or send ; the direction must be to , and payload defined in the feature file. endpoint has support for setting response content type as a parameter: content_type will be removed from the actual endpoint value. Then post request with name \" test-post \" to endpoint \" /api/test \" \"\"\" { \"test\": \"hello world\" } \"\"\" Then put request with name \" test-put \" to endpoint \" /api/test \" \"\"\" { \"test\": \"hello world\" } \"\"\" Then get request with name \" test-get \" from endpoint \" /api/test \" Then send request with name \" test-send \" to endpoint \" queue:receive-queue \" \"\"\" { \"value\": \"do something\" } \"\"\" Then receive request with name \" test-receive \" from endpoint \" queue:receive-queue \" Then receive request with name \" test-receive \" from endpoint \" queue:receive-queue | content_type=xml \" # same as Then receive request with name \" test-receive \" from endpoint \" queue:receive-queue \" And set response content type to \" xml \" Arguments : method RequestMethod - type of request name str - name of the requests in logs, can contain variables direction RequestDirection - one of to or from depending on the value of method endpoint str - URI relative to host in the scenario, can contain variables and in certain cases user_class_name specific parameters","title":"step_task_request_text_with_name_to_endpoint"},{"location":"framework/usage/steps/scenario/tasks/#step_task_request_file_with_name_endpoint","text":"@then ( u '{method:Method} request \" {source} \" with name \" {name} \" to endpoint \" {endpoint} \"' ) def step_task_request_file_with_name_endpoint ( context : Context , method : RequestMethod , source : str , name : str , endpoint : str ) -> None Creates a named request to an endpoint on host , where the payload is defined in a template file. endpoint has support for setting response content type as a parameter: content_type will be removed from the actual endpoint value. Then send request \" test/request.j2.json \" with name \" test-send \" to endpoint \" queue:receive-queue \" Then post request \" test/request.j2.json \" with name \" test-post \" to endpoint \" /api/test \" Then put request \" test/request.j2.json \" with name \" test-put \" to endpoint \" /api/test \" Then put request \" test/request.j2.json \" with name \" test-put \" to endpoint \" /api/test | content_type=json \" # same as Then put request \" test/request.j2.json \" with name \" test-put \" to endpoint \" /api/test \" And set response content type to \" application/json \" Arguments : method RequestMethod - type of request source str - path to a template file relative to the directory requests/ , which must exist in the directory the feature file is located name str - name of the requests in logs, can contain variables endpoint str - URI relative to host in the scenario, can contain variables and in certain cases user_class_name specific parameters","title":"step_task_request_file_with_name_endpoint"},{"location":"framework/usage/steps/scenario/tasks/#step_task_request_file_with_name","text":"@then ( u '{method:Method} request \" {source} \" with name \" {name} \"' ) def step_task_request_file_with_name ( context : Context , method : RequestMethod , source : str , name : str ) -> None Creates a named request to the same endpoint as previous request, where the payload is defined in a template file. endpoint has support for setting response content type as a parameter: content_type will be removed from the actual endpoint value. Then post request \" test/request1.j2.json \" with name \" test-post1 \" to endpoint \" /api/test \" Then post request \" test/request2.j2.json \" with name \" test-post2 \" # same as Then post request \" test/request1.j2.json \" with name \" test-post1 \" to endpoint \" /api/test \" Then post request \" test/request2.j2.json \" with name \" test-post2 \" to endpoint \" /api/test \" Then post request \" test/request1.j2.json \" with name \" test-post1 \" to endpoint \" /api/test | content_type=json \" # same as Then post request \" test/request1.j2.json \" with name \" test-post1 \" to endpoint \" /api/test \" And set response content type to \" application/json \" Arguments : method RequestMethod - type of request source str - path to a template file relative to the directory requests/ , which must exist in the directory the feature file is located name str - name of the requests in logs, can contain variables","title":"step_task_request_file_with_name"},{"location":"framework/usage/steps/scenario/tasks/#step_task_request_text_with_name","text":"@then ( u '{method:Method} request with name \" {name} \"' ) def step_task_request_text_with_name ( context : Context , method : RequestMethod , name : str ) -> None Creates a named request to the same endpoint as previous request, where optional payload is defined directly in the feature file. If method in the expression is post , put or send the payload in the request must be defined directly in the feature file after the step. This step is useful if method and endpoint are the same as previous request, but the payload should be different. Then post request with name \" test-post-1 \" to endpoint \" /api/test \" \"\"\" { \"value\": \"hello world!\" } \"\"\" Then post request with name \" test-post-2 \" \"\"\" { \"value\": \"i have good news!\" } \"\"\" # same as Then post request with name \" test-post-1 \" to endpoint \" /api/test \" \"\"\" { \"value\": \"hello world!\" } \"\"\" Then post request with name \" test-post-2 \" to endpoint \" /api/test \" \"\"\" { \"value\": \"i have good news!\" } \"\"\" Then get request with name \" test-get-1 \" from endpoint \" /api/test \" Then get request with name \" test-get-2 \" # same as Then get request with name \" test-get-1 \" from endpoint \" /api/test \" Then get request with name \" test-get-2 \" from endpoint \" /api/test \" Arguments : method RequestMethod - type of request name str - name of the requests in logs, can contain variables","title":"step_task_request_text_with_name"},{"location":"framework/usage/steps/scenario/tasks/#step_task_wait_seconds","text":"@then ( u 'wait for \" {wait_time:f} \" seconds' ) def step_task_wait_seconds ( context : Context , wait_time : float ) -> None Create an explicit wait (task) in the scenario. The scenario will wait the time specified (seconds) on top of what has been defined in step_setup_wait_time . Above combinations of steps will result in a wait time between 3 and 4 seconds for the first request that is defined after the Then wait for... -step. And wait time inbetween requests is random between \" 1.5 \" and \" 2.5 \" seconds ... Then wait for \" 1.5 \" seconds Arguments : wait_time float - wait time in seconds","title":"step_task_wait_seconds"},{"location":"framework/usage/steps/scenario/tasks/#step_task_print_message","text":"@then ( u 'print message \" {message} \"' ) def step_task_print_message ( context : Context , message : str ) -> None Print a message in the scenario. Useful for visualizing values of variables. The message can be a jinja template, and any variables will be rendered at the time the task executes. And print message \" context_variable='{{ context_variable }}' Arguments : message str - message to print","title":"step_task_print_message"},{"location":"framework/usage/steps/scenario/tasks/#step_task_transform","text":"@then ( u 'parse \" {content} \" as \"{content_type:ContentType}\" and save value of \" {expression} \" in variable \" {variable} \"' ) def step_task_transform ( context : Context , content : str , content_type : TransformerContentType , expression : str , variable : str ) -> None Parse (part of) a JSON object or a XML document and extract a specific value from that and save into a variable. This can be especially useful in combination with AtomicMessageQueue variable. And value for variable \" document_id \" is \" None \" And value for variable \" document_title \" is \" None \" And value for variable \" document \" is \" {\\ \"document\\\" : {\\ \"id\\\" : \\ \"DOCUMENT_ 8843 - 1 \\\" , \\ \"title\\\" : \\ \"TPM Report 2021 \\\" }} \" ... Then parse \" {{ document }} \" as \" json \" and save value of \" $.document.id \" in variable \" document_id \" Then parse \" {{ document }} \" as \" json \" and save value of \" $.document.title \" in variable \" document_title \" Arguments : contents str - contents to parse, supports templating or a static string content_type TransformerContentType - MIME type of contents expression str - JSON or XPath expression for specific value in contents variable str - name of variable to save value to, must have been initialized","title":"step_task_transform"},{"location":"framework/usage/steps/scenario/tasks/#step_task_client_get_endpoint","text":"@then ( u 'get \" {endpoint} \" with name \" {name} \" and save response in \" {variable} \"' ) def step_task_client_get_endpoint ( context : Context , endpoint : str , name : str , variable : str ) -> None Get information from another host or endpoint than the scenario is load testing and save the response in a variable. Task implementations are found in grizzly.task.clients and each implementation is looked up through the scheme in the specified endpoint. If the endpoint is a variable, one have to manually specify the endpoint scheme even though the resolved variable contains the scheme. In this case the manually specified scheme will be removed to the endpoint actually used by the task. Then get \" https://www.example.org/example.json \" with name \" example-1 \" and save response in \" example_openapi \" Then get \" http://{{ endpoint }} \" with name \" example-2 \" and save response in \" endpoint_result \" Arguments : endpoint str - information about where to get information, see the specific getter task implementations for more information name str - name of the request, used in request statistics variable str - name of, initialized, variable where response will be saved in","title":"step_task_client_get_endpoint"},{"location":"framework/usage/steps/scenario/tasks/#step_task_client_put_endpoint_file_destination","text":"@then ( u 'put \" {source} \" to \" {endpoint} \" with name \" {name} \" as \" {destination} \"' ) def step_task_client_put_endpoint_file_destination ( context : Context , source : str , endpoint : str , name : str , destination : str ) -> None Put information to another host or endpoint than the scenario is load testing, source being a file. Task implementations are found in grizzly.task.clients and each implementation is looked up through the scheme in the specified endpoint. If the endpoint is a variable, one have to manually specify the endpoint scheme even though the resolved variable contains the scheme. In this case the manually specified scheme will be removed to the endpoint actually used by the task. Then put \" test-file.json \" to \" bs://my-storage?AccountKey=aaaabbb=&Container=my-container \" with name \" upload-file \" as \" uploaded-test-file.json \" Arguments : source str - relative path to file in feature/requests , supports templating endpoint str - information about where to get information, see the specific getter task implementations for more information name str - name of the request, used in request statistics destination str - name of source on the destination","title":"step_task_client_put_endpoint_file_destination"},{"location":"framework/usage/steps/scenario/tasks/#step_task_client_put_endpoint_file","text":"@then ( u 'put \" {source} \" to \" {endpoint} \" with name \" {name} \"' ) def step_task_client_put_endpoint_file ( context : Context , source : str , endpoint : str , name : str ) -> None Put information to another host or endpoint than the scenario is load testing, source being a file. Task implementations are found in grizzly.task.clients and each implementation is looked up through the scheme in the specified endpoint. If the endpoint is a variable, one have to manually specify the endpoint scheme even though the resolved variable contains the scheme. In this case the manually specified scheme will be removed to the endpoint actually used by the task. Then put \" test-file.json \" to \" bs://my-storage?AccountKey=aaaabbb=&Container=my-container \" with name \" upload-file \" Arguments : source str - relative path to file in feature/requests , supports templating endpoint str - information about where to get information, see the specific getter task implementations for more information name str - name of the request, used in request statistics","title":"step_task_client_put_endpoint_file"},{"location":"framework/usage/steps/scenario/tasks/#step_task_date","text":"@then ( u 'parse date \" {value} \" and save in variable \" {variable} \"' ) def step_task_date ( context : Context , value : str , variable : str ) -> None Parses a datetime string and transforms it according to specified arguments. This step is useful when changes has to be made to a datetime representation during an iteration of a scenario. Endpoint Arguments : At least one of the following optional arguments must be specified: format str - a python strftime format string , this argument is required timezone str (optional) - a valid timezone name offset str (optional) - a time span string describing the offset, Y = years, M = months, D = days, h = hours, m = minutes, s = seconds, e.g. 1Y-2M10D ... And value for variable \" date1 \" is \" none \" And value for variable \" date2 \" is \" none \" And value for variable \" date3 \" is \" none \" And value for variable \" AtomicDate.test \" is \" now \" Then parse date \" 2022-01-17 12:21:37 | timezone=UTC, format= \"%Y-%m-%dT%H:%M:%S.%f\" , offset=1D \" and save in variable \" date1 \" Then parse date \" {{ AtomicDate.test }} | offset=-1D \" and save in variable \" date2 \" Then parse date \" {{ datetime.now() }} | offset=1Y \" and save in variable \" date3 \" Arguments : value str - datetime string and arguments variable str - name of, initialized, variable where response will be saved in","title":"step_task_date"},{"location":"framework/usage/steps/scenario/tasks/#step_task_async_group_start","text":"@given ( u 'an async request group with name \" {name} \"' ) def step_task_async_group_start ( context : Context , name : str ) -> None Creates a group of requests that should be executed asynchronously. All requests tasks created after this step will be added to the request group, until the group is closed. In this example, the put and get requests will run asynchronously, and both requests will block following requests until both are finished. Given an async request group with name \" async-group-1 \" Then post request with name \" test-post-2 \" to endpoint \" /api/test \" \"\"\" { \"value\": \"i have good news!\" } \"\"\" Then get request with name \" test-get-1 \" from endpoint \" /api/test \" And close async request group Arguments : name str - name of the group, will be used in locust statistics","title":"step_task_async_group_start"},{"location":"framework/usage/steps/scenario/tasks/#step_task_async_group_close","text":"@then ( u 'close async request group' ) def step_task_async_group_close ( context : Context ) -> None Closes an open async request group, to end the \"boxing\" of requests that should run asynchronously. Must be preceeded by the expression `Given an async request group with name...\" expression, and one or more requests expressions. Given an async request group with name \" async-group-1 \" Then post request with name \" test-post-2 \" to endpoint \" /api/test \" \"\"\" { \"value\": \"i have good news!\" } \"\"\" Then get request with name \" test-get-1 \" from endpoint \" /api/test \" And close async request group","title":"step_task_async_group_close"},{"location":"framework/usage/steps/scenario/tasks/#step_task_timer_start","text":"@then ( u 'start timer with name \" {name} \"' ) def step_task_timer_start ( context : Context , name : str ) -> None Start a timer to measure the \"request time\" for all tasks between the start and stop of the timer. Then start timer with name \" parsing-xml \" ... And stop timer with name \" parsing-xml \"","title":"step_task_timer_start"},{"location":"framework/usage/steps/scenario/tasks/#step_task_timer_stop","text":"@then ( u 'stop timer with name \" {name} \"' ) def step_task_timer_stop ( context : Context , name : str ) -> None Stop a timer to measure the \"request time\" for all tasks between the start and stop of the timer. Then start timer with name \" parsing-xml \" ... And stop timer with name \" parsing-xml \"","title":"step_task_timer_stop"},{"location":"framework/usage/steps/scenario/tasks/#step_task_request_wait_between","text":"@given ( u 'wait \" {min_time:g} .. {max_time:g} \" seconds between tasks' ) def step_task_request_wait_between ( context : Context , min_time : float , max_time : float ) -> None Set number of, randomly, seconds the user will wait between executing tasks. And wait \" 1.4..1.7 \" seconds between tasks # wait between 1.4 and 1.7 seconds Then get request with name \" test-get-1 \" from endpoint \" ... \" # wait between 1.4 and 1.7 seconds Then get request with name \" test-get-2 \" from endpoint \" ... \" # wait between 1.4 and 1.7 seconds And wait \" 0.1 \" seconds between tasks # wait 0.1 seconds Then get request with name \" test-get-3 \" from endpoint \" ... \" # wait 0.1 seconds ...","title":"step_task_request_wait_between"},{"location":"framework/usage/steps/scenario/tasks/#step_task_request_wait_constant","text":"@given ( u 'wait \" {time:g} \" seconds between tasks' ) def step_task_request_wait_constant ( context : Context , time : float ) -> None Set number of, constant, seconds the user will wait between executing tasks. And wait \" 1.4 \" seconds between tasks # wait 1.4 seconds Then get request with name \" test-get-1 \" from endpoint \" ... \" # wait 1.4 seconds Then get request with name \" test-get-2 \" from endpoint \" ... \" # wait 1.4 seconds And wait \" 0.1 \" seconds between tasks # wait 0.1 seconds Then get request with name \" test-get-3 \" from endpoint \" ... \" # wait 0.1 seconds ...","title":"step_task_request_wait_constant"},{"location":"framework/usage/steps/scenario/user/","text":"grizzly.steps.scenario.user This module contains step implementations that describes a user. step_user_type_with_weight @given ( u 'a user of type \" {user_class_name} \" with weight \" {weight_value} \" load testing \" {host} \"' ) def step_user_type_with_weight ( context : Context , user_class_name : str , weight_value : str , host : str ) -> None Set which type of user the scenario should use and which host is the target, together with weight for the user (how much this user should spawn, relative to others). Given a user of type \" RestApi \" with weight \" 2 \" load testing \" ... \" Given a user of type \" MessageQueue \" with weight \" 1 \" load testing \" ... \" Given a user of type \" ServiceBus \" with weight \" 1 \" load testing \" ... \" Given a user of type \" BlobStorage \" with weight \" 4 \" load testing \" ... \" Arguments : user_class_name str - name of an implementation in grizzly.users , with or without User weight_value str - weight value for the user, default is '1' (see http://docs.locust.io/en/stable/writing-a-locustfile.html#weight-attribute) host str - an URL for the target host, format depends on which user_class_name (see grizzly.users ) step_user_type @given ( u 'a user of type \" {user_class_name} \" load testing \" {host} \"' ) def step_user_type ( context : Context , user_class_name : str , host : str ) -> None Set which type of user the scenario should use and which host is the target. Given a user of type \" RestApi \" load testing \" http://api.example.com \" Given a user of type \" MessageQueue \" load testing \" mq://mqm:secret@mq.example.com/?QueueManager=QMGR01&Channel=Channel01 \" Given a user of type \" ServiceBus \" load testing \" sb://sb.example.com/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=abc123def456ghi789= \" Given a user of type \" BlobStorage \" load testing \" DefaultEndpointsProtocol=https;EndpointSuffix=core.windows.net;AccountName=examplestorage;AccountKey=xxxyyyyzzz== \" Arguments : user_class_name str - name of an implementation in grizzly.users , with or without User host str - an URL for the target host, format depends on which user_class_name (see grizzly.users )","title":"User"},{"location":"framework/usage/steps/scenario/user/#grizzlystepsscenariouser","text":"This module contains step implementations that describes a user.","title":"grizzly.steps.scenario.user"},{"location":"framework/usage/steps/scenario/user/#step_user_type_with_weight","text":"@given ( u 'a user of type \" {user_class_name} \" with weight \" {weight_value} \" load testing \" {host} \"' ) def step_user_type_with_weight ( context : Context , user_class_name : str , weight_value : str , host : str ) -> None Set which type of user the scenario should use and which host is the target, together with weight for the user (how much this user should spawn, relative to others). Given a user of type \" RestApi \" with weight \" 2 \" load testing \" ... \" Given a user of type \" MessageQueue \" with weight \" 1 \" load testing \" ... \" Given a user of type \" ServiceBus \" with weight \" 1 \" load testing \" ... \" Given a user of type \" BlobStorage \" with weight \" 4 \" load testing \" ... \" Arguments : user_class_name str - name of an implementation in grizzly.users , with or without User weight_value str - weight value for the user, default is '1' (see http://docs.locust.io/en/stable/writing-a-locustfile.html#weight-attribute) host str - an URL for the target host, format depends on which user_class_name (see grizzly.users )","title":"step_user_type_with_weight"},{"location":"framework/usage/steps/scenario/user/#step_user_type","text":"@given ( u 'a user of type \" {user_class_name} \" load testing \" {host} \"' ) def step_user_type ( context : Context , user_class_name : str , host : str ) -> None Set which type of user the scenario should use and which host is the target. Given a user of type \" RestApi \" load testing \" http://api.example.com \" Given a user of type \" MessageQueue \" load testing \" mq://mqm:secret@mq.example.com/?QueueManager=QMGR01&Channel=Channel01 \" Given a user of type \" ServiceBus \" load testing \" sb://sb.example.com/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=abc123def456ghi789= \" Given a user of type \" BlobStorage \" load testing \" DefaultEndpointsProtocol=https;EndpointSuffix=core.windows.net;AccountName=examplestorage;AccountKey=xxxyyyyzzz== \" Arguments : user_class_name str - name of an implementation in grizzly.users , with or without User host str - an URL for the target host, format depends on which user_class_name (see grizzly.users )","title":"step_user_type"},{"location":"framework/usage/tasks/async-request-group/","text":"grizzly.tasks.async_group This task runs all requests in the group asynchronously. The name of all request added to the group will be prefixed with async group <name>: . Request type for this task is ASYNC . Arguments : name (str): name of the group of asynchronously requests Instances of this task is created with step expressions: step_task_async_group_start step_task_async_group_close Requests are added to the group with the same step expressions as RequestTask . Enable gevent debugging for this task by running with argument --verbose and setting environment variable GEVENT_MONITOR_THREAD_ENABLE .","title":"Async Request Group"},{"location":"framework/usage/tasks/async-request-group/#grizzlytasksasync_group","text":"This task runs all requests in the group asynchronously. The name of all request added to the group will be prefixed with async group <name>: . Request type for this task is ASYNC . Arguments : name (str): name of the group of asynchronously requests Instances of this task is created with step expressions: step_task_async_group_start step_task_async_group_close Requests are added to the group with the same step expressions as RequestTask . Enable gevent debugging for this task by running with argument --verbose and setting environment variable GEVENT_MONITOR_THREAD_ENABLE .","title":"grizzly.tasks.async_group"},{"location":"framework/usage/tasks/date/","text":"grizzly.tasks.date This task parses a string representation of a date/time and allows transformation of it, such as specifying an offset or changing the format, and saves the result as a date/time string in an variable. At least one arguments needs to specified. Instances of this task is created with the step expression: step_task_date Arguments format str - a python strftime format string or ISO-8601:[DateTime|Time][:ms] , this argument is required timezone str (optional) - a valid timezone name offset str (optional) - a time span string describing the offset, Y = years, M = months, D = days, h = hours, m = minutes, s = seconds, e.g. 1Y-2M10D","title":"Date"},{"location":"framework/usage/tasks/date/#grizzlytasksdate","text":"This task parses a string representation of a date/time and allows transformation of it, such as specifying an offset or changing the format, and saves the result as a date/time string in an variable. At least one arguments needs to specified. Instances of this task is created with the step expression: step_task_date","title":"grizzly.tasks.date"},{"location":"framework/usage/tasks/date/#arguments","text":"format str - a python strftime format string or ISO-8601:[DateTime|Time][:ms] , this argument is required timezone str (optional) - a valid timezone name offset str (optional) - a time span string describing the offset, Y = years, M = months, D = days, h = hours, m = minutes, s = seconds, e.g. 1Y-2M10D","title":"Arguments"},{"location":"framework/usage/tasks/log-message/","text":"grizzly.tasks.log_message This task calls the grizzly logger to print a log message at level INFO . It can be used to visualize values for templating variables. Instances of this task is created with the step expression: step_task_print_message","title":"Log Message"},{"location":"framework/usage/tasks/log-message/#grizzlytaskslog_message","text":"This task calls the grizzly logger to print a log message at level INFO . It can be used to visualize values for templating variables. Instances of this task is created with the step expression: step_task_print_message","title":"grizzly.tasks.log_message"},{"location":"framework/usage/tasks/request-wait/","text":"grizzly.tasks.request_wait This task sets the wait time between tasks in a scenario. The default is to wait 0 seconds between each task. This is useful in a scenario with many requests that should have some wait time between them, but there are a group of tasks (e.g. Transform, Date or Log Messages) that should execute as fast as possible. Instances of this task is created with the step expression: step_task_request_wait_constant step_task_request_wait_between","title":"Request Wait"},{"location":"framework/usage/tasks/request-wait/#grizzlytasksrequest_wait","text":"This task sets the wait time between tasks in a scenario. The default is to wait 0 seconds between each task. This is useful in a scenario with many requests that should have some wait time between them, but there are a group of tasks (e.g. Transform, Date or Log Messages) that should execute as fast as possible. Instances of this task is created with the step expression: step_task_request_wait_constant step_task_request_wait_between","title":"grizzly.tasks.request_wait"},{"location":"framework/usage/tasks/request/","text":"grizzly.tasks.request This task calls the request method of a grizzly.users implementation. This is the most essential task in grizzly , it defines requests that the specified load user is going to execute against the target under test. Instances of this task is created with the step expressions: step_task_request_text_with_name_to_endpoint step_task_request_file_with_name_endpoint step_task_request_file_with_name step_task_request_text_with_name","title":"Request"},{"location":"framework/usage/tasks/request/#grizzlytasksrequest","text":"This task calls the request method of a grizzly.users implementation. This is the most essential task in grizzly , it defines requests that the specified load user is going to execute against the target under test. Instances of this task is created with the step expressions: step_task_request_text_with_name_to_endpoint step_task_request_file_with_name_endpoint step_task_request_file_with_name step_task_request_text_with_name","title":"grizzly.tasks.request"},{"location":"framework/usage/tasks/timer/","text":"grizzly.tasks.timer This task \"wraps\" a group of other tasks, that might not have any requests and hence no statistics, to measure how long time they took. Request content length for this task in the scenario is number of tasks between starting and stopping the timer. Instances of this task is created with the step expressions: step_task_timer_start step_task_timer_stop","title":"Timer"},{"location":"framework/usage/tasks/timer/#grizzlytaskstimer","text":"This task \"wraps\" a group of other tasks, that might not have any requests and hence no statistics, to measure how long time they took. Request content length for this task in the scenario is number of tasks between starting and stopping the timer. Instances of this task is created with the step expressions: step_task_timer_start step_task_timer_stop","title":"grizzly.tasks.timer"},{"location":"framework/usage/tasks/transformer/","text":"grizzly.tasks.transformer This task transforms a variable value to a document of correct type, so an expression can be used to extract values from the document to be used in another variable. This is especially useful when used in combination with other variables variables containing a lot of information, where many parts of a message can be useful to re-use. Instances of this task is created with the step expression: step_task_transform","title":"Transformer"},{"location":"framework/usage/tasks/transformer/#grizzlytaskstransformer","text":"This task transforms a variable value to a document of correct type, so an expression can be used to extract values from the document to be used in another variable. This is especially useful when used in combination with other variables variables containing a lot of information, where many parts of a message can be useful to re-use. Instances of this task is created with the step expression: step_task_transform","title":"grizzly.tasks.transformer"},{"location":"framework/usage/tasks/until-request/","text":"grizzly.tasks.until This task calls the request method of a grizzly.users implementation, until condition matches the payload returned for the request. condition is a JSON- or Xpath expression, that also has support for \"grizzly style\" arguments: Arguments : retries (int): maximum number of times to repeat the request if condition is not met (default 3 ) wait (float): number of seconds to wait between retries (default 1.0 ) expected_matches (int): number of matches that the expression should match (default 1 ) Instances of this task is created with step expression: step_task_request_text_with_name_to_endpoint_until","title":"Until Request"},{"location":"framework/usage/tasks/until-request/#grizzlytasksuntil","text":"This task calls the request method of a grizzly.users implementation, until condition matches the payload returned for the request. condition is a JSON- or Xpath expression, that also has support for \"grizzly style\" arguments: Arguments : retries (int): maximum number of times to repeat the request if condition is not met (default 3 ) wait (float): number of seconds to wait between retries (default 1.0 ) expected_matches (int): number of matches that the expression should match (default 1 ) Instances of this task is created with step expression: step_task_request_text_with_name_to_endpoint_until","title":"grizzly.tasks.until"},{"location":"framework/usage/tasks/wait/","text":"grizzly.tasks.wait This task executes a gevent.sleep and is used to manually create delays between steps in a scenario. Instances of this task is created with the step expression: step_task_wait_seconds","title":"Wait"},{"location":"framework/usage/tasks/wait/#grizzlytaskswait","text":"This task executes a gevent.sleep and is used to manually create delays between steps in a scenario. Instances of this task is created with the step expression: step_task_wait_seconds","title":"grizzly.tasks.wait"},{"location":"framework/usage/tasks/clients/blob-storage/","text":"grizzly.tasks.clients.blobstorage This task performs Azure Blob Storage put operations to a specified endpoint. This is useful if the scenario is another user type than BlobStorageUser , but the scenario still requires an action towards a blob container. Endpoint is specified in the format: All variables in the endpoint supports templating, but not the whole string. Content-Type of an uploaded file will automagically be guessed based on the [rendered] destination file extension. bs[s]://<AccountName>?AccountKey=<AccountKey>&Container=<Container> Example : bss://my-storage?AccountKey=aaaabbbb==&Container=my-container This will be resolved to DefaultEndpointsProtocol=https;AccountName=my-storage;AccountKey=aaaabbbb==;EndpointSuffix=core.windows.net , and operations will be performed in container my-container . Instances of this task is created with the step expression, if endpoint is defined with scheme bs : step_task_client_put_endpoint_file_destination","title":"Blob Storage"},{"location":"framework/usage/tasks/clients/blob-storage/#grizzlytasksclientsblobstorage","text":"This task performs Azure Blob Storage put operations to a specified endpoint. This is useful if the scenario is another user type than BlobStorageUser , but the scenario still requires an action towards a blob container. Endpoint is specified in the format: All variables in the endpoint supports templating, but not the whole string. Content-Type of an uploaded file will automagically be guessed based on the [rendered] destination file extension. bs[s]://<AccountName>?AccountKey=<AccountKey>&Container=<Container> Example : bss://my-storage?AccountKey=aaaabbbb==&Container=my-container This will be resolved to DefaultEndpointsProtocol=https;AccountName=my-storage;AccountKey=aaaabbbb==;EndpointSuffix=core.windows.net , and operations will be performed in container my-container . Instances of this task is created with the step expression, if endpoint is defined with scheme bs : step_task_client_put_endpoint_file_destination","title":"grizzly.tasks.clients.blobstorage"},{"location":"framework/usage/tasks/clients/http/","text":"grizzly.tasks.clients.http This task performs a HTTP request to a specified endpoint. This is useful if the scenario is using a non-HTTP user or a request to a URL other than the one under testing is needed, e.g. for testdata. Instances of this task is created with the step expression, if endpoint is defined with scheme http or https : step_task_client_get_endpoint","title":"HTTP"},{"location":"framework/usage/tasks/clients/http/#grizzlytasksclientshttp","text":"This task performs a HTTP request to a specified endpoint. This is useful if the scenario is using a non-HTTP user or a request to a URL other than the one under testing is needed, e.g. for testdata. Instances of this task is created with the step expression, if endpoint is defined with scheme http or https : step_task_client_get_endpoint","title":"grizzly.tasks.clients.http"},{"location":"framework/usage/tasks/clients/message-queue/","text":"grizzly.tasks.clients.messagequeue This task performs IBM MQM get and put opertions to a specified queue or topic. This is useful if the scenario is another user type than MessageQueueUser , but the scenario still requires an action towards an MQ server. Use transformer task to extract specific parts of the message. Grizzly must have been installed with the extra mq package and native IBM MQ libraries must be installed for being able to use this variable: pip3 install grizzly-loadtester[mq] Endpoint is specified in the format: mq[s]://<username>:<password>@]<hostname>[:<port>]/<endpoint>?QueueManager=<queue manager>&Channel=<channel>[&wait=<wait>][&heartbeat=<heartbeat>][&KeyFile=<key repo path>[&SslCipher=<ssl cipher>][&CertLabel=<certificate label>]] All variables in the URL have support for templating . mq[s] str - must be specified, mqs implies connecting with TLS, if KeyFile is not set in querystring, it will look for a key repository in ./<username> username str (optional) - username to authenticate with, default None password str (optional) - password to authenticate with, default None hostname str - hostname of MQ server port int (optional) - port on MQ server, default 1414 endpoint str - prefixed with either topic: or queue: and then the name of the endpoint to perform operations on wait int (optional) - number of seconds to wait for an message, default is to wait infinite (0 seconds) heartbeat int (optional) - number of seconds between heartbeats, default is 300 seconds QueueManager str - name of queue manager Channel str - name of channel to connect to KeyFile str (optional) - path to key repository for certificates needed to connect over TLS SslCipher str (optional) - SSL cipher to use for connection, default ECDHE_RSA_AES_256_GCM_SHA384 CertLabel str (optional) - label of certificate in key repository, default username Instances of this task is created with the step expression, if endpoint is defined with scheme mq or mqs : step_task_client_get_endpoint step_task_client_put_endpoint_file","title":"Message Queue"},{"location":"framework/usage/tasks/clients/message-queue/#grizzlytasksclientsmessagequeue","text":"This task performs IBM MQM get and put opertions to a specified queue or topic. This is useful if the scenario is another user type than MessageQueueUser , but the scenario still requires an action towards an MQ server. Use transformer task to extract specific parts of the message. Grizzly must have been installed with the extra mq package and native IBM MQ libraries must be installed for being able to use this variable: pip3 install grizzly-loadtester[mq] Endpoint is specified in the format: mq[s]://<username>:<password>@]<hostname>[:<port>]/<endpoint>?QueueManager=<queue manager>&Channel=<channel>[&wait=<wait>][&heartbeat=<heartbeat>][&KeyFile=<key repo path>[&SslCipher=<ssl cipher>][&CertLabel=<certificate label>]] All variables in the URL have support for templating . mq[s] str - must be specified, mqs implies connecting with TLS, if KeyFile is not set in querystring, it will look for a key repository in ./<username> username str (optional) - username to authenticate with, default None password str (optional) - password to authenticate with, default None hostname str - hostname of MQ server port int (optional) - port on MQ server, default 1414 endpoint str - prefixed with either topic: or queue: and then the name of the endpoint to perform operations on wait int (optional) - number of seconds to wait for an message, default is to wait infinite (0 seconds) heartbeat int (optional) - number of seconds between heartbeats, default is 300 seconds QueueManager str - name of queue manager Channel str - name of channel to connect to KeyFile str (optional) - path to key repository for certificates needed to connect over TLS SslCipher str (optional) - SSL cipher to use for connection, default ECDHE_RSA_AES_256_GCM_SHA384 CertLabel str (optional) - label of certificate in key repository, default username Instances of this task is created with the step expression, if endpoint is defined with scheme mq or mqs : step_task_client_get_endpoint step_task_client_put_endpoint_file","title":"grizzly.tasks.clients.messagequeue"},{"location":"framework/usage/variables/environment-configuration/","text":"Environment configuration It is possible to make the feature file environment agnostic by providing a yaml file containing a dictionary with a root node named configuration . The environment configuration file can also be used to store credentials and other sensitive information that should not be under version control. Internally grizzly will check if the environment variable GRIZZLY_CONFIGURATION_FILE is set and contains a valid environment configuration file. When using grizzly-cli you specify the file with -e/--environment-file which then will be set as a value for GRIZZLY_CONFIGURATION_FILE . Format An example environment configuration file: configuration : frontend : host : https://www.example.com backend : host : https://backend.example.com auth : user : username : bob password : Who-the-f-is-alice The only rule for any nodes under configuration is that it must be a dictionary, since the path to a value will be flattened. Usage In a feature file the dictionary can then be used by prefixing the path of a node under configuration with $conf:: . Example: Feature: application test Background: common configuration Given \" 1 \" users And spawn rate is \" 1 \" user per second And stop on first failure Scenario: frontend Given a user of type \" RestApi \" load testing \" $conf::frontend.host \" ... Scenario: backend Given a user of type \" RestApi \" load testing \" $conf::backend.host \" And set context variable \" auth.user.username \" to \" $conf::backend.auth.user.username \" And set context variable \" auth.user.password \" to \" $conf::backend.auth.user.password \" This feature can now be run against a different environment just by creating a new environment configuration file with different values.","title":"Environment configuration"},{"location":"framework/usage/variables/environment-configuration/#environment-configuration","text":"It is possible to make the feature file environment agnostic by providing a yaml file containing a dictionary with a root node named configuration . The environment configuration file can also be used to store credentials and other sensitive information that should not be under version control. Internally grizzly will check if the environment variable GRIZZLY_CONFIGURATION_FILE is set and contains a valid environment configuration file. When using grizzly-cli you specify the file with -e/--environment-file which then will be set as a value for GRIZZLY_CONFIGURATION_FILE .","title":"Environment configuration"},{"location":"framework/usage/variables/environment-configuration/#format","text":"An example environment configuration file: configuration : frontend : host : https://www.example.com backend : host : https://backend.example.com auth : user : username : bob password : Who-the-f-is-alice The only rule for any nodes under configuration is that it must be a dictionary, since the path to a value will be flattened.","title":"Format"},{"location":"framework/usage/variables/environment-configuration/#usage","text":"In a feature file the dictionary can then be used by prefixing the path of a node under configuration with $conf:: . Example: Feature: application test Background: common configuration Given \" 1 \" users And spawn rate is \" 1 \" user per second And stop on first failure Scenario: frontend Given a user of type \" RestApi \" load testing \" $conf::frontend.host \" ... Scenario: backend Given a user of type \" RestApi \" load testing \" $conf::backend.host \" And set context variable \" auth.user.username \" to \" $conf::backend.auth.user.username \" And set context variable \" auth.user.password \" to \" $conf::backend.auth.user.password \" This feature can now be run against a different environment just by creating a new environment configuration file with different values.","title":"Usage"},{"location":"framework/usage/variables/templating/","text":"Templating grizzly has support for templating in both step expression variables (most) and request payload, with the templating backend Jinja2 . Request payload Request payload is treated as complete Jinja2 templates and has full support for any Jinja2 features. Request payload files must be stored in ./features/requests and are referenced in a feature file as a relative path to that directory. . \u2514\u2500\u2500 features \u251c\u2500\u2500 load-test.feature \u2514\u2500\u2500 requests \u2514\u2500\u2500 load-test \u2514\u2500\u2500 request.j2.json Consider that load-test.feature contains the following steps: Feature: templating example Background: common settings for all scenarios Given \" 1 \" user And spawn rate is \" 1 \" user per second And stop on first failure Scenario: example Given a user of type \" RestApi \" load testing \" https://localhost \" And repeat for \" 3 \" iterations And value for variable \" AtomicIntegerIncrementer.items \" is \" 1 | step=3 \" Then post request \" load-test/request.j2.json \" with name \" template-request \" to endpoint \" /api/v1/test \" request.j2.json is a full Jinja2 template which will be rendered before the request is sent. The reason for this is that testdata variables can be used in the template, and these can change for each request. If request.j2.json contains the following: [ { % - f or n i n ra n ge(A t omicI nte gerI n creme nter .i te ms) % } { \"item\" : {{ n }}, \"name\" : \"item-{{ n }}\" } { % - i f n < A t omicI nte gerI n creme nter .i te ms - 1 % },{ % - e n di f % } { % - e n d f or % } ] Since the scenario has been setup to run for 3 iterations with 1 user and assumed that we run it locally, or distributed with one worker node, the scenario will run three times. The first post request to /api/v1/test will have the following payload: [ { \"item\" : 0 , \"name\" : \"item-0\" } ] The second post request: [ { \"item\" : 0 , \"name\" : \"item-0\" }, { \"item\" : 1 , \"name\" : \"item-1\" }, { \"item\" : 2 , \"name\" : \"item-2\" }, { \"item\" : 3 , \"name\" : \"item-3\" } ] The third post request: [ { \"item\" : 0 , \"name\" : \"item-0\" }, { \"item\" : 1 , \"name\" : \"item-1\" }, { \"item\" : 2 , \"name\" : \"item-2\" }, { \"item\" : 3 , \"name\" : \"item-3\" }, { \"item\" : 4 , \"name\" : \"item-4\" }, { \"item\" : 5 , \"name\" : \"item-5\" }, { \"item\" : 6 , \"name\" : \"item-6\" } ] Step expression Most step expressions also support templating for their variables, for example: And set context variable \" auth.user.username \" to \" $conf::backend.auth.user.username \" And set context variable \" auth.refresh_time \" to \" {{ AtomicIntegerIncrementer.refresh_time }} \" And repeat for \" {{ iterations * 0.25 }} \" And save statistics to \" influxdb://$conf::statistics.username:$conf::statistics.password@{{ influxdb_host }}/$conf::statistics.database \" And ask for value of variable \" initial_id \" And value for variable \" AtomicIntegerIncrementer.id1 \" is \" {{ initial_id }} \" And value for variable \" AtomicIntegerIncrementer.id2 \" is \" {{ initial_id }} \" Then put request with name \" example-{{ initial_id }} \" to \" /api/v{{ initial_id }}/test \" \"\"\" { \"test\": { \"value\": \"{{ initial_id }}\" } } \"\"\"","title":"Templating"},{"location":"framework/usage/variables/templating/#templating","text":"grizzly has support for templating in both step expression variables (most) and request payload, with the templating backend Jinja2 .","title":"Templating"},{"location":"framework/usage/variables/templating/#request-payload","text":"Request payload is treated as complete Jinja2 templates and has full support for any Jinja2 features. Request payload files must be stored in ./features/requests and are referenced in a feature file as a relative path to that directory. . \u2514\u2500\u2500 features \u251c\u2500\u2500 load-test.feature \u2514\u2500\u2500 requests \u2514\u2500\u2500 load-test \u2514\u2500\u2500 request.j2.json Consider that load-test.feature contains the following steps: Feature: templating example Background: common settings for all scenarios Given \" 1 \" user And spawn rate is \" 1 \" user per second And stop on first failure Scenario: example Given a user of type \" RestApi \" load testing \" https://localhost \" And repeat for \" 3 \" iterations And value for variable \" AtomicIntegerIncrementer.items \" is \" 1 | step=3 \" Then post request \" load-test/request.j2.json \" with name \" template-request \" to endpoint \" /api/v1/test \" request.j2.json is a full Jinja2 template which will be rendered before the request is sent. The reason for this is that testdata variables can be used in the template, and these can change for each request. If request.j2.json contains the following: [ { % - f or n i n ra n ge(A t omicI nte gerI n creme nter .i te ms) % } { \"item\" : {{ n }}, \"name\" : \"item-{{ n }}\" } { % - i f n < A t omicI nte gerI n creme nter .i te ms - 1 % },{ % - e n di f % } { % - e n d f or % } ] Since the scenario has been setup to run for 3 iterations with 1 user and assumed that we run it locally, or distributed with one worker node, the scenario will run three times. The first post request to /api/v1/test will have the following payload: [ { \"item\" : 0 , \"name\" : \"item-0\" } ] The second post request: [ { \"item\" : 0 , \"name\" : \"item-0\" }, { \"item\" : 1 , \"name\" : \"item-1\" }, { \"item\" : 2 , \"name\" : \"item-2\" }, { \"item\" : 3 , \"name\" : \"item-3\" } ] The third post request: [ { \"item\" : 0 , \"name\" : \"item-0\" }, { \"item\" : 1 , \"name\" : \"item-1\" }, { \"item\" : 2 , \"name\" : \"item-2\" }, { \"item\" : 3 , \"name\" : \"item-3\" }, { \"item\" : 4 , \"name\" : \"item-4\" }, { \"item\" : 5 , \"name\" : \"item-5\" }, { \"item\" : 6 , \"name\" : \"item-6\" } ]","title":"Request payload"},{"location":"framework/usage/variables/templating/#step-expression","text":"Most step expressions also support templating for their variables, for example: And set context variable \" auth.user.username \" to \" $conf::backend.auth.user.username \" And set context variable \" auth.refresh_time \" to \" {{ AtomicIntegerIncrementer.refresh_time }} \" And repeat for \" {{ iterations * 0.25 }} \" And save statistics to \" influxdb://$conf::statistics.username:$conf::statistics.password@{{ influxdb_host }}/$conf::statistics.database \" And ask for value of variable \" initial_id \" And value for variable \" AtomicIntegerIncrementer.id1 \" is \" {{ initial_id }} \" And value for variable \" AtomicIntegerIncrementer.id2 \" is \" {{ initial_id }} \" Then put request with name \" example-{{ initial_id }} \" to \" /api/v{{ initial_id }}/test \" \"\"\" { \"test\": { \"value\": \"{{ initial_id }}\" } } \"\"\"","title":"Step expression"},{"location":"framework/usage/variables/testdata/csv-row/","text":"grizzly.testdata.variables.csv_row This variable reads a CSV file and provides a new row from the CSV file each time it is accessed. The CSV files must have headers for each column, since these are used to reference the value. Format Value is the path, relative to requests/ , of an file ending with .csv . Arguments repeat bool (optional) - whether values should be reused, e.g. when reaching the end it should start from the beginning again (default: False ) random bool (optional) - if rows should be selected by random, instead of sequential from first to last (default: False ) Example requests/example.csv : username,password bob1,some-password alice1,some-other-password bob2,password And value for variable \" AtomicCsvRow.example \" is \" example.csv | random=False, repeat=True \" Then post request with name \" authenticate \" to endpoint \" /api/v1/authenticate \" \"\"\" { \"username\": \"{{ AtomicCsvRow.example.username }}\", \"password\": \"{{ AtomicCsvRow.example.password }}\" } \"\"\" First request the payload will be: { \"username\" : \"bob1\" , \"password\" : \"some-password\" } Second request: { \"username\" : \"alice1\" , \"password\" : \"some-other-password\" } etc.","title":"CSV Row"},{"location":"framework/usage/variables/testdata/csv-row/#grizzlytestdatavariablescsv_row","text":"This variable reads a CSV file and provides a new row from the CSV file each time it is accessed. The CSV files must have headers for each column, since these are used to reference the value.","title":"grizzly.testdata.variables.csv_row"},{"location":"framework/usage/variables/testdata/csv-row/#format","text":"Value is the path, relative to requests/ , of an file ending with .csv .","title":"Format"},{"location":"framework/usage/variables/testdata/csv-row/#arguments","text":"repeat bool (optional) - whether values should be reused, e.g. when reaching the end it should start from the beginning again (default: False ) random bool (optional) - if rows should be selected by random, instead of sequential from first to last (default: False )","title":"Arguments"},{"location":"framework/usage/variables/testdata/csv-row/#example","text":"requests/example.csv : username,password bob1,some-password alice1,some-other-password bob2,password And value for variable \" AtomicCsvRow.example \" is \" example.csv | random=False, repeat=True \" Then post request with name \" authenticate \" to endpoint \" /api/v1/authenticate \" \"\"\" { \"username\": \"{{ AtomicCsvRow.example.username }}\", \"password\": \"{{ AtomicCsvRow.example.password }}\" } \"\"\" First request the payload will be: { \"username\" : \"bob1\" , \"password\" : \"some-password\" } Second request: { \"username\" : \"alice1\" , \"password\" : \"some-other-password\" } etc.","title":"Example"},{"location":"framework/usage/variables/testdata/date/","text":"grizzly.testdata.variables.date This variable is used to format and use dates. Format Initial value can, other than a parseable datetime string, be now . Each time the variable is accessed the value will represent that date and time at the time of access. Arguments format str - a python strftime format string , this argument is required timezone str (optional) - a valid timezone name offset str (optional) - a time span string describing the offset, Y = years, M = months, D = days, h = hours, m = minutes, s = seconds, e.g. 1Y-2M10D Example And value for variable \" AtomicDate.arrival \" is \" now | format='%Y-%m-%dT%H:%M:%S.000Z', timezone=UTC \" This can then be used in a template: { \"arrival\" : \"{{ AtomicDate.arrival }}\" , \"location\" : \"Port of Shanghai\" }","title":"Date"},{"location":"framework/usage/variables/testdata/date/#grizzlytestdatavariablesdate","text":"This variable is used to format and use dates.","title":"grizzly.testdata.variables.date"},{"location":"framework/usage/variables/testdata/date/#format","text":"Initial value can, other than a parseable datetime string, be now . Each time the variable is accessed the value will represent that date and time at the time of access.","title":"Format"},{"location":"framework/usage/variables/testdata/date/#arguments","text":"format str - a python strftime format string , this argument is required timezone str (optional) - a valid timezone name offset str (optional) - a time span string describing the offset, Y = years, M = months, D = days, h = hours, m = minutes, s = seconds, e.g. 1Y-2M10D","title":"Arguments"},{"location":"framework/usage/variables/testdata/date/#example","text":"And value for variable \" AtomicDate.arrival \" is \" now | format='%Y-%m-%dT%H:%M:%S.000Z', timezone=UTC \" This can then be used in a template: { \"arrival\" : \"{{ AtomicDate.arrival }}\" , \"location\" : \"Port of Shanghai\" }","title":"Example"},{"location":"framework/usage/variables/testdata/directory-contents/","text":"grizzly.testdata.variables.directory_contents This variable provides a list of files in the specified directory. Format Relative path of a directory under requests/ . Arguments repeat bool (optional) - wether values should be reused, e.g. when reaching the end it should start from the beginning again (default: False ) random bool (optional) - if files should be selected by random, instead of sequential from first to last (default: False ) Example With the following directory structure: . \u2514\u2500\u2500 requests \u2514\u2500\u2500 files \u251c\u2500\u2500 file1.bin \u251c\u2500\u2500 file2.bin \u251c\u2500\u2500 file3.bin \u251c\u2500\u2500 file4.bin \u2514\u2500\u2500 file5.bin And value for variable \" AtomicDirectoryContents.files \" is \" files/ | repeat=True, random=False \" And put request \" {{ AtomicDirectoryContents.files }} \" with name \" put-file \" to endpoint \" /tmp \" First request will provide file1.bin , second file2.bin etc.","title":"Directory Contents"},{"location":"framework/usage/variables/testdata/directory-contents/#grizzlytestdatavariablesdirectory_contents","text":"This variable provides a list of files in the specified directory.","title":"grizzly.testdata.variables.directory_contents"},{"location":"framework/usage/variables/testdata/directory-contents/#format","text":"Relative path of a directory under requests/ .","title":"Format"},{"location":"framework/usage/variables/testdata/directory-contents/#arguments","text":"repeat bool (optional) - wether values should be reused, e.g. when reaching the end it should start from the beginning again (default: False ) random bool (optional) - if files should be selected by random, instead of sequential from first to last (default: False )","title":"Arguments"},{"location":"framework/usage/variables/testdata/directory-contents/#example","text":"With the following directory structure: . \u2514\u2500\u2500 requests \u2514\u2500\u2500 files \u251c\u2500\u2500 file1.bin \u251c\u2500\u2500 file2.bin \u251c\u2500\u2500 file3.bin \u251c\u2500\u2500 file4.bin \u2514\u2500\u2500 file5.bin And value for variable \" AtomicDirectoryContents.files \" is \" files/ | repeat=True, random=False \" And put request \" {{ AtomicDirectoryContents.files }} \" with name \" put-file \" to endpoint \" /tmp \" First request will provide file1.bin , second file2.bin etc.","title":"Example"},{"location":"framework/usage/variables/testdata/integer-incrementer/","text":"grizzly.testdata.variables.integer_incrementer This variable provides an unique integer each time it is accessed. Useful to generate unique ID for each request. Format The first value of an integer that is going to be used. Arguments step int , (optional) - how much the value should increment each time (default 1 ) Example And value for variable \" AtomicIntegerIncrementer.unique_id \" is \" 100 | step=10 \" This can then be used in a template: { \"id\" : {{ A t omicI nte gerI n creme nter .u n ique_id }} } First request AtomicIntegerIncrementer.unique_id will be 100 , second 110 , third 120 etc.","title":"Integer incrementer"},{"location":"framework/usage/variables/testdata/integer-incrementer/#grizzlytestdatavariablesinteger_incrementer","text":"This variable provides an unique integer each time it is accessed. Useful to generate unique ID for each request.","title":"grizzly.testdata.variables.integer_incrementer"},{"location":"framework/usage/variables/testdata/integer-incrementer/#format","text":"The first value of an integer that is going to be used.","title":"Format"},{"location":"framework/usage/variables/testdata/integer-incrementer/#arguments","text":"step int , (optional) - how much the value should increment each time (default 1 )","title":"Arguments"},{"location":"framework/usage/variables/testdata/integer-incrementer/#example","text":"And value for variable \" AtomicIntegerIncrementer.unique_id \" is \" 100 | step=10 \" This can then be used in a template: { \"id\" : {{ A t omicI nte gerI n creme nter .u n ique_id }} } First request AtomicIntegerIncrementer.unique_id will be 100 , second 110 , third 120 etc.","title":"Example"},{"location":"framework/usage/variables/testdata/message-queue/","text":"grizzly.testdata.variables.messagequeue Listens for messages on IBM MQ. Use transformer task to extract specific parts of the message. Grizzly must have been installed with the extra mq package and native IBM MQ libraries must be installed for being able to use this variable: pip3 install grizzly-loadtester[mq] Format queue:<queue_name>[, expression:<expression>] | url=<url>, wait=<wait>[, content_type=<content_type>][, repeat=<repeat>] Initial value is the name of the queue, prefixed with queue: , on the MQ server specified in argument url . Expression is optional, and can be specified if a message matching specific criteria is to be fetched. The expression format depends on content type, which needs to be specified as an argument (e.g. XPATH expressions are used with application/xml content type). content_type str (optional) - specifies the content type of messages on the queue, needed if expressions are to be used when getting messages repeat bool (optional) - if True , values read for the queue will be saved in a list and re-used if there are no new messages available url str - see format of url below. wait int - number of seconds to wait for a message on the queue heartbeat_interval int - number of seconds to use for the heartbeat interval (default 300) URL format mq[s]://[<username>:<password>@]<hostname>[:<port>]/?QueueManager=<queue manager>&Channel=<channel>[&KeyFile=<key repository path>[&SslCipher=<ssl cipher>][&CertLabel=<certificate label>]] All variables in the URL have support for templating . mq[s] str - must be specified, mqs implies connecting with TLS, if KeyFile is not set in querystring, it will look for a key repository in ./<username> username str (optional) - username to authenticate with, default None password str (optional) - password to authenticate with, default None hostname str - hostname of MQ server port int (optional) - port on MQ server, default 1414 QueueManager str - name of queue manager Channel str - name of channel to connect to KeyFile str (optional) - path to key repository for certificates needed to connect over TLS SslCipher str (optional) - SSL cipher to use for connection, default ECDHE_RSA_AES_256_GCM_SHA384 CertLabel str (optional) - label of certificate in key repository, default username Example And value for variable \" AtomicMessageQueue.document_id \" is \" queue:IN.DOCUMENTS | wait=120, url='mqs://mq_subscription:$conf::mq.password@mq.example.com/?QueueManager=QM1&Channel=SRV.CONN', repeat=True \" ... Given a user of type \" RestApi \" load testing \" http://example.com \" ... Then get request \" fetch-document \" from \" /api/v1/document/{{ AtomicMessageQueue.document_id }} \" ### Using expression to get specific message And value for variable \" AtomicMessageQueue.document_id \" is \" queue:IN.DOCUMENTS, expression:'//DocumentReference[text()='123abc']' | wait=120, url='mqs://mq_subscription:$conf::mq.password@mq.example.com/?QueueManager=QM1&Channel=SRV.CONN', repeat=True \" And set response content type to \" application/xml \" ... Given a user of type \" RestApi \" load testing \" http://example.com \" ... Then get request \" fetch-document \" from \" /api/v1/document/{{ AtomicMessageQueue.document_id }} \" When the scenario starts grizzly will wait up to 120 seconds until AtomicMessageQueue.document_id has been populated from a message on the queue IN.DOCUMENTS . If there are no messages within 120 seconds, and it is the first iteration of the scenario, it will fail. If there has been at least one message on the queue since the scenario started, it will use the oldest of those values, and then add it back in the end of the list again.","title":"Message Queue"},{"location":"framework/usage/variables/testdata/message-queue/#grizzlytestdatavariablesmessagequeue","text":"Listens for messages on IBM MQ. Use transformer task to extract specific parts of the message. Grizzly must have been installed with the extra mq package and native IBM MQ libraries must be installed for being able to use this variable: pip3 install grizzly-loadtester[mq]","title":"grizzly.testdata.variables.messagequeue"},{"location":"framework/usage/variables/testdata/message-queue/#format","text":"queue:<queue_name>[, expression:<expression>] | url=<url>, wait=<wait>[, content_type=<content_type>][, repeat=<repeat>] Initial value is the name of the queue, prefixed with queue: , on the MQ server specified in argument url . Expression is optional, and can be specified if a message matching specific criteria is to be fetched. The expression format depends on content type, which needs to be specified as an argument (e.g. XPATH expressions are used with application/xml content type). content_type str (optional) - specifies the content type of messages on the queue, needed if expressions are to be used when getting messages repeat bool (optional) - if True , values read for the queue will be saved in a list and re-used if there are no new messages available url str - see format of url below. wait int - number of seconds to wait for a message on the queue heartbeat_interval int - number of seconds to use for the heartbeat interval (default 300)","title":"Format"},{"location":"framework/usage/variables/testdata/message-queue/#url-format","text":"mq[s]://[<username>:<password>@]<hostname>[:<port>]/?QueueManager=<queue manager>&Channel=<channel>[&KeyFile=<key repository path>[&SslCipher=<ssl cipher>][&CertLabel=<certificate label>]] All variables in the URL have support for templating . mq[s] str - must be specified, mqs implies connecting with TLS, if KeyFile is not set in querystring, it will look for a key repository in ./<username> username str (optional) - username to authenticate with, default None password str (optional) - password to authenticate with, default None hostname str - hostname of MQ server port int (optional) - port on MQ server, default 1414 QueueManager str - name of queue manager Channel str - name of channel to connect to KeyFile str (optional) - path to key repository for certificates needed to connect over TLS SslCipher str (optional) - SSL cipher to use for connection, default ECDHE_RSA_AES_256_GCM_SHA384 CertLabel str (optional) - label of certificate in key repository, default username","title":"URL format"},{"location":"framework/usage/variables/testdata/message-queue/#example","text":"And value for variable \" AtomicMessageQueue.document_id \" is \" queue:IN.DOCUMENTS | wait=120, url='mqs://mq_subscription:$conf::mq.password@mq.example.com/?QueueManager=QM1&Channel=SRV.CONN', repeat=True \" ... Given a user of type \" RestApi \" load testing \" http://example.com \" ... Then get request \" fetch-document \" from \" /api/v1/document/{{ AtomicMessageQueue.document_id }} \" ### Using expression to get specific message And value for variable \" AtomicMessageQueue.document_id \" is \" queue:IN.DOCUMENTS, expression:'//DocumentReference[text()='123abc']' | wait=120, url='mqs://mq_subscription:$conf::mq.password@mq.example.com/?QueueManager=QM1&Channel=SRV.CONN', repeat=True \" And set response content type to \" application/xml \" ... Given a user of type \" RestApi \" load testing \" http://example.com \" ... Then get request \" fetch-document \" from \" /api/v1/document/{{ AtomicMessageQueue.document_id }} \" When the scenario starts grizzly will wait up to 120 seconds until AtomicMessageQueue.document_id has been populated from a message on the queue IN.DOCUMENTS . If there are no messages within 120 seconds, and it is the first iteration of the scenario, it will fail. If there has been at least one message on the queue since the scenario started, it will use the oldest of those values, and then add it back in the end of the list again.","title":"Example"},{"location":"framework/usage/variables/testdata/random-integer/","text":"grizzly.testdata.variables.random_integer This variable provides an random integer between specified interval. Format Interval from which the integer should be generated from, in the format <min>..<max> . Arguments This variable does not have any arguments. Example And value for variable \" AtomicRandomInteger.weight \" is \" 10..30 \" This can then be used in a template: { \"weight_tons\" : {{ A t omicRa n domI nte ger.weigh t }} } AtomicRandomInteger.weight will then be anything between, and including, 10 and 30 .","title":"Random Integer"},{"location":"framework/usage/variables/testdata/random-integer/#grizzlytestdatavariablesrandom_integer","text":"This variable provides an random integer between specified interval.","title":"grizzly.testdata.variables.random_integer"},{"location":"framework/usage/variables/testdata/random-integer/#format","text":"Interval from which the integer should be generated from, in the format <min>..<max> .","title":"Format"},{"location":"framework/usage/variables/testdata/random-integer/#arguments","text":"This variable does not have any arguments.","title":"Arguments"},{"location":"framework/usage/variables/testdata/random-integer/#example","text":"And value for variable \" AtomicRandomInteger.weight \" is \" 10..30 \" This can then be used in a template: { \"weight_tons\" : {{ A t omicRa n domI nte ger.weigh t }} } AtomicRandomInteger.weight will then be anything between, and including, 10 and 30 .","title":"Example"},{"location":"framework/usage/variables/testdata/random-string/","text":"grizzly.testdata.variables.random_string This variable generates a specified number of unique strings, based on a string format pattern. The list is pre-populated to ensure that each string is unique. Format Initial value is a string pattern specified with %s and %d . %s represents one ASCII letter %d represents one digit between 0 and 9 Parts of the string can be static, e.g. not random. Arguments count int (optional) - number of unique strings to generate (default: 1 ) upper bool (optional) - if the strings should be in upper case (default: False ) Example And value for variable \" AtomicRandomString.registration_plate_number \" is \" %s%sZ%d%d0 | upper=True, count=100 \" This can then be used in a template: { \"registration_plate_number\" : \"{{ AtomicRandomString.registration_plate_number }}\" } AtomicRandomString.registration_plate_number will then be a string in the format [A-Z][A-Z]Z[0-9][0-9]0 and there will be 100 unique values for disposal.","title":"Random String"},{"location":"framework/usage/variables/testdata/random-string/#grizzlytestdatavariablesrandom_string","text":"This variable generates a specified number of unique strings, based on a string format pattern. The list is pre-populated to ensure that each string is unique.","title":"grizzly.testdata.variables.random_string"},{"location":"framework/usage/variables/testdata/random-string/#format","text":"Initial value is a string pattern specified with %s and %d . %s represents one ASCII letter %d represents one digit between 0 and 9 Parts of the string can be static, e.g. not random.","title":"Format"},{"location":"framework/usage/variables/testdata/random-string/#arguments","text":"count int (optional) - number of unique strings to generate (default: 1 ) upper bool (optional) - if the strings should be in upper case (default: False )","title":"Arguments"},{"location":"framework/usage/variables/testdata/random-string/#example","text":"And value for variable \" AtomicRandomString.registration_plate_number \" is \" %s%sZ%d%d0 | upper=True, count=100 \" This can then be used in a template: { \"registration_plate_number\" : \"{{ AtomicRandomString.registration_plate_number }}\" } AtomicRandomString.registration_plate_number will then be a string in the format [A-Z][A-Z]Z[0-9][0-9]0 and there will be 100 unique values for disposal.","title":"Example"},{"location":"framework/usage/variables/testdata/service-bus/","text":"grizzly.testdata.variables.servicebus Listens for messages on Azure Service Bus queue or topic. Use transformer task to extract specific parts of the message. Format Initial value for a variable must have the prefix queue: or topic: followed by the name of the targeted type. When receiving messages from a topic, the argument subscription: is mandatory. The format of endpoint is: Where <expression> can be a XPath or jsonpath expression, depending on the specified content type. This argument is only allowed when receiving messages. See example below. Warning : Do not use expression to filter messages unless you do not care about the messages that does not match the expression. If you do care about them, you should setup a subscription to do the filtering in Azure. Arguments support templating for their value, but not the complete endpoint value. [queue|topic]:<endpoint name>[, subscription:<subscription name>][, expression:<expression>] Examples : queue:test-queue topic:test-topic, subscription:test-subscription queue:\"$conf::sb.endpoint.queue\" topic:\"$conf::sb.endpoint.topic\", subscription:\"$conf::sb.endpoint.subscription\" queue:\"{{ queue_name }}\", expression=\"$.document[?(@.name=='TPM report')]\" ## Arguments repeat bool (optional) - if True , values read from the endpoint will be saved in a list and re-used if there are no new messages available url str - see format of url below. wait int - number of seconds to wait for a message on the queue content_type str (optional) - specify the MIME type of the message received on the queue, only mandatory when expression is specified in endpoint ### URL format [Endpoint=]sb://<hostname>/;SharedAccessKeyName=<shared key name>;SharedAccessKey=<shared key> The complete url has templating support, but not parts of it. # valid $conf::sb.url # not valid Endpoint=sb://$conf::sb.hostname/;SharedAccessKeyName=$conf::sb.keyname;SharedAccessKey=$conf::sb.key ## Example And value for variable \" AtomicServiceBus.document_id \" is \" queue:documents-in | wait=120, url=$conf::sb.endpoint, repeat=True \" ... Given a user of type \" RestApi \" load testing \" http://example.com \" ... Then get request \" fetch-document \" from \" /api/v1/document/{{ AtomicServiceBus.document_id }} \" When the scenario starts grizzly will wait up to 120 seconds until AtomicServiceBus.document_id has been populated from a message on the queue documents-in . If there are no messages within 120 seconds, and it is the first iteration of the scenario, it will fail. If there has been at least one message on the queue since the scenario started, it will use the oldest of those values, and then add it back in the end of the list again. ### Get message with expression When specifying an expression, the messages on the endpoint is first peeked on. If any message matches the expression, it is later consumed from the endpoint. If no matching messages was found when peeking, it is repeated again up until the specified wait seconds has elapsed. To use expression, a content type must be specified for the endpint, e.g. application/xml . And value for variable \"AtomicServiceBus.tpm_document\" is \"queue:documents-in | wait=120, url=$conf::sb.endpoint, repeat=True, content_type=json, expression='$.document[?(@.name=='TPM Report')'\"","title":"Service Bus"},{"location":"framework/usage/variables/testdata/service-bus/#grizzlytestdatavariablesservicebus","text":"Listens for messages on Azure Service Bus queue or topic. Use transformer task to extract specific parts of the message.","title":"grizzly.testdata.variables.servicebus"},{"location":"framework/usage/variables/testdata/service-bus/#format","text":"Initial value for a variable must have the prefix queue: or topic: followed by the name of the targeted type. When receiving messages from a topic, the argument subscription: is mandatory. The format of endpoint is: Where <expression> can be a XPath or jsonpath expression, depending on the specified content type. This argument is only allowed when receiving messages. See example below. Warning : Do not use expression to filter messages unless you do not care about the messages that does not match the expression. If you do care about them, you should setup a subscription to do the filtering in Azure. Arguments support templating for their value, but not the complete endpoint value. [queue|topic]:<endpoint name>[, subscription:<subscription name>][, expression:<expression>] Examples : queue:test-queue topic:test-topic, subscription:test-subscription queue:\"$conf::sb.endpoint.queue\" topic:\"$conf::sb.endpoint.topic\", subscription:\"$conf::sb.endpoint.subscription\" queue:\"{{ queue_name }}\", expression=\"$.document[?(@.name=='TPM report')]\" ## Arguments repeat bool (optional) - if True , values read from the endpoint will be saved in a list and re-used if there are no new messages available url str - see format of url below. wait int - number of seconds to wait for a message on the queue content_type str (optional) - specify the MIME type of the message received on the queue, only mandatory when expression is specified in endpoint ### URL format [Endpoint=]sb://<hostname>/;SharedAccessKeyName=<shared key name>;SharedAccessKey=<shared key> The complete url has templating support, but not parts of it. # valid $conf::sb.url # not valid Endpoint=sb://$conf::sb.hostname/;SharedAccessKeyName=$conf::sb.keyname;SharedAccessKey=$conf::sb.key ## Example And value for variable \" AtomicServiceBus.document_id \" is \" queue:documents-in | wait=120, url=$conf::sb.endpoint, repeat=True \" ... Given a user of type \" RestApi \" load testing \" http://example.com \" ... Then get request \" fetch-document \" from \" /api/v1/document/{{ AtomicServiceBus.document_id }} \" When the scenario starts grizzly will wait up to 120 seconds until AtomicServiceBus.document_id has been populated from a message on the queue documents-in . If there are no messages within 120 seconds, and it is the first iteration of the scenario, it will fail. If there has been at least one message on the queue since the scenario started, it will use the oldest of those values, and then add it back in the end of the list again. ### Get message with expression When specifying an expression, the messages on the endpoint is first peeked on. If any message matches the expression, it is later consumed from the endpoint. If no matching messages was found when peeking, it is repeated again up until the specified wait seconds has elapsed. To use expression, a content type must be specified for the endpint, e.g. application/xml . And value for variable \"AtomicServiceBus.tpm_document\" is \"queue:documents-in | wait=120, url=$conf::sb.endpoint, repeat=True, content_type=json, expression='$.document[?(@.name=='TPM Report')'\"","title":"Format"}]}