{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Grizzly - /\u02c8\u0261\u0279\u026azli/ Framework: Command Line Interface: Grizzly is a framework to be able to easily define load scenarios, and is mainly built on-top of two other frameworks: Locust : Define user behaviour with Python code, and swarm your system with millions of simultaneous users. Behave : Uses tests written in a natural language style, backed up by Python code. Locust are a group of certain species of short-horned grasshoppers in the family Arcididae that have a swarming phase. The name grizzly was chosen based on the grasshopper Melanoplus punctulatus , also known as grizzly spur-throat grasshopper. This species prefers living in trees over grass, which is a hint to Biometria 1 , where grizzly originally was created. 1 Biometria is a member owned and central actor within the swedish forestry that performs unbiased measurement of lumber flowing between forest and industry so that all of Swedens forest owners can feel confident selling their lumber. Documentation More detailed documentation can be found here and the easiest way to get started is to check out the example . Description behave is ab used for being able to define locust load test scenarios using gherkin . A feature can contain more than one scenario and all scenarios will run in parallell. Feature: Rest API endpoint testing Background: Common properties for all scenarios Given \" 2 \" users And spawn rate is \" 2 \" user per second And stop on first failure Scenario: Authorize Given a user of type \" RestApi \" sending requests to \" https://api.example.com \" And repeat for \" 2 \" iterations And wait time inbetween requests is random between \" 0.1 \" and \" 0.3 \" seconds And value for variable \" AtomicDate.called \" is \" now | format='%Y-%m-%dT%H:%M:%S.00Z', timezone=UTC \" And value for variable \" callback_endpoint \" is \" none \" Then post request with name \" authorize \" from endpoint \" /api/v1/authorize?called={{ AtomicDate.called }} | content_type=json \" \"\"\" { \"username\": \"test\", \"password\": \"password123\", \"callback\": \"/api/v1/user/test\" } \"\"\" Then save response payload \" $.callback \" in variable \" callback_endpoint \" Then get request with name \" user info \" from endpoint \" {{ callback_endpoint }} | content_type=json \" When response payload \" $.user.name \" is not \" Test User \" stop user This makes it possible to implement load test scenarios without knowing python or how to use locust . Features A number of features that we thought locust was missing out-of-the-box has been implemented in grizzly . Test data Support for synchronous handling of test data (variables). This is extra important when running locust distributed and there is a need for each worker and user to have unique test data, that cannot be re-used. The solution is heavily inspired by Karol Brejnas locust experiments - feeding the locust . A producer is running on the master (or local) node and keeps track of what has been sent to the consumer running on a worker (or local) node. The two communicates over a seperate ZeroMQ session. When the consumer wants new test data, it sends a message to the server that it is available and for which scenario it is going to run. The producer then responds with unique test data that can be used. Statistics Listeners for both InfluxDB and Azure Application Insights are included. The later is more or less appinsights_listener.py , from the good guys at Svenska Spel , but with typing. They are useful when history of test runs is needed, or when wanting to correlate load tests with other events in the targeted environment. Load test users locust comes with a simple user for loading an HTTP(S) endpoint and due to the nature of how the integration between behave and locust works in grizzly , it is not possible to directly use locust.user.users provided users, even for HTTP(S) targets. RestApiUser : send requests to REST API endpoinds, supports authentication with username+password or client secret ServiceBusUser : send to and receive from Azure Service Bus queues and topics MessageQueueUser : send and receive from IBM MQ queues SftpUser : send and receive files from an SFTP-server BlobStorageUser : send files to Azure Blob Storage 2 IotHubUser : send/put files to Azure IoT Hub 2 A pull request for functionality in the other direction is appreciated! Request log All failed requests are logged to a file which includes both header and body, both for request and response. Installation pip3 install grizzly-loadtester pip3 install grizzly-loadtester-cli Do not forget to try the example which also serves as a boilerplate scenario project, or create a new grizzly project with: grizzly-cli init my-grizzly-project Development The easiest way to start contributing to this project is to have Visual Studio Code (with \"Remote - Containers\" extension) and docker installed. The project comes with a devcontainer , which encapsulates everything needed for a development environment. It is also possible to use a python virtual environment where requirements-dev.txt is installed.","title":"Overview"},{"location":"#grizzly-zli","text":"Framework: Command Line Interface: Grizzly is a framework to be able to easily define load scenarios, and is mainly built on-top of two other frameworks: Locust : Define user behaviour with Python code, and swarm your system with millions of simultaneous users. Behave : Uses tests written in a natural language style, backed up by Python code. Locust are a group of certain species of short-horned grasshoppers in the family Arcididae that have a swarming phase. The name grizzly was chosen based on the grasshopper Melanoplus punctulatus , also known as grizzly spur-throat grasshopper. This species prefers living in trees over grass, which is a hint to Biometria 1 , where grizzly originally was created. 1 Biometria is a member owned and central actor within the swedish forestry that performs unbiased measurement of lumber flowing between forest and industry so that all of Swedens forest owners can feel confident selling their lumber.","title":"Grizzly - /\u02c8\u0261\u0279\u026azli/"},{"location":"#documentation","text":"More detailed documentation can be found here and the easiest way to get started is to check out the example .","title":"Documentation"},{"location":"#description","text":"behave is ab used for being able to define locust load test scenarios using gherkin . A feature can contain more than one scenario and all scenarios will run in parallell. Feature: Rest API endpoint testing Background: Common properties for all scenarios Given \" 2 \" users And spawn rate is \" 2 \" user per second And stop on first failure Scenario: Authorize Given a user of type \" RestApi \" sending requests to \" https://api.example.com \" And repeat for \" 2 \" iterations And wait time inbetween requests is random between \" 0.1 \" and \" 0.3 \" seconds And value for variable \" AtomicDate.called \" is \" now | format='%Y-%m-%dT%H:%M:%S.00Z', timezone=UTC \" And value for variable \" callback_endpoint \" is \" none \" Then post request with name \" authorize \" from endpoint \" /api/v1/authorize?called={{ AtomicDate.called }} | content_type=json \" \"\"\" { \"username\": \"test\", \"password\": \"password123\", \"callback\": \"/api/v1/user/test\" } \"\"\" Then save response payload \" $.callback \" in variable \" callback_endpoint \" Then get request with name \" user info \" from endpoint \" {{ callback_endpoint }} | content_type=json \" When response payload \" $.user.name \" is not \" Test User \" stop user This makes it possible to implement load test scenarios without knowing python or how to use locust .","title":"Description"},{"location":"#features","text":"A number of features that we thought locust was missing out-of-the-box has been implemented in grizzly .","title":"Features"},{"location":"#test-data","text":"Support for synchronous handling of test data (variables). This is extra important when running locust distributed and there is a need for each worker and user to have unique test data, that cannot be re-used. The solution is heavily inspired by Karol Brejnas locust experiments - feeding the locust . A producer is running on the master (or local) node and keeps track of what has been sent to the consumer running on a worker (or local) node. The two communicates over a seperate ZeroMQ session. When the consumer wants new test data, it sends a message to the server that it is available and for which scenario it is going to run. The producer then responds with unique test data that can be used.","title":"Test data"},{"location":"#statistics","text":"Listeners for both InfluxDB and Azure Application Insights are included. The later is more or less appinsights_listener.py , from the good guys at Svenska Spel , but with typing. They are useful when history of test runs is needed, or when wanting to correlate load tests with other events in the targeted environment.","title":"Statistics"},{"location":"#load-test-users","text":"locust comes with a simple user for loading an HTTP(S) endpoint and due to the nature of how the integration between behave and locust works in grizzly , it is not possible to directly use locust.user.users provided users, even for HTTP(S) targets. RestApiUser : send requests to REST API endpoinds, supports authentication with username+password or client secret ServiceBusUser : send to and receive from Azure Service Bus queues and topics MessageQueueUser : send and receive from IBM MQ queues SftpUser : send and receive files from an SFTP-server BlobStorageUser : send files to Azure Blob Storage 2 IotHubUser : send/put files to Azure IoT Hub 2 A pull request for functionality in the other direction is appreciated!","title":"Load test users"},{"location":"#request-log","text":"All failed requests are logged to a file which includes both header and body, both for request and response.","title":"Request log"},{"location":"#installation","text":"pip3 install grizzly-loadtester pip3 install grizzly-loadtester-cli Do not forget to try the example which also serves as a boilerplate scenario project, or create a new grizzly project with: grizzly-cli init my-grizzly-project","title":"Installation"},{"location":"#development","text":"The easiest way to start contributing to this project is to have Visual Studio Code (with \"Remote - Containers\" extension) and docker installed. The project comes with a devcontainer , which encapsulates everything needed for a development environment. It is also possible to use a python virtual environment where requirements-dev.txt is installed.","title":"Development"},{"location":"example/","text":"Example The directory example/ is an working project that sends requests to public REST API endpoints, please do not abuse these . Structure The project must have the follwoing structure: . \u2514\u2500\u2500 features \u251c\u2500\u2500 environment.py \u251c\u2500\u2500 test.feature \u251c\u2500\u2500 requests \u2502 \u2514\u2500\u2500 ... \u2514\u2500\u2500 steps \u2514\u2500\u2500 steps.py In this example there are two requirements*.txt files. The reason is that requirements.txt will be copied and installed in the container image if grizzly-cli is used. The container image should not contain grizzly-cli and should be installed where scenarios are started from. After installing grizzly-cli the easiest way to get a correct project structure is to use the builtin init subcommand: grizzly-cli init my-grizzly-project cd my-grizzly-project/ Environment features/environment.py should contain: from grizzly.environment import * This file can contain overloading of behave hooks to trigger events that should happen during different stages of running a feature file. from grizzly.environment import before_feature as grizzly_before_feature , after_feature as grizzly_after_feature , before_scenario , after_scenario , before_step def before_feature ( context : Context , * args : Tuple [ Any , ... ], ** kwargs : Dict [ str , Any ]) -> None : # custom code that should run before feature file is started, e.g. notify something that a test # is started grizzly_before_feature ( context , * args , ** kwargs ) def after_feature ( context : Context , feature : Feature , * args : Tuple [ Any , ... ], ** kwargs : Dict [ str , Any ]) -> None : grizzly_after_feature ( context , feature , * args , ** kwargs ) # custom code that should run before feature file is started, e.g. notify something that a test # is finished Steps features/steps/steps.py should contain: from grizzly.steps import * This is where custom step implementation can be added, then should look something like: from behave.runner import Context from behave import then # pylint: disable=no-name-in-module from grizzly.steps import * from grizzly.context import GrizzlyContext @then ( u 'this custom step should be executed' ) def step_custom_the_custom_step ( context : Context ) -> None : grizzly = cast ( GrizzlyContext , context . grizzly ) # custom step implementation Request templates features/requests can contain jinja2 templates used in requests. E.g., if the feature file contains the following step: Then send request \" payload.j2.json \" Then features/requests/payload.j2.json needs to exist. Get First do a sparse checkout of the example/ directory in the repository. If you have git older than 2.25.0 , follow these instructions on stackoverflow.com . Bash PowerShell mkdir grizzly-example cd grizzly-example git init git remote add -f origin https://github.com/Biometria-se/grizzly.git git sparse-checkout init git sparse-checkout set example/ git pull origin main rm -rf .git/ cd example/ mkdir grizzly-example cd .\\ grizzly-example \\ git init git remote add -f origin https :// github . com / Biometria-se / grizzly . git git sparse-checkout init git sparse-checkout set example / git pull origin main rm -Recurse -Force .\\. git \\ cd .\\ example \\ Create an python virtual environment and install dependencies: Bash PowerShell python3 -m venv .env source .env/bin/activate pip3 install -r requirements.txt pip3 install grizzly-loadtester-cli python3 -m venv . env .\\. env \\ Scripts \\ activate pip3 install -r .\\ requirements . txt pip3 install grizzly-loadtester-cli If you do not already have an working \"IBM MQ\" client setup and run grizzly-cli in local mode you will not be able to use MessageQueueUser . See grizzly-cli/static/Containerfile on how to get these. When that is done you need to install the extra dependencies: pip3 install grizzly-loadtester [ mq ] Run grizzly has some runtime features which is easiliest handled by using the grizzly-cli . It provides a simple command line interface wrapping the behave command, for providing initial variable values, configuration etc. To run the example, in local mode: Bash PowerShell grizzly-cli local run -e environments/example.yaml features/example.feature grizzly-cli local run -e .\\ environments \\ example . yaml .\\ features \\ example . feature And in distributed mode (requires docker and docker-compose in PATH ): Bash PowerShell grizzly-cli dist run -e environments/example.yaml features/example.feature grizzly-cli dist run -e .\\ environments \\ example . yaml .\\ features \\ example . feature Develop If you have Visual Studio Code installed, you can also install the grizzly extension to make your life easier when developing scenarios! pip3 install grizzly-loadtester-ls code --install-extension biometria-se.grizzly-loadtester-vscode","title":"Example"},{"location":"example/#example","text":"The directory example/ is an working project that sends requests to public REST API endpoints, please do not abuse these .","title":"Example"},{"location":"example/#structure","text":"The project must have the follwoing structure: . \u2514\u2500\u2500 features \u251c\u2500\u2500 environment.py \u251c\u2500\u2500 test.feature \u251c\u2500\u2500 requests \u2502 \u2514\u2500\u2500 ... \u2514\u2500\u2500 steps \u2514\u2500\u2500 steps.py In this example there are two requirements*.txt files. The reason is that requirements.txt will be copied and installed in the container image if grizzly-cli is used. The container image should not contain grizzly-cli and should be installed where scenarios are started from. After installing grizzly-cli the easiest way to get a correct project structure is to use the builtin init subcommand: grizzly-cli init my-grizzly-project cd my-grizzly-project/","title":"Structure"},{"location":"example/#environment","text":"features/environment.py should contain: from grizzly.environment import * This file can contain overloading of behave hooks to trigger events that should happen during different stages of running a feature file. from grizzly.environment import before_feature as grizzly_before_feature , after_feature as grizzly_after_feature , before_scenario , after_scenario , before_step def before_feature ( context : Context , * args : Tuple [ Any , ... ], ** kwargs : Dict [ str , Any ]) -> None : # custom code that should run before feature file is started, e.g. notify something that a test # is started grizzly_before_feature ( context , * args , ** kwargs ) def after_feature ( context : Context , feature : Feature , * args : Tuple [ Any , ... ], ** kwargs : Dict [ str , Any ]) -> None : grizzly_after_feature ( context , feature , * args , ** kwargs ) # custom code that should run before feature file is started, e.g. notify something that a test # is finished","title":"Environment"},{"location":"example/#steps","text":"features/steps/steps.py should contain: from grizzly.steps import * This is where custom step implementation can be added, then should look something like: from behave.runner import Context from behave import then # pylint: disable=no-name-in-module from grizzly.steps import * from grizzly.context import GrizzlyContext @then ( u 'this custom step should be executed' ) def step_custom_the_custom_step ( context : Context ) -> None : grizzly = cast ( GrizzlyContext , context . grizzly ) # custom step implementation","title":"Steps"},{"location":"example/#request-templates","text":"features/requests can contain jinja2 templates used in requests. E.g., if the feature file contains the following step: Then send request \" payload.j2.json \" Then features/requests/payload.j2.json needs to exist.","title":"Request templates"},{"location":"example/#get","text":"First do a sparse checkout of the example/ directory in the repository. If you have git older than 2.25.0 , follow these instructions on stackoverflow.com . Bash PowerShell mkdir grizzly-example cd grizzly-example git init git remote add -f origin https://github.com/Biometria-se/grizzly.git git sparse-checkout init git sparse-checkout set example/ git pull origin main rm -rf .git/ cd example/ mkdir grizzly-example cd .\\ grizzly-example \\ git init git remote add -f origin https :// github . com / Biometria-se / grizzly . git git sparse-checkout init git sparse-checkout set example / git pull origin main rm -Recurse -Force .\\. git \\ cd .\\ example \\ Create an python virtual environment and install dependencies: Bash PowerShell python3 -m venv .env source .env/bin/activate pip3 install -r requirements.txt pip3 install grizzly-loadtester-cli python3 -m venv . env .\\. env \\ Scripts \\ activate pip3 install -r .\\ requirements . txt pip3 install grizzly-loadtester-cli If you do not already have an working \"IBM MQ\" client setup and run grizzly-cli in local mode you will not be able to use MessageQueueUser . See grizzly-cli/static/Containerfile on how to get these. When that is done you need to install the extra dependencies: pip3 install grizzly-loadtester [ mq ]","title":"Get"},{"location":"example/#run","text":"grizzly has some runtime features which is easiliest handled by using the grizzly-cli . It provides a simple command line interface wrapping the behave command, for providing initial variable values, configuration etc. To run the example, in local mode: Bash PowerShell grizzly-cli local run -e environments/example.yaml features/example.feature grizzly-cli local run -e .\\ environments \\ example . yaml .\\ features \\ example . feature And in distributed mode (requires docker and docker-compose in PATH ): Bash PowerShell grizzly-cli dist run -e environments/example.yaml features/example.feature grizzly-cli dist run -e .\\ environments \\ example . yaml .\\ features \\ example . feature","title":"Run"},{"location":"example/#develop","text":"If you have Visual Studio Code installed, you can also install the grizzly extension to make your life easier when developing scenarios! pip3 install grizzly-loadtester-ls code --install-extension biometria-se.grizzly-loadtester-vscode","title":"Develop"},{"location":"command-line-interface/changelog/","text":"Changelog v3.1.4 0cfd9e9f : implemented support for --csv* arguments (#65) v3.1.3 e211442c : grizzly support templating for user weight v3.1.2 8c7b8915 : annotate notices in feature metadata (comments) that grizzly-cli will show v3.1.1 4df22703 : check for return code in command output da9c0f0d : add wheel as dev dependency v3.1.0 f0a6b13b : fixed copy-paste error in publish package step 40b83dc5 : fixed indentation for inputs in release workflow (#61) 34235b59 : fixed warnings from coverage when running e2e tests (#60) 771eb3e1 : implementation of issue #159 a9f6982c : ::set-output deprecated (#58) 159b313a : v3.0.10 comes after v3.0.1, so latest is v3.0.9 (lexicographic order) -- use sort -r --version-sort (#57) 5404d7ae : assume a remote branch if git cat-file fails fb1f2608 : set LANG and LC_ALL to C.UTF-8 instead of C bdd0f7a3 : improved grizzly version crawling 238a989c : oooh man... encoding on the windows-latest runner :S 924486e6 : make End2EndFixture windows compatible 35b3b18b : remove user and group in grizzly image, if they exists f2f20240 : update versions of github actions checkout and setup-python bf4050e2 : e2e test of grizzly-cli init e96ee349 : e2e test for grizzly init 9af2236c : restructure of tests and added e2e tests 0032002c : fixed unit tests for windows 086df974 : optimization of listing files for bash completion v3.0.9 d91ba37e : workdir changed, correct entrypoint script path (#51) v3.0.8 61f8699e : simplified format_text for md-help (#50) 13c3e809 : set workdir to /srv/grizzly v3.0.7 84590d5c : implementation of grizzly-cli dist clean (#48) 05c628fb : changes for being able to use in E2E tests (#47) v3.0.6 215522a1 : possibility to inject grizzly-cli command arguments via metadata specified in feature file 140f7484 : argument to increase how long the master will wait for worker report v3.0.5 7c3bb2f6 : change version of IBM MQ Redist, and allow it to be overriden v3.0.4 75690e56 : pkg-resources is some kind of meta package, ignore in license table (#44) v3.0.3 6df5c857 : update script that generates licenses information (#43) v3.0.2 159b313a : v3.0.10 comes after v3.0.1, so latest is v3.0.9 (lexicographic order) -- use sort -r --version-sort (#57) 5404d7ae : assume a remote branch if git cat-file fails fb1f2608 : set LANG and LC_ALL to C.UTF-8 instead of C bdd0f7a3 : improved grizzly version crawling 238a989c : oooh man... encoding on the windows-latest runner :S 924486e6 : make End2EndFixture windows compatible 35b3b18b : remove user and group in grizzly image, if they exists f2f20240 : update versions of github actions checkout and setup-python bf4050e2 : e2e test of grizzly-cli init e96ee349 : e2e test for grizzly init 9af2236c : restructure of tests and added e2e tests 0032002c : fixed unit tests for windows 086df974 : optimization of listing files for bash completion d91ba37e : workdir changed, correct entrypoint script path (#51) 61f8699e : simplified format_text for md-help (#50) 13c3e809 : set workdir to /srv/grizzly 84590d5c : implementation of grizzly-cli dist clean (#48) 05c628fb : changes for being able to use in E2E tests (#47) 215522a1 : possibility to inject grizzly-cli command arguments via metadata specified in feature file 140f7484 : argument to increase how long the master will wait for worker report 7c3bb2f6 : change version of IBM MQ Redist, and allow it to be overriden 75690e56 : pkg-resources is some kind of meta package, ignore in license table (#44) 6df5c857 : update script that generates licenses information (#43) v3.0.11 159b313a : v3.0.10 comes after v3.0.1, so latest is v3.0.9 (lexicographic order) -- use sort -r --version-sort (#57) 5404d7ae : assume a remote branch if git cat-file fails v3.0.10 fb1f2608 : set LANG and LC_ALL to C.UTF-8 instead of C bdd0f7a3 : improved grizzly version crawling 238a989c : oooh man... encoding on the windows-latest runner :S 924486e6 : make End2EndFixture windows compatible 35b3b18b : remove user and group in grizzly image, if they exists f2f20240 : update versions of github actions checkout and setup-python bf4050e2 : e2e test of grizzly-cli init e96ee349 : e2e test for grizzly init 9af2236c : restructure of tests and added e2e tests 0032002c : fixed unit tests for windows 086df974 : optimization of listing files for bash completion d91ba37e : workdir changed, correct entrypoint script path (#51) 61f8699e : simplified format_text for md-help (#50) 13c3e809 : set workdir to /srv/grizzly 84590d5c : implementation of grizzly-cli dist clean (#48) 05c628fb : changes for being able to use in E2E tests (#47) 215522a1 : possibility to inject grizzly-cli command arguments via metadata specified in feature file 140f7484 : argument to increase how long the master will wait for worker report 7c3bb2f6 : change version of IBM MQ Redist, and allow it to be overriden 75690e56 : pkg-resources is some kind of meta package, ignore in license table (#44) 6df5c857 : update script that generates licenses information (#43) bb270a82 : changed grizzly_cli.SCENARIOS to a list to get guaranteed insertion order (#42) v3.0.1 df5a4902 : --yes argument to automagically answer yes on any questions 0b57d739 : subcommand is not set for command init 43ccba6b : do not sort scenarios by name, iterate in the order they are defined dd4b5e7b : adaptations for Biometria-se/grizzly#71 v3.0.0 267ee8df : restructuring commands c1170417 : step expression for number of users can be singular (#37) v2.1.6 803b3f3a : users per scenario is calculated incorrectly (#36) 065b1e5c : documentation of IBM_MQ_LIB_HOST environment variable (#35) e73174b2 : make sure that it is possible to generate licenses documentation (#34) a574b5c4 : github action action-push-tag@v1 is broken (#33) v2.1.5 e3eb9073 : no smoothed timeline in test summary 2d706e0f : --add-host if overridden IBM_MQ_LIB_HOST is using host.docker.internal (#31) v2.1.4 220924f6 : fix failing tests 45fc7718 : possible to override host where IBM MQ lib redist package should be downloaded from d34ebbf8 : script for generating a license summary (#29) v2.1.3 49116c42 : check if container image should be built with or without mq libraries 50ec4869 : check if grizzly-loadtester is installed with any extras 447f677e : Containerfile updated to have MQ libraries as optional 64b2131a : unable to use cache functionality of setup-python@v2 241bdb22 : fix for Biometria-se/grizzly#73 340cfd18 : only run code quality workflow on 3.10 on windows e11c1b09 : docker-compose v2 and v1 compatible in instructions 1db75e0b : base on 3.10-slim instead of alpine a7dc5ce6 : add --no-tty argument to run dist 8d3d83ee : more dynamic creation of sub command parsers 03652ae8 : build package based on metadata only v2.1.2 344bc53b : remove debug prints that fell through quality control v2.1.1 d41cde5c : added missing dependency (#24) v2.1.0 4feb4ec5 : build grizzly container image based on locust container image version that the project depends on 4e3ec441 : implementation of getting dependencies version 4ffc4535 : WIP: get grizzly and locust version from project 64b5eaef : Feature/spring 2022 cleanup (#22) v2.0.4 c9c0c24b : fix tty size in container (#20) v2.0.3 234e9c05 : getattr retrives value of registry in args, but if it is None (#19) v2.0.2 37da0e73 : Feature/build parser (#18) 7c64bd0b : added arguments for controlling compose health checks (#17) v2.0.1 83b08112 : build broken for 2.0.0 (#16) v2.0.0 d624baa7 : Feature/run windows 57 (#15) f20dccfa : too greedy gitignore rule resulted in missing new workflow (#14) 724bd70e : Feature/argument refactor (#13) 97ab0e45 : refreshed devcontainer (#12) v1.1.1 ae46c7a6 : do not expose locust webui port (8089) in compose file (#11) v1.1.0 9be8b64b : Feature/validate iterations prompt (#10) v1.0.9 2cd470ae : remove locust user (uid 1000) when building grizzly container image (#9) v1.0.8 cca24c6b : create a user with uid/gid matching user that executes grizzly-cli (#8) v1.0.7 4bee4c7b : get IBM MQ client logs when running distributed (#7) v1.0.6 746d7219 : expose internal environment variables in execution context (#6) v1.0.5 824f163d : lock locust image version to version of locust used by grizzly v1.0.4 f8fd5c9d : ask for value expression can have more than one keyword (#5) v1.0.3 c0eacc1a : set MTU in docker-compose network to the same value as the default bridge has 964e6993 : updated pylint configuration v1.0.2 0d5ec1ba : also get tags ffd52159 : change development version to 0.0.0 v1.0.1 7fc1fa1b : set ulimit nofile to min recommended value for locust","title":"Changelog"},{"location":"command-line-interface/changelog/#changelog","text":"","title":"Changelog"},{"location":"command-line-interface/changelog/#v314","text":"0cfd9e9f : implemented support for --csv* arguments (#65)","title":"v3.1.4"},{"location":"command-line-interface/changelog/#v313","text":"e211442c : grizzly support templating for user weight","title":"v3.1.3"},{"location":"command-line-interface/changelog/#v312","text":"8c7b8915 : annotate notices in feature metadata (comments) that grizzly-cli will show","title":"v3.1.2"},{"location":"command-line-interface/changelog/#v311","text":"4df22703 : check for return code in command output da9c0f0d : add wheel as dev dependency","title":"v3.1.1"},{"location":"command-line-interface/changelog/#v310","text":"f0a6b13b : fixed copy-paste error in publish package step 40b83dc5 : fixed indentation for inputs in release workflow (#61) 34235b59 : fixed warnings from coverage when running e2e tests (#60) 771eb3e1 : implementation of issue #159 a9f6982c : ::set-output deprecated (#58) 159b313a : v3.0.10 comes after v3.0.1, so latest is v3.0.9 (lexicographic order) -- use sort -r --version-sort (#57) 5404d7ae : assume a remote branch if git cat-file fails fb1f2608 : set LANG and LC_ALL to C.UTF-8 instead of C bdd0f7a3 : improved grizzly version crawling 238a989c : oooh man... encoding on the windows-latest runner :S 924486e6 : make End2EndFixture windows compatible 35b3b18b : remove user and group in grizzly image, if they exists f2f20240 : update versions of github actions checkout and setup-python bf4050e2 : e2e test of grizzly-cli init e96ee349 : e2e test for grizzly init 9af2236c : restructure of tests and added e2e tests 0032002c : fixed unit tests for windows 086df974 : optimization of listing files for bash completion","title":"v3.1.0"},{"location":"command-line-interface/changelog/#v309","text":"d91ba37e : workdir changed, correct entrypoint script path (#51)","title":"v3.0.9"},{"location":"command-line-interface/changelog/#v308","text":"61f8699e : simplified format_text for md-help (#50) 13c3e809 : set workdir to /srv/grizzly","title":"v3.0.8"},{"location":"command-line-interface/changelog/#v307","text":"84590d5c : implementation of grizzly-cli dist clean (#48) 05c628fb : changes for being able to use in E2E tests (#47)","title":"v3.0.7"},{"location":"command-line-interface/changelog/#v306","text":"215522a1 : possibility to inject grizzly-cli command arguments via metadata specified in feature file 140f7484 : argument to increase how long the master will wait for worker report","title":"v3.0.6"},{"location":"command-line-interface/changelog/#v305","text":"7c3bb2f6 : change version of IBM MQ Redist, and allow it to be overriden","title":"v3.0.5"},{"location":"command-line-interface/changelog/#v304","text":"75690e56 : pkg-resources is some kind of meta package, ignore in license table (#44)","title":"v3.0.4"},{"location":"command-line-interface/changelog/#v303","text":"6df5c857 : update script that generates licenses information (#43)","title":"v3.0.3"},{"location":"command-line-interface/changelog/#v302","text":"159b313a : v3.0.10 comes after v3.0.1, so latest is v3.0.9 (lexicographic order) -- use sort -r --version-sort (#57) 5404d7ae : assume a remote branch if git cat-file fails fb1f2608 : set LANG and LC_ALL to C.UTF-8 instead of C bdd0f7a3 : improved grizzly version crawling 238a989c : oooh man... encoding on the windows-latest runner :S 924486e6 : make End2EndFixture windows compatible 35b3b18b : remove user and group in grizzly image, if they exists f2f20240 : update versions of github actions checkout and setup-python bf4050e2 : e2e test of grizzly-cli init e96ee349 : e2e test for grizzly init 9af2236c : restructure of tests and added e2e tests 0032002c : fixed unit tests for windows 086df974 : optimization of listing files for bash completion d91ba37e : workdir changed, correct entrypoint script path (#51) 61f8699e : simplified format_text for md-help (#50) 13c3e809 : set workdir to /srv/grizzly 84590d5c : implementation of grizzly-cli dist clean (#48) 05c628fb : changes for being able to use in E2E tests (#47) 215522a1 : possibility to inject grizzly-cli command arguments via metadata specified in feature file 140f7484 : argument to increase how long the master will wait for worker report 7c3bb2f6 : change version of IBM MQ Redist, and allow it to be overriden 75690e56 : pkg-resources is some kind of meta package, ignore in license table (#44) 6df5c857 : update script that generates licenses information (#43)","title":"v3.0.2"},{"location":"command-line-interface/changelog/#v3011","text":"159b313a : v3.0.10 comes after v3.0.1, so latest is v3.0.9 (lexicographic order) -- use sort -r --version-sort (#57) 5404d7ae : assume a remote branch if git cat-file fails","title":"v3.0.11"},{"location":"command-line-interface/changelog/#v3010","text":"fb1f2608 : set LANG and LC_ALL to C.UTF-8 instead of C bdd0f7a3 : improved grizzly version crawling 238a989c : oooh man... encoding on the windows-latest runner :S 924486e6 : make End2EndFixture windows compatible 35b3b18b : remove user and group in grizzly image, if they exists f2f20240 : update versions of github actions checkout and setup-python bf4050e2 : e2e test of grizzly-cli init e96ee349 : e2e test for grizzly init 9af2236c : restructure of tests and added e2e tests 0032002c : fixed unit tests for windows 086df974 : optimization of listing files for bash completion d91ba37e : workdir changed, correct entrypoint script path (#51) 61f8699e : simplified format_text for md-help (#50) 13c3e809 : set workdir to /srv/grizzly 84590d5c : implementation of grizzly-cli dist clean (#48) 05c628fb : changes for being able to use in E2E tests (#47) 215522a1 : possibility to inject grizzly-cli command arguments via metadata specified in feature file 140f7484 : argument to increase how long the master will wait for worker report 7c3bb2f6 : change version of IBM MQ Redist, and allow it to be overriden 75690e56 : pkg-resources is some kind of meta package, ignore in license table (#44) 6df5c857 : update script that generates licenses information (#43) bb270a82 : changed grizzly_cli.SCENARIOS to a list to get guaranteed insertion order (#42)","title":"v3.0.10"},{"location":"command-line-interface/changelog/#v301","text":"df5a4902 : --yes argument to automagically answer yes on any questions 0b57d739 : subcommand is not set for command init 43ccba6b : do not sort scenarios by name, iterate in the order they are defined dd4b5e7b : adaptations for Biometria-se/grizzly#71","title":"v3.0.1"},{"location":"command-line-interface/changelog/#v300","text":"267ee8df : restructuring commands c1170417 : step expression for number of users can be singular (#37)","title":"v3.0.0"},{"location":"command-line-interface/changelog/#v216","text":"803b3f3a : users per scenario is calculated incorrectly (#36) 065b1e5c : documentation of IBM_MQ_LIB_HOST environment variable (#35) e73174b2 : make sure that it is possible to generate licenses documentation (#34) a574b5c4 : github action action-push-tag@v1 is broken (#33)","title":"v2.1.6"},{"location":"command-line-interface/changelog/#v215","text":"e3eb9073 : no smoothed timeline in test summary 2d706e0f : --add-host if overridden IBM_MQ_LIB_HOST is using host.docker.internal (#31)","title":"v2.1.5"},{"location":"command-line-interface/changelog/#v214","text":"220924f6 : fix failing tests 45fc7718 : possible to override host where IBM MQ lib redist package should be downloaded from d34ebbf8 : script for generating a license summary (#29)","title":"v2.1.4"},{"location":"command-line-interface/changelog/#v213","text":"49116c42 : check if container image should be built with or without mq libraries 50ec4869 : check if grizzly-loadtester is installed with any extras 447f677e : Containerfile updated to have MQ libraries as optional 64b2131a : unable to use cache functionality of setup-python@v2 241bdb22 : fix for Biometria-se/grizzly#73 340cfd18 : only run code quality workflow on 3.10 on windows e11c1b09 : docker-compose v2 and v1 compatible in instructions 1db75e0b : base on 3.10-slim instead of alpine a7dc5ce6 : add --no-tty argument to run dist 8d3d83ee : more dynamic creation of sub command parsers 03652ae8 : build package based on metadata only","title":"v2.1.3"},{"location":"command-line-interface/changelog/#v212","text":"344bc53b : remove debug prints that fell through quality control","title":"v2.1.2"},{"location":"command-line-interface/changelog/#v211","text":"d41cde5c : added missing dependency (#24)","title":"v2.1.1"},{"location":"command-line-interface/changelog/#v210","text":"4feb4ec5 : build grizzly container image based on locust container image version that the project depends on 4e3ec441 : implementation of getting dependencies version 4ffc4535 : WIP: get grizzly and locust version from project 64b5eaef : Feature/spring 2022 cleanup (#22)","title":"v2.1.0"},{"location":"command-line-interface/changelog/#v204","text":"c9c0c24b : fix tty size in container (#20)","title":"v2.0.4"},{"location":"command-line-interface/changelog/#v203","text":"234e9c05 : getattr retrives value of registry in args, but if it is None (#19)","title":"v2.0.3"},{"location":"command-line-interface/changelog/#v202","text":"37da0e73 : Feature/build parser (#18) 7c64bd0b : added arguments for controlling compose health checks (#17)","title":"v2.0.2"},{"location":"command-line-interface/changelog/#v201","text":"83b08112 : build broken for 2.0.0 (#16)","title":"v2.0.1"},{"location":"command-line-interface/changelog/#v200","text":"d624baa7 : Feature/run windows 57 (#15) f20dccfa : too greedy gitignore rule resulted in missing new workflow (#14) 724bd70e : Feature/argument refactor (#13) 97ab0e45 : refreshed devcontainer (#12)","title":"v2.0.0"},{"location":"command-line-interface/changelog/#v111","text":"ae46c7a6 : do not expose locust webui port (8089) in compose file (#11)","title":"v1.1.1"},{"location":"command-line-interface/changelog/#v110","text":"9be8b64b : Feature/validate iterations prompt (#10)","title":"v1.1.0"},{"location":"command-line-interface/changelog/#v109","text":"2cd470ae : remove locust user (uid 1000) when building grizzly container image (#9)","title":"v1.0.9"},{"location":"command-line-interface/changelog/#v108","text":"cca24c6b : create a user with uid/gid matching user that executes grizzly-cli (#8)","title":"v1.0.8"},{"location":"command-line-interface/changelog/#v107","text":"4bee4c7b : get IBM MQ client logs when running distributed (#7)","title":"v1.0.7"},{"location":"command-line-interface/changelog/#v106","text":"746d7219 : expose internal environment variables in execution context (#6)","title":"v1.0.6"},{"location":"command-line-interface/changelog/#v105","text":"824f163d : lock locust image version to version of locust used by grizzly","title":"v1.0.5"},{"location":"command-line-interface/changelog/#v104","text":"f8fd5c9d : ask for value expression can have more than one keyword (#5)","title":"v1.0.4"},{"location":"command-line-interface/changelog/#v103","text":"c0eacc1a : set MTU in docker-compose network to the same value as the default bridge has 964e6993 : updated pylint configuration","title":"v1.0.3"},{"location":"command-line-interface/changelog/#v102","text":"0d5ec1ba : also get tags ffd52159 : change development version to 0.0.0","title":"v1.0.2"},{"location":"command-line-interface/changelog/#v101","text":"7fc1fa1b : set ulimit nofile to min recommended value for locust","title":"v1.0.1"},{"location":"command-line-interface/licenses/","text":"Licenses The MIT License (MIT) Copyright \u00a9 2021 Biometria Ekonomiska F\u00f6rening Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \u201cSoftware\u201d), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \u201cAS IS\u201d, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Third party licenses Python dependencies Name Version License coverage 6.5.0 Apache Software License requests 2.28.1 Apache Software License requests-mock 1.10.0 Apache Software License types-PyYAML 6.0.12.2 Apache Software License types-requests 2.28.11.5 Apache Software License types-urllib3 1.26.25.4 Apache Software License packaging 21.3 Apache Software License; BSD License python-dateutil 2.8.2 Apache Software License; BSD License Flask 2.0.3 BSD License Jinja2 3.1.2 BSD License MarkupSafe 2.1.1 BSD License Werkzeug 2.2.2 BSD License behave 1.2.6 BSD License click 8.1.3 BSD License dill 0.3.6 BSD License idna 3.4 BSD License itsdangerous 2.1.2 BSD License lazy-object-proxy 1.8.0 BSD License line-profiler 4.0.2 BSD License parse 1.19.0 BSD License parse-type 0.6.0 BSD License wrapt 1.14.1 BSD License pytest-timeout 2.1.0 DFSG approved; MIT License pylint 2.15.8 GNU General Public License v2 (GPLv2) astroid 2.12.13 GNU Lesser General Public License v2 (LGPLv2) chardet 4.0.0 GNU Library or Lesser General Public License (LGPL) DataProperty 0.55.0 MIT License Flake8-pyproject 1.2.2 MIT License PyYAML 6.0 MIT License atomicwrites 1.4.1 MIT License attrs 22.1.0 MIT License charset-normalizer 2.1.1 MIT License exceptiongroup 1.0.4 MIT License flake8 6.0.0 MIT License gevent 21.12.0 MIT License greenlet 1.1.3.post0 MIT License iniconfig 1.1.1 MIT License isort 5.11.2 MIT License mbstrdecoder 1.1.1 MIT License mccabe 0.7.0 MIT License mypy 0.991 MIT License mypy-extensions 0.4.3 MIT License pathvalidate 2.5.2 MIT License platformdirs 2.6.0 MIT License pluggy 1.0.0 MIT License pycodestyle 2.10.0 MIT License pyflakes 3.0.1 MIT License pyparsing 3.0.9 MIT License pytablewriter 0.64.2 MIT License pytest 7.2.0 MIT License pytest-cov 4.0.0 MIT License pytest-mock 3.10.0 MIT License pytz 2022.6 MIT License setuptools-scm 7.0.5 MIT License six 1.16.0 MIT License tabledata 1.3.0 MIT License tcolorpy 0.1.2 MIT License tomli 1.2.3 MIT License tomlkit 0.11.6 MIT License typepy 1.3.0 MIT License urllib3 1.26.13 MIT License certifi 2022.12.7 Mozilla Public License 2.0 (MPL 2.0) typing_extensions 4.4.0 Python Software Foundation License zope.event 4.6 Zope Public License","title":"Licenses"},{"location":"command-line-interface/licenses/#licenses","text":"","title":"Licenses"},{"location":"command-line-interface/licenses/#the-mit-license-mit","text":"Copyright \u00a9 2021 Biometria Ekonomiska F\u00f6rening Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \u201cSoftware\u201d), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \u201cAS IS\u201d, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"The MIT License (MIT)"},{"location":"command-line-interface/licenses/#third-party-licenses","text":"","title":"Third party licenses"},{"location":"command-line-interface/licenses/#python-dependencies","text":"Name Version License coverage 6.5.0 Apache Software License requests 2.28.1 Apache Software License requests-mock 1.10.0 Apache Software License types-PyYAML 6.0.12.2 Apache Software License types-requests 2.28.11.5 Apache Software License types-urllib3 1.26.25.4 Apache Software License packaging 21.3 Apache Software License; BSD License python-dateutil 2.8.2 Apache Software License; BSD License Flask 2.0.3 BSD License Jinja2 3.1.2 BSD License MarkupSafe 2.1.1 BSD License Werkzeug 2.2.2 BSD License behave 1.2.6 BSD License click 8.1.3 BSD License dill 0.3.6 BSD License idna 3.4 BSD License itsdangerous 2.1.2 BSD License lazy-object-proxy 1.8.0 BSD License line-profiler 4.0.2 BSD License parse 1.19.0 BSD License parse-type 0.6.0 BSD License wrapt 1.14.1 BSD License pytest-timeout 2.1.0 DFSG approved; MIT License pylint 2.15.8 GNU General Public License v2 (GPLv2) astroid 2.12.13 GNU Lesser General Public License v2 (LGPLv2) chardet 4.0.0 GNU Library or Lesser General Public License (LGPL) DataProperty 0.55.0 MIT License Flake8-pyproject 1.2.2 MIT License PyYAML 6.0 MIT License atomicwrites 1.4.1 MIT License attrs 22.1.0 MIT License charset-normalizer 2.1.1 MIT License exceptiongroup 1.0.4 MIT License flake8 6.0.0 MIT License gevent 21.12.0 MIT License greenlet 1.1.3.post0 MIT License iniconfig 1.1.1 MIT License isort 5.11.2 MIT License mbstrdecoder 1.1.1 MIT License mccabe 0.7.0 MIT License mypy 0.991 MIT License mypy-extensions 0.4.3 MIT License pathvalidate 2.5.2 MIT License platformdirs 2.6.0 MIT License pluggy 1.0.0 MIT License pycodestyle 2.10.0 MIT License pyflakes 3.0.1 MIT License pyparsing 3.0.9 MIT License pytablewriter 0.64.2 MIT License pytest 7.2.0 MIT License pytest-cov 4.0.0 MIT License pytest-mock 3.10.0 MIT License pytz 2022.6 MIT License setuptools-scm 7.0.5 MIT License six 1.16.0 MIT License tabledata 1.3.0 MIT License tcolorpy 0.1.2 MIT License tomli 1.2.3 MIT License tomlkit 0.11.6 MIT License typepy 1.3.0 MIT License urllib3 1.26.13 MIT License certifi 2022.12.7 Mozilla Public License 2.0 (MPL 2.0) typing_extensions 4.4.0 Python Software Foundation License zope.event 4.6 Zope Public License","title":"Python dependencies"},{"location":"command-line-interface/usage/","text":"grizzly-cli the command line interface for grizzly, which makes it easer to start a test with all features of grizzly wrapped up nicely. installing it is a matter of: pip install grizzly-loadtester-cli enable bash completion by adding the following to your shell profile: eval \" $( grizzly-cli --bash-completion ) \" Usage grizzly-cli [ -h ] [ --version [{ all }]] { init,local,dist } ... Positional arguments argument default help command Optional arguments argument default help --version print version of command line interface, and exit. add argument all to get versions of dependencies grizzly-cli init create a skeleton project with required structure and files. Usage grizzly-cli init [ -h ] [ --grizzly-version GRIZZLY_VERSION ] [ --with-mq ] [ -y ] project Positional arguments argument default help project project name, a directory will be created with this name Optional arguments argument default help --grizzly-version specify which grizzly version to use for project, default is latest --with-mq False if grizzly should be installed with IBM MQ support (external dependencies excluded) -y, --yes False automagically answer yes on any questions grizzly-cli local commands for running grizzly in local mode. Usage grizzly-cli local [ -h ] { run } ... Positional arguments argument default help subcommand grizzly-cli local run execute load test scenarios specified in a feature file. Usage grizzly-cli local run [ -h ] [ --verbose ] [ -T TESTDATA_VARIABLE ] [ -y ] [ -e ENVIRONMENT_FILE ] [ --csv-prefix [ CSV_PREFIX ]] [ --csv-interval CSV_INTERVAL ] [ --csv-flush-interval CSV_FLUSH_INTERVAL ] file [ file ... ] Positional arguments argument default help file path to feature file with one or more scenarios Optional arguments argument default help --verbose False changes the log level to DEBUG , regardless of what it says in the feature file. gives more verbose logging that can be useful when troubleshooting a problem with a scenario. -T, --testdata-variable specified in the format <name>=<value> . avoids being asked for an initial value for a scenario variable. -y, --yes False answer yes on any questions that would require confirmation -e, --environment-file configuration file with environment specific information --csv-prefix write log statistics to CSV files with specified prefix, if no value is specified the description of the gherkin Feature tag will be used, suffixed with timestamp --csv-interval interval that statistics is collected for CSV files, can only be used in combination with --csv-prefix --csv-flush-interval interval that CSV statistics is flushed to disk, can only be used in combination with --csv-prefix grizzly-cli dist commands for running grizzly i distributed mode. Usage grizzly-cli dist [ -h ] [ --workers WORKERS ] [ --id ID ] [ --limit-nofile LIMIT_NOFILE ] [ --health-retries HEALTH_RETRIES ] [ --health-timeout HEALTH_TIMEOUT ] [ --health-interval HEALTH_INTERVAL ] [ --registry REGISTRY ] [ --tty ] [ --wait-for-worker WAIT_FOR_WORKER ] [ --project-name PROJECT_NAME ] [ --force-build | --build | --validate-config ] { build,clean,run } ... Positional arguments argument default help subcommand Optional arguments argument default help --workers 1 how many instances of the workers container that should be created --id unique identifier suffixed to compose project, should be used when the same user needs to run more than one instance of grizzly-cli --limit-nofile 10001 set system limit \"number of open files\" --health-retries 3 set number of retries for health check of master container --health-timeout 3 set timeout in seconds for health check of master container --health-interval 5 set interval in seconds between health checks of master container --registry push built image to this registry, if the registry has authentication you need to login first --tty False start containers with a TTY enabled --wait-for-worker sets enviroment variable LOCUST_WAIT_FOR_WORKERS_REPORT_AFTER_RAMP_UP, which tells master to wait this amount of time for worker report --project-name override project name, which otherwise would be the name of the directory where command is executed in --force-build False force rebuild the grizzly projects container image (no cache) --build False rebuild the grizzly projects container images (with cache) --validate-config False validate and print compose project file grizzly-cli dist build build grizzly compose project container image before running test. if worker nodes runs on different physical computers, it is mandatory to build the images before hand and push to a registry. if image includes IBM MQ native dependencies, the build time increases due to download times. it is possible to self- host the archive and override the download host with environment variable IBM_MQ_LIB_HOST . Usage grizzly-cli dist build [ -h ] [ --no-cache ] [ --registry REGISTRY ] Optional arguments argument default help --no-cache False build container image with out cache (full build) --registry push built image to this registry, if the registry has authentication you need to login first grizzly-cli dist clean clean all grizzly compose project resources; containers, images, networks and volumes Usage grizzly-cli dist clean [ -h ] [ --no-images ] [ --no-networks ] Optional arguments argument default help --no-images True do not remove images --no-networks True do not remove networks grizzly-cli dist run execute load test scenarios specified in a feature file. Usage grizzly-cli dist run [ -h ] [ --verbose ] [ -T TESTDATA_VARIABLE ] [ -y ] [ -e ENVIRONMENT_FILE ] [ --csv-prefix [ CSV_PREFIX ]] [ --csv-interval CSV_INTERVAL ] [ --csv-flush-interval CSV_FLUSH_INTERVAL ] file [ file ... ] Positional arguments argument default help file path to feature file with one or more scenarios Optional arguments argument default help --verbose False changes the log level to DEBUG , regardless of what it says in the feature file. gives more verbose logging that can be useful when troubleshooting a problem with a scenario. -T, --testdata-variable specified in the format <name>=<value> . avoids being asked for an initial value for a scenario variable. -y, --yes False answer yes on any questions that would require confirmation -e, --environment-file configuration file with environment specific information --csv-prefix write log statistics to CSV files with specified prefix, if no value is specified the description of the gherkin Feature tag will be used, suffixed with timestamp --csv-interval interval that statistics is collected for CSV files, can only be used in combination with --csv-prefix --csv-flush-interval interval that CSV statistics is flushed to disk, can only be used in combination with --csv-prefix","title":"Usage"},{"location":"command-line-interface/usage/#grizzly-cli","text":"the command line interface for grizzly, which makes it easer to start a test with all features of grizzly wrapped up nicely. installing it is a matter of: pip install grizzly-loadtester-cli enable bash completion by adding the following to your shell profile: eval \" $( grizzly-cli --bash-completion ) \"","title":"grizzly-cli"},{"location":"command-line-interface/usage/#usage","text":"grizzly-cli [ -h ] [ --version [{ all }]] { init,local,dist } ...","title":"Usage"},{"location":"command-line-interface/usage/#positional-arguments","text":"argument default help command","title":"Positional arguments"},{"location":"command-line-interface/usage/#optional-arguments","text":"argument default help --version print version of command line interface, and exit. add argument all to get versions of dependencies","title":"Optional arguments"},{"location":"command-line-interface/usage/#grizzly-cli-init","text":"create a skeleton project with required structure and files.","title":"grizzly-cli init"},{"location":"command-line-interface/usage/#usage_1","text":"grizzly-cli init [ -h ] [ --grizzly-version GRIZZLY_VERSION ] [ --with-mq ] [ -y ] project","title":"Usage"},{"location":"command-line-interface/usage/#positional-arguments_1","text":"argument default help project project name, a directory will be created with this name","title":"Positional arguments"},{"location":"command-line-interface/usage/#optional-arguments_1","text":"argument default help --grizzly-version specify which grizzly version to use for project, default is latest --with-mq False if grizzly should be installed with IBM MQ support (external dependencies excluded) -y, --yes False automagically answer yes on any questions","title":"Optional arguments"},{"location":"command-line-interface/usage/#grizzly-cli-local","text":"commands for running grizzly in local mode.","title":"grizzly-cli local"},{"location":"command-line-interface/usage/#usage_2","text":"grizzly-cli local [ -h ] { run } ...","title":"Usage"},{"location":"command-line-interface/usage/#positional-arguments_2","text":"argument default help subcommand","title":"Positional arguments"},{"location":"command-line-interface/usage/#grizzly-cli-local-run","text":"execute load test scenarios specified in a feature file.","title":"grizzly-cli local run"},{"location":"command-line-interface/usage/#usage_3","text":"grizzly-cli local run [ -h ] [ --verbose ] [ -T TESTDATA_VARIABLE ] [ -y ] [ -e ENVIRONMENT_FILE ] [ --csv-prefix [ CSV_PREFIX ]] [ --csv-interval CSV_INTERVAL ] [ --csv-flush-interval CSV_FLUSH_INTERVAL ] file [ file ... ]","title":"Usage"},{"location":"command-line-interface/usage/#positional-arguments_3","text":"argument default help file path to feature file with one or more scenarios","title":"Positional arguments"},{"location":"command-line-interface/usage/#optional-arguments_2","text":"argument default help --verbose False changes the log level to DEBUG , regardless of what it says in the feature file. gives more verbose logging that can be useful when troubleshooting a problem with a scenario. -T, --testdata-variable specified in the format <name>=<value> . avoids being asked for an initial value for a scenario variable. -y, --yes False answer yes on any questions that would require confirmation -e, --environment-file configuration file with environment specific information --csv-prefix write log statistics to CSV files with specified prefix, if no value is specified the description of the gherkin Feature tag will be used, suffixed with timestamp --csv-interval interval that statistics is collected for CSV files, can only be used in combination with --csv-prefix --csv-flush-interval interval that CSV statistics is flushed to disk, can only be used in combination with --csv-prefix","title":"Optional arguments"},{"location":"command-line-interface/usage/#grizzly-cli-dist","text":"commands for running grizzly i distributed mode.","title":"grizzly-cli dist"},{"location":"command-line-interface/usage/#usage_4","text":"grizzly-cli dist [ -h ] [ --workers WORKERS ] [ --id ID ] [ --limit-nofile LIMIT_NOFILE ] [ --health-retries HEALTH_RETRIES ] [ --health-timeout HEALTH_TIMEOUT ] [ --health-interval HEALTH_INTERVAL ] [ --registry REGISTRY ] [ --tty ] [ --wait-for-worker WAIT_FOR_WORKER ] [ --project-name PROJECT_NAME ] [ --force-build | --build | --validate-config ] { build,clean,run } ...","title":"Usage"},{"location":"command-line-interface/usage/#positional-arguments_4","text":"argument default help subcommand","title":"Positional arguments"},{"location":"command-line-interface/usage/#optional-arguments_3","text":"argument default help --workers 1 how many instances of the workers container that should be created --id unique identifier suffixed to compose project, should be used when the same user needs to run more than one instance of grizzly-cli --limit-nofile 10001 set system limit \"number of open files\" --health-retries 3 set number of retries for health check of master container --health-timeout 3 set timeout in seconds for health check of master container --health-interval 5 set interval in seconds between health checks of master container --registry push built image to this registry, if the registry has authentication you need to login first --tty False start containers with a TTY enabled --wait-for-worker sets enviroment variable LOCUST_WAIT_FOR_WORKERS_REPORT_AFTER_RAMP_UP, which tells master to wait this amount of time for worker report --project-name override project name, which otherwise would be the name of the directory where command is executed in --force-build False force rebuild the grizzly projects container image (no cache) --build False rebuild the grizzly projects container images (with cache) --validate-config False validate and print compose project file","title":"Optional arguments"},{"location":"command-line-interface/usage/#grizzly-cli-dist-build","text":"build grizzly compose project container image before running test. if worker nodes runs on different physical computers, it is mandatory to build the images before hand and push to a registry. if image includes IBM MQ native dependencies, the build time increases due to download times. it is possible to self- host the archive and override the download host with environment variable IBM_MQ_LIB_HOST .","title":"grizzly-cli dist build"},{"location":"command-line-interface/usage/#usage_5","text":"grizzly-cli dist build [ -h ] [ --no-cache ] [ --registry REGISTRY ]","title":"Usage"},{"location":"command-line-interface/usage/#optional-arguments_4","text":"argument default help --no-cache False build container image with out cache (full build) --registry push built image to this registry, if the registry has authentication you need to login first","title":"Optional arguments"},{"location":"command-line-interface/usage/#grizzly-cli-dist-clean","text":"clean all grizzly compose project resources; containers, images, networks and volumes","title":"grizzly-cli dist clean"},{"location":"command-line-interface/usage/#usage_6","text":"grizzly-cli dist clean [ -h ] [ --no-images ] [ --no-networks ]","title":"Usage"},{"location":"command-line-interface/usage/#optional-arguments_5","text":"argument default help --no-images True do not remove images --no-networks True do not remove networks","title":"Optional arguments"},{"location":"command-line-interface/usage/#grizzly-cli-dist-run","text":"execute load test scenarios specified in a feature file.","title":"grizzly-cli dist run"},{"location":"command-line-interface/usage/#usage_7","text":"grizzly-cli dist run [ -h ] [ --verbose ] [ -T TESTDATA_VARIABLE ] [ -y ] [ -e ENVIRONMENT_FILE ] [ --csv-prefix [ CSV_PREFIX ]] [ --csv-interval CSV_INTERVAL ] [ --csv-flush-interval CSV_FLUSH_INTERVAL ] file [ file ... ]","title":"Usage"},{"location":"command-line-interface/usage/#positional-arguments_5","text":"argument default help file path to feature file with one or more scenarios","title":"Positional arguments"},{"location":"command-line-interface/usage/#optional-arguments_6","text":"argument default help --verbose False changes the log level to DEBUG , regardless of what it says in the feature file. gives more verbose logging that can be useful when troubleshooting a problem with a scenario. -T, --testdata-variable specified in the format <name>=<value> . avoids being asked for an initial value for a scenario variable. -y, --yes False answer yes on any questions that would require confirmation -e, --environment-file configuration file with environment specific information --csv-prefix write log statistics to CSV files with specified prefix, if no value is specified the description of the gherkin Feature tag will be used, suffixed with timestamp --csv-interval interval that statistics is collected for CSV files, can only be used in combination with --csv-prefix --csv-flush-interval interval that CSV statistics is flushed to disk, can only be used in combination with --csv-prefix","title":"Optional arguments"},{"location":"command-line-interface/usage/metadata/","text":"Metadata It is possible to add metadata in feature files that grizzly-cli will use. Metadata comments can be added anywhere in the feature file, but it is recommended to add them in the top for readability. Arguments Inject grizzly-cli arguments via metadata comments. When executing a feature file, grizzly-cli will add the specified arguments automagically, if they match the command being executed. This makes it possible to add arguments needed for a specific feature file to be documented in the feature file itself, and one does not have to remember all combinations in memory. Format # grizzly-cli <[sub]parser> <argument> No validation is done that an argument actually exists in the subparser, other than that grizzly-cli will fail with an argument error. Which is solved by checking grizzly-cli usage and correct the metadata comments. Examples E.g., the run subparser is used by both dist and local , so when specifying an metadata comment for run arguments it should be: example.feature # grizzly-cli run --verbose Feature: Example Feature Scenario: Example Scenario ... This means that executing example.feature either in mode local or dist , the argument --verbose will be injected unless already manually specified. grizzly-cli local run example.feature -> grizzly-cli local run example.feature --verbose grizzly-cli dist run example.feature -> grizzly-cli dist run example.feature --verbose If metadata comments adds arguments for a subparser that is not used when executing the feature file the following message will be seen when executing grizzly-cli : ?? ignoring <arguments> Given the following feature file: example-dist.feature # grizzly-cli dist --health-retries 999 # grizzly-cli dist --workers 6 # grizzly-cli run --verbose Feature: Example Feature Scenario: Example Scenario ... When executed with grizzly-cli local run example-dist.feature , the output will contain: ?? ignoring dist --health-retries 999 ?? ignoring dist --workers 6 And the command that is actually executed is grizzly local run example-dist.feature --verbose . Notices It is possible to tell grizzly-cli show confirmation notices with metadata in a a feature file. This is useful to remind the user about manual steps och checks that should be done before running the feature. Format # grizzly-cli:notice <message> Everything after # grizzly-cli:notice (notice the space) will be displayed in the confirmation prompt. Examples example.feature # grizzly-cli:notice have you piped the fork in a loop? Feature: Example Feature Scenario: Example Scenario ... Running example.feature will in additional to the normal grizzly-cli input/output also trigger the following prompt: have you piped the fork in a loop? [y/n] If run argument -y/--yes is provided, it will only print the message and not ask for confirmation.","title":"Metadata"},{"location":"command-line-interface/usage/metadata/#metadata","text":"It is possible to add metadata in feature files that grizzly-cli will use. Metadata comments can be added anywhere in the feature file, but it is recommended to add them in the top for readability.","title":"Metadata"},{"location":"command-line-interface/usage/metadata/#arguments","text":"Inject grizzly-cli arguments via metadata comments. When executing a feature file, grizzly-cli will add the specified arguments automagically, if they match the command being executed. This makes it possible to add arguments needed for a specific feature file to be documented in the feature file itself, and one does not have to remember all combinations in memory.","title":"Arguments"},{"location":"command-line-interface/usage/metadata/#format","text":"# grizzly-cli <[sub]parser> <argument> No validation is done that an argument actually exists in the subparser, other than that grizzly-cli will fail with an argument error. Which is solved by checking grizzly-cli usage and correct the metadata comments.","title":"Format"},{"location":"command-line-interface/usage/metadata/#examples","text":"E.g., the run subparser is used by both dist and local , so when specifying an metadata comment for run arguments it should be: example.feature # grizzly-cli run --verbose Feature: Example Feature Scenario: Example Scenario ... This means that executing example.feature either in mode local or dist , the argument --verbose will be injected unless already manually specified. grizzly-cli local run example.feature -> grizzly-cli local run example.feature --verbose grizzly-cli dist run example.feature -> grizzly-cli dist run example.feature --verbose If metadata comments adds arguments for a subparser that is not used when executing the feature file the following message will be seen when executing grizzly-cli : ?? ignoring <arguments> Given the following feature file: example-dist.feature # grizzly-cli dist --health-retries 999 # grizzly-cli dist --workers 6 # grizzly-cli run --verbose Feature: Example Feature Scenario: Example Scenario ... When executed with grizzly-cli local run example-dist.feature , the output will contain: ?? ignoring dist --health-retries 999 ?? ignoring dist --workers 6 And the command that is actually executed is grizzly local run example-dist.feature --verbose .","title":"Examples"},{"location":"command-line-interface/usage/metadata/#notices","text":"It is possible to tell grizzly-cli show confirmation notices with metadata in a a feature file. This is useful to remind the user about manual steps och checks that should be done before running the feature.","title":"Notices"},{"location":"command-line-interface/usage/metadata/#format_1","text":"# grizzly-cli:notice <message> Everything after # grizzly-cli:notice (notice the space) will be displayed in the confirmation prompt.","title":"Format"},{"location":"command-line-interface/usage/metadata/#examples_1","text":"example.feature # grizzly-cli:notice have you piped the fork in a loop? Feature: Example Feature Scenario: Example Scenario ... Running example.feature will in additional to the normal grizzly-cli input/output also trigger the following prompt: have you piped the fork in a loop? [y/n] If run argument -y/--yes is provided, it will only print the message and not ask for confirmation.","title":"Examples"},{"location":"editor-support/","text":"Editor support It can be hard to remember all the step expressions by heart; that's why grizzly-ls exists! Which is a server implementation of LSP 1 , providing auto-complete of step expressions. The server does not do much by itself, you have to install a client/extension that speaks LSP for your editor. The Language Server Protocol (LSP) defines the protocol used between an editor or IDE and a language server that provides language features like auto complete, go to definition, find all references etc. The goal of the Language Server Index Format (LSIF, pronounced like \"else if\") is to support rich code navigation in development tools or a Web UI without needing a local copy of the source code. Read more \u21a9","title":"Editor support"},{"location":"editor-support/#editor-support","text":"It can be hard to remember all the step expressions by heart; that's why grizzly-ls exists! Which is a server implementation of LSP 1 , providing auto-complete of step expressions. The server does not do much by itself, you have to install a client/extension that speaks LSP for your editor. The Language Server Protocol (LSP) defines the protocol used between an editor or IDE and a language server that provides language features like auto complete, go to definition, find all references etc. The goal of the Language Server Index Format (LSIF, pronounced like \"else if\") is to support rich code navigation in development tools or a Web UI without needing a local copy of the source code. Read more \u21a9","title":"Editor support"},{"location":"editor-support/changelog/","text":"Changelog v1.0.0 e174a6d7 : upgrade to pygls 1.0.0 (#28) v0.0.9 08f3a4f6 : updated action versions to get rid of warnings (#27) v0.0.8 1ca7171d : return snippet strings for step expressions containing variables (#26) 29c03082 : step completion improvements (#25) v0.0.7 b082f8af : fix hover help for alias step keywords (#24) abb3c607 : provide name and version in LanguageServer constructor (#23) v0.0.6 a4f553ed : only try to find help text if keyword is valid (#22) v0.0.5 0b734bc1 : map step implementation docs to correct normalized step expression (#21) 71e5773c : add link to vscode marketplace in extension readme (#20) v0.0.4 b658074b : help on hover (#19) 82fbd485 : packages metadata (#18) v0.0.3 375eb605 : client vscode icon (#17) 5d3e3da8 : documentation and bugs (#16) 1c913841 : added missing project description (#15) v0.0.2 38ada912 : metadata update (#14) 1de67efc : action-push-tag@v1 is broken (#13)","title":"Changelog"},{"location":"editor-support/changelog/#changelog","text":"","title":"Changelog"},{"location":"editor-support/changelog/#v100","text":"e174a6d7 : upgrade to pygls 1.0.0 (#28)","title":"v1.0.0"},{"location":"editor-support/changelog/#v009","text":"08f3a4f6 : updated action versions to get rid of warnings (#27)","title":"v0.0.9"},{"location":"editor-support/changelog/#v008","text":"1ca7171d : return snippet strings for step expressions containing variables (#26) 29c03082 : step completion improvements (#25)","title":"v0.0.8"},{"location":"editor-support/changelog/#v007","text":"b082f8af : fix hover help for alias step keywords (#24) abb3c607 : provide name and version in LanguageServer constructor (#23)","title":"v0.0.7"},{"location":"editor-support/changelog/#v006","text":"a4f553ed : only try to find help text if keyword is valid (#22)","title":"v0.0.6"},{"location":"editor-support/changelog/#v005","text":"0b734bc1 : map step implementation docs to correct normalized step expression (#21) 71e5773c : add link to vscode marketplace in extension readme (#20)","title":"v0.0.5"},{"location":"editor-support/changelog/#v004","text":"b658074b : help on hover (#19) 82fbd485 : packages metadata (#18)","title":"v0.0.4"},{"location":"editor-support/changelog/#v003","text":"375eb605 : client vscode icon (#17) 5d3e3da8 : documentation and bugs (#16) 1c913841 : added missing project description (#15)","title":"v0.0.3"},{"location":"editor-support/changelog/#v002","text":"38ada912 : metadata update (#14) 1de67efc : action-push-tag@v1 is broken (#13)","title":"v0.0.2"},{"location":"editor-support/language-server/","text":"grizzly-ls This is the LSP server implementation for Visual Studio Code extension biometria-se.grizzly-loadtester-vscode . It provides the logic for auto-completion of step expressions for your grizzly-loadtester project. Big shout out to pygls for making the implementation of a LSP server easy!","title":"Language server"},{"location":"editor-support/language-server/#grizzly-ls","text":"This is the LSP server implementation for Visual Studio Code extension biometria-se.grizzly-loadtester-vscode . It provides the logic for auto-completion of step expressions for your grizzly-loadtester project. Big shout out to pygls for making the implementation of a LSP server easy!","title":"grizzly-ls"},{"location":"editor-support/licenses/","text":"Licenses The MIT License (MIT) Copyright \u00a9 2021 Biometria Ekonomiska F\u00f6rening Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \u201cSoftware\u201d), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \u201cAS IS\u201d, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Third party licenses Server Name Version License protobuf 4.21.12 3-Clause BSD License PyNaCl 1.5.0 Apache License 2.0 bcrypt 4.0.1 Apache Software License coverage 6.5.0 Apache Software License deprecation 2.1.0 Apache Software License google-api-core 2.11.0 Apache Software License google-auth 2.15.0 Apache Software License googleapis-common-protos 1.57.0 Apache Software License janus 1.0.0 Apache Software License jsonpath-ng 1.5.3 Apache Software License msgpack 1.0.4 Apache Software License opencensus 0.11.0 Apache Software License opencensus-context 0.1.3 Apache Software License opencensus-ext-azure 1.1.7 Apache Software License pygls 1.0.0 Apache Software License requests 2.28.1 Apache Software License requests-unixsocket 0.3.0 Apache Software License rsa 4.9 Apache Software License types-requests 2.28.11.5 Apache Software License types-urllib3 1.26.25.4 Apache Software License tzdata 2022.7 Apache Software License cryptography 38.0.4 Apache Software License; BSD License packaging 22.0 Apache Software License; BSD License python-dateutil 2.8.2 Apache Software License; BSD License PySocks 1.7.1 BSD ply 3.11 BSD Flask 2.2.2 BSD License Flask-BasicAuth 0.2.0 BSD License Jinja2 3.1.2 BSD License MarkupSafe 2.1.1 BSD License Werkzeug 2.2.2 BSD License aenum 3.1.11 BSD License behave 1.2.6 BSD License click 8.1.3 BSD License decorator 5.1.1 BSD License dill 0.3.6 BSD License idna 3.4 BSD License isodate 0.6.1 BSD License itsdangerous 2.1.2 BSD License lazy-object-proxy 1.8.0 BSD License lxml 4.9.2 BSD License oauthlib 3.2.2 BSD License parse 1.19.0 BSD License parse-type 0.6.0 BSD License psutil 5.9.4 BSD License pyasn1 0.4.8 BSD License pyasn1-modules 0.2.8 BSD License pycparser 2.21 BSD License requests-oauthlib 1.3.1 BSD License setproctitle 1.3.2 BSD License wrapt 1.14.1 BSD License pyzmq 22.3.0 BSD License; GNU Library or Lesser General Public License (LGPL) pytest-timeout 2.1.0 DFSG approved; MIT License paho-mqtt 1.6.1 Eclipse Public License v2.0 / Eclipse Distribution License v1.0 pylint 2.15.8 GNU General Public License v2 (GPLv2) astroid 2.12.13 GNU Lesser General Public License v2 (LGPLv2) chardet 5.1.0 GNU Lesser General Public License v2 or later (LGPLv2+) paramiko 2.12.0 GNU Library or Lesser General Public License (LGPL) geventhttpclient 2.0.8 MIT Brotli 1.0.9 MIT License ConfigArgParse 1.5.3 MIT License DataProperty 0.55.0 MIT License Flake8-pyproject 1.2.2 MIT License Flask-Cors 3.0.10 MIT License PyJWT 2.6.0 MIT License PyYAML 5.4.1 MIT License attrs 22.1.0 MIT License azure-common 1.1.28 MIT License azure-core 1.26.1 MIT License azure-identity 1.12.0 MIT License azure-iot-device 2.12.0 MIT License azure-servicebus 7.8.1 MIT License azure-storage-blob 12.14.1 MIT License black 22.12.0 MIT License cachetools 5.2.0 MIT License cattrs 22.2.0 MIT License cffi 1.15.1 MIT License charset-normalizer 2.1.1 MIT License exceptiongroup 1.0.4 MIT License flake8 6.0.0 MIT License gevent 22.10.2 MIT License greenlet 2.0.1 MIT License influxdb 5.3.1 MIT License iniconfig 1.1.1 MIT License isort 5.11.2 MIT License locust 2.12.2 MIT License lsprotocol 2022.0.0a9 MIT License mbstrdecoder 1.1.1 MIT License mccabe 0.7.0 MIT License msal 1.20.0 MIT License msal-extensions 1.0.0 MIT License msrest 0.7.1 MIT License mypy 0.991 MIT License mypy-extensions 0.4.3 MIT License pathvalidate 2.5.2 MIT License platformdirs 2.6.0 MIT License pluggy 1.0.0 MIT License pycodestyle 2.10.0 MIT License pyflakes 3.0.1 MIT License pytablewriter 0.64.2 MIT License pytest 7.2.0 MIT License pytest-cov 4.0.0 MIT License pytest-mock 3.10.0 MIT License pytz 2022.6 MIT License roundrobin 0.0.4 MIT License six 1.16.0 MIT License tabledata 1.3.0 MIT License tcolorpy 0.1.2 MIT License tomli 2.0.1 MIT License tomlkit 0.11.6 MIT License typeguard 2.13.3 MIT License typepy 1.3.0 MIT License uamqp 1.6.3 MIT License urllib3 1.26.13 MIT License certifi 2022.12.7 Mozilla Public License 2.0 (MPL 2.0) pathspec 0.10.3 Mozilla Public License 2.0 (MPL 2.0) portalocker 2.6.0 PSF typing_extensions 4.4.0 Python Software Foundation License zope.event 4.6 Zope Public License Client Visual Studio Code Name Parents Version License @eslint/eslintrc grizzly-loadtester-vscode 1.3.0 MIT @humanwhocodes/config-array grizzly-loadtester-vscode 0.10.4 Apache-2.0 @humanwhocodes/gitignore-to-minimatch grizzly-loadtester-vscode 1.0.2 Apache-2.0 @humanwhocodes/object-schema grizzly-loadtester-vscode 1.2.1 BSD-3-Clause @nodelib/fs.scandir grizzly-loadtester-vscode 2.1.5 MIT @nodelib/fs.stat grizzly-loadtester-vscode 2.0.5 MIT @nodelib/fs.walk grizzly-loadtester-vscode 1.2.8 MIT @tootallnate/once grizzly-loadtester-vscode 1.1.2 MIT @types/chai grizzly-loadtester-vscode 4.3.3 MIT @types/glob grizzly-loadtester-vscode 8.0.0 MIT @types/json-schema grizzly-loadtester-vscode 7.0.11 MIT @types/json5 grizzly-loadtester-vscode 0.0.29 MIT @types/minimatch grizzly-loadtester-vscode 5.1.2 MIT @types/mocha grizzly-loadtester-vscode 9.1.1 MIT @types/node grizzly-loadtester-vscode 16.11.58 MIT @types/vscode grizzly-loadtester-vscode 1.64.0 MIT @typescript-eslint/eslint-plugin grizzly-loadtester-vscode 5.33.1 MIT @typescript-eslint/parser grizzly-loadtester-vscode 5.33.1 BSD-2-Clause @typescript-eslint/scope-manager grizzly-loadtester-vscode 5.33.1 MIT @typescript-eslint/type-utils grizzly-loadtester-vscode 5.33.1 MIT @typescript-eslint/types grizzly-loadtester-vscode 5.33.1 MIT @typescript-eslint/typescript-estree grizzly-loadtester-vscode 5.33.1 BSD-2-Clause @typescript-eslint/utils grizzly-loadtester-vscode 5.33.1 MIT @typescript-eslint/visitor-keys grizzly-loadtester-vscode 5.33.1 MIT @ungap/promise-all-settled grizzly-loadtester-vscode 1.1.2 ISC @vscode/test-electron grizzly-loadtester-vscode 2.1.2 MIT abbrev grizzly-loadtester-vscode 1.1.1 ISC acorn-jsx grizzly-loadtester-vscode 5.3.2 MIT acorn grizzly-loadtester-vscode 8.8.0 MIT agent-base @vscode/test-electron:grizzly-loadtester-vscode 6.0.2 MIT ajv grizzly-loadtester-vscode 6.12.6 MIT ansi-colors grizzly-loadtester-vscode 4.1.1 MIT ansi-regex has-ansi:grizzly-loadtester-vscode 0.2.1 MIT ansi-regex grizzly-loadtester-vscode 5.0.1 MIT ansi-styles license-checker:grizzly-loadtester-vscode 1.1.0 MIT ansi-styles npm-license-crawler:grizzly-loadtester-vscode 3.2.1 MIT ansi-styles grizzly-loadtester-vscode 4.3.0 MIT anymatch grizzly-loadtester-vscode 3.1.2 ISC argparse grizzly-loadtester-vscode 2.0.1 Python-2.0 array-includes grizzly-loadtester-vscode 3.1.5 MIT array-union grizzly-loadtester-vscode 2.1.0 MIT array.prototype.flat grizzly-loadtester-vscode 1.3.0 MIT asap grizzly-loadtester-vscode 2.0.6 MIT assertion-error grizzly-loadtester-vscode 1.1.0 MIT async grizzly-loadtester-vscode 2.6.4 MIT balanced-match grizzly-loadtester-vscode 1.0.0 MIT big-integer grizzly-loadtester-vscode 1.6.48 Unlicense binary-extensions grizzly-loadtester-vscode 2.2.0 MIT binary grizzly-loadtester-vscode 0.3.0 MIT bluebird grizzly-loadtester-vscode 3.4.7 MIT brace-expansion grizzly-loadtester-vscode 1.1.11 MIT braces grizzly-loadtester-vscode 3.0.2 MIT browser-stdout grizzly-loadtester-vscode 1.3.1 ISC buffer-indexof-polyfill grizzly-loadtester-vscode 1.0.2 MIT buffers grizzly-loadtester-vscode 0.1.1 UNKNOWN builtins grizzly-loadtester-vscode 5.0.1 MIT call-bind grizzly-loadtester-vscode 1.0.2 MIT callsites grizzly-loadtester-vscode 3.1.0 MIT camelcase grizzly-loadtester-vscode 6.3.0 MIT chai grizzly-loadtester-vscode 4.3.6 MIT chainsaw grizzly-loadtester-vscode 0.1.0 MIT/X11 chalk license-checker:grizzly-loadtester-vscode 0.5.1 MIT chalk npm-license-crawler:grizzly-loadtester-vscode 2.4.2 MIT chalk grizzly-loadtester-vscode 4.1.2 MIT check-error grizzly-loadtester-vscode 1.0.2 MIT chokidar grizzly-loadtester-vscode 3.5.3 MIT cliui grizzly-loadtester-vscode 7.0.4 ISC color-convert npm-license-crawler:grizzly-loadtester-vscode 1.9.3 MIT color-convert grizzly-loadtester-vscode 2.0.1 MIT color-name npm-license-crawler:grizzly-loadtester-vscode 1.1.3 MIT color-name grizzly-loadtester-vscode 1.1.4 MIT concat-map grizzly-loadtester-vscode 0.0.1 MIT core-util-is grizzly-loadtester-vscode 1.0.2 MIT cross-spawn grizzly-loadtester-vscode 7.0.3 MIT debug eslint-plugin-import:grizzly-loadtester-vscode 2.6.9 MIT debug eslint-module-utils:grizzly-loadtester-vscode 3.2.7 MIT debug mocha:grizzly-loadtester-vscode 4.3.3 MIT debug grizzly-loadtester-vscode 4.3.4 MIT debuglog grizzly-loadtester-vscode 1.0.1 MIT decamelize grizzly-loadtester-vscode 4.0.0 MIT deep-eql grizzly-loadtester-vscode 3.0.1 MIT deep-is grizzly-loadtester-vscode 0.1.4 MIT define-properties grizzly-loadtester-vscode 1.1.4 MIT dezalgo grizzly-loadtester-vscode 1.0.4 ISC diff grizzly-loadtester-vscode 5.0.0 BSD-3-Clause dir-glob grizzly-loadtester-vscode 3.0.1 MIT doctrine eslint-plugin-import:grizzly-loadtester-vscode 2.1.0 Apache-2.0 doctrine grizzly-loadtester-vscode 3.0.0 Apache-2.0 duplexer2 grizzly-loadtester-vscode 0.1.4 BSD-3-Clause emoji-regex grizzly-loadtester-vscode 8.0.0 MIT es-abstract grizzly-loadtester-vscode 1.20.1 MIT es-shim-unscopables grizzly-loadtester-vscode 1.0.0 MIT es-to-primitive grizzly-loadtester-vscode 1.2.1 MIT esbuild-linux-64 grizzly-loadtester-vscode 0.15.7 MIT esbuild grizzly-loadtester-vscode 0.15.7 MIT escalade grizzly-loadtester-vscode 3.1.1 MIT escape-string-regexp npm-license-crawler:grizzly-loadtester-vscode 1.0.5 MIT escape-string-regexp grizzly-loadtester-vscode 4.0.0 MIT eslint-config-standard-with-typescript grizzly-loadtester-vscode 22.0.0 MIT eslint-config-standard grizzly-loadtester-vscode 17.0.0 MIT eslint-import-resolver-node grizzly-loadtester-vscode 0.3.6 MIT eslint-module-utils grizzly-loadtester-vscode 2.7.4 MIT eslint-plugin-es grizzly-loadtester-vscode 4.1.0 MIT eslint-plugin-import grizzly-loadtester-vscode 2.26.0 MIT eslint-plugin-n grizzly-loadtester-vscode 15.2.4 MIT eslint-plugin-promise grizzly-loadtester-vscode 6.0.0 ISC eslint-scope grizzly-loadtester-vscode 5.1.1 BSD-2-Clause eslint-scope eslint:grizzly-loadtester-vscode 7.1.1 BSD-2-Clause eslint-utils eslint-plugin-es:grizzly-loadtester-vscode 2.1.0 MIT eslint-utils grizzly-loadtester-vscode 3.0.0 MIT eslint-visitor-keys eslint-plugin-es:grizzly-loadtester-vscode 1.3.0 Apache-2.0 eslint-visitor-keys eslint-utils:grizzly-loadtester-vscode 2.1.0 Apache-2.0 eslint-visitor-keys grizzly-loadtester-vscode 3.3.0 Apache-2.0 eslint grizzly-loadtester-vscode 8.22.0 MIT espree grizzly-loadtester-vscode 9.3.3 BSD-2-Clause esquery grizzly-loadtester-vscode 1.4.0 BSD-3-Clause esrecurse grizzly-loadtester-vscode 4.3.0 BSD-2-Clause estraverse grizzly-loadtester-vscode 4.3.0 BSD-2-Clause estraverse esrecurse:grizzly-loadtester-vscode 5.3.0 BSD-2-Clause esutils grizzly-loadtester-vscode 2.0.3 BSD-2-Clause fast-deep-equal grizzly-loadtester-vscode 3.1.3 MIT fast-glob grizzly-loadtester-vscode 3.2.11 MIT fast-json-stable-stringify grizzly-loadtester-vscode 2.1.0 MIT fast-levenshtein grizzly-loadtester-vscode 2.0.6 MIT fastq grizzly-loadtester-vscode 1.13.0 ISC file-entry-cache grizzly-loadtester-vscode 6.0.1 MIT fill-range grizzly-loadtester-vscode 7.0.1 MIT find-up grizzly-loadtester-vscode 5.0.0 MIT flat-cache grizzly-loadtester-vscode 3.0.4 MIT flat grizzly-loadtester-vscode 5.0.2 BSD-3-Clause flatted grizzly-loadtester-vscode 3.2.5 ISC fs.realpath grizzly-loadtester-vscode 1.0.0 ISC fstream grizzly-loadtester-vscode 1.0.12 ISC function-bind grizzly-loadtester-vscode 1.1.1 MIT function.prototype.name grizzly-loadtester-vscode 1.1.5 MIT functional-red-black-tree grizzly-loadtester-vscode 1.0.1 MIT functions-have-names grizzly-loadtester-vscode 1.2.3 MIT get-caller-file grizzly-loadtester-vscode 2.0.5 ISC get-func-name grizzly-loadtester-vscode 2.0.0 MIT get-intrinsic grizzly-loadtester-vscode 1.1.2 MIT get-symbol-description grizzly-loadtester-vscode 1.0.0 MIT github-url-from-git grizzly-loadtester-vscode 1.5.0 MIT github-url-from-username-repo grizzly-loadtester-vscode 1.0.2 BSD-2-Clause glob-parent fast-glob:grizzly-loadtester-vscode 5.1.2 ISC glob-parent grizzly-loadtester-vscode 6.0.2 ISC glob read-package-json:grizzly-loadtester-vscode 5.0.15 ISC glob grizzly-loadtester-vscode 7.2.0 ISC globals grizzly-loadtester-vscode 13.15.0 MIT globby grizzly-loadtester-vscode 11.1.0 MIT graceful-fs read-package-json:grizzly-loadtester-vscode 3.0.12 ISC graceful-fs grizzly-loadtester-vscode 4.2.6 ISC grapheme-splitter grizzly-loadtester-vscode 1.0.4 MIT grizzly-loadtester-vscode 0.0.0 MIT growl grizzly-loadtester-vscode 1.10.5 MIT has-ansi grizzly-loadtester-vscode 0.1.0 MIT has-bigints grizzly-loadtester-vscode 1.0.2 MIT has-flag npm-license-crawler:grizzly-loadtester-vscode 3.0.0 MIT has-flag grizzly-loadtester-vscode 4.0.0 MIT has-property-descriptors grizzly-loadtester-vscode 1.0.0 MIT has-symbols grizzly-loadtester-vscode 1.0.3 MIT has-tostringtag grizzly-loadtester-vscode 1.0.0 MIT has grizzly-loadtester-vscode 1.0.3 MIT he grizzly-loadtester-vscode 1.2.0 MIT http-proxy-agent @vscode/test-electron:grizzly-loadtester-vscode 4.0.1 MIT https-proxy-agent @vscode/test-electron:grizzly-loadtester-vscode 5.0.0 MIT ignore grizzly-loadtester-vscode 5.2.0 MIT import-fresh grizzly-loadtester-vscode 3.3.0 MIT imurmurhash grizzly-loadtester-vscode 0.1.4 MIT inflight grizzly-loadtester-vscode 1.0.6 ISC inherits grizzly-loadtester-vscode 2.0.4 ISC internal-slot grizzly-loadtester-vscode 1.0.3 MIT is-bigint grizzly-loadtester-vscode 1.0.4 MIT is-binary-path grizzly-loadtester-vscode 2.1.0 MIT is-boolean-object grizzly-loadtester-vscode 1.1.2 MIT is-callable grizzly-loadtester-vscode 1.2.4 MIT is-core-module grizzly-loadtester-vscode 2.10.0 MIT is-date-object grizzly-loadtester-vscode 1.0.5 MIT is-extglob grizzly-loadtester-vscode 2.1.1 MIT is-fullwidth-code-point grizzly-loadtester-vscode 3.0.0 MIT is-glob grizzly-loadtester-vscode 4.0.3 MIT is-negative-zero grizzly-loadtester-vscode 2.0.2 MIT is-number-object grizzly-loadtester-vscode 1.0.7 MIT is-number grizzly-loadtester-vscode 7.0.0 MIT is-plain-obj grizzly-loadtester-vscode 2.1.0 MIT is-regex grizzly-loadtester-vscode 1.1.4 MIT is-shared-array-buffer grizzly-loadtester-vscode 1.0.2 MIT is-string grizzly-loadtester-vscode 1.0.7 MIT is-symbol grizzly-loadtester-vscode 1.0.4 MIT is-unicode-supported grizzly-loadtester-vscode 0.1.0 MIT is-weakref grizzly-loadtester-vscode 1.0.2 MIT isarray grizzly-loadtester-vscode 1.0.0 MIT isexe grizzly-loadtester-vscode 2.0.0 ISC jju grizzly-loadtester-vscode 1.4.0 MIT jquery-extend grizzly-loadtester-vscode 2.0.3 MIT js-yaml grizzly-loadtester-vscode 4.1.0 MIT json-parse-helpfulerror grizzly-loadtester-vscode 1.0.3 MIT json-schema-traverse grizzly-loadtester-vscode 0.4.1 MIT json-stable-stringify-without-jsonify grizzly-loadtester-vscode 1.0.1 MIT json5 grizzly-loadtester-vscode 1.0.1 MIT levn grizzly-loadtester-vscode 0.4.1 MIT license-checker grizzly-loadtester-vscode 1.0.0 BSD-3-Clause listenercount grizzly-loadtester-vscode 1.0.1 ISC locate-path grizzly-loadtester-vscode 6.0.0 MIT lodash.merge grizzly-loadtester-vscode 4.6.2 MIT lodash grizzly-loadtester-vscode 4.17.21 MIT log-symbols grizzly-loadtester-vscode 4.1.0 MIT loupe grizzly-loadtester-vscode 2.3.4 MIT lru-cache grizzly-loadtester-vscode 6.0.0 ISC merge2 grizzly-loadtester-vscode 1.4.1 MIT micromatch grizzly-loadtester-vscode 4.0.5 MIT minimatch grizzly-loadtester-vscode 3.1.2 ISC minimatch mocha:grizzly-loadtester-vscode 4.2.1 ISC minimist grizzly-loadtester-vscode 1.2.6 MIT mkdirp license-checker:grizzly-loadtester-vscode 0.3.5 MIT mkdirp grizzly-loadtester-vscode 0.5.5 MIT mocha grizzly-loadtester-vscode 9.2.2 MIT ms eslint-plugin-import:grizzly-loadtester-vscode 2.0.0 MIT ms grizzly-loadtester-vscode 2.1.2 MIT ms mocha:grizzly-loadtester-vscode 2.1.3 MIT nanoid grizzly-loadtester-vscode 3.3.1 MIT natives grizzly-loadtester-vscode 1.1.6 ISC natural-compare grizzly-loadtester-vscode 1.4.0 MIT nopt-defaults grizzly-loadtester-vscode 0.0.1 BSD-3-Clause nopt-usage grizzly-loadtester-vscode 0.1.0 MIT nopt license-checker:grizzly-loadtester-vscode 2.2.1 MIT nopt grizzly-loadtester-vscode 3.0.6 ISC normalize-package-data grizzly-loadtester-vscode 1.0.3 MIT* normalize-path grizzly-loadtester-vscode 3.0.0 MIT npm-license-crawler grizzly-loadtester-vscode 0.2.1 BSD-3-Clause object-inspect grizzly-loadtester-vscode 1.12.2 MIT object-keys grizzly-loadtester-vscode 1.1.1 MIT object.assign grizzly-loadtester-vscode 4.1.4 MIT object.values grizzly-loadtester-vscode 1.1.5 MIT once grizzly-loadtester-vscode 1.4.0 ISC optionator grizzly-loadtester-vscode 0.9.1 MIT p-limit grizzly-loadtester-vscode 3.1.0 MIT p-locate grizzly-loadtester-vscode 5.0.0 MIT parent-module grizzly-loadtester-vscode 1.0.1 MIT path-exists grizzly-loadtester-vscode 4.0.0 MIT path-is-absolute grizzly-loadtester-vscode 1.0.1 MIT path-key grizzly-loadtester-vscode 3.1.1 MIT path-parse grizzly-loadtester-vscode 1.0.7 MIT path-type grizzly-loadtester-vscode 4.0.0 MIT pathval grizzly-loadtester-vscode 1.1.1 MIT picomatch grizzly-loadtester-vscode 2.3.1 MIT prelude-ls grizzly-loadtester-vscode 1.2.1 MIT process-nextick-args grizzly-loadtester-vscode 2.0.1 MIT punycode grizzly-loadtester-vscode 2.1.1 MIT queue-microtask grizzly-loadtester-vscode 1.2.3 MIT randombytes grizzly-loadtester-vscode 2.1.0 MIT read-installed grizzly-loadtester-vscode 3.1.5 ISC read-package-json grizzly-loadtester-vscode 1.3.3 ISC readable-stream grizzly-loadtester-vscode 2.3.7 MIT readdir-scoped-modules grizzly-loadtester-vscode 1.1.0 ISC readdirp grizzly-loadtester-vscode 3.6.0 MIT regexp.prototype.flags grizzly-loadtester-vscode 1.4.3 MIT regexpp grizzly-loadtester-vscode 3.2.0 MIT require-directory grizzly-loadtester-vscode 2.1.1 MIT resolve-from grizzly-loadtester-vscode 4.0.0 MIT resolve grizzly-loadtester-vscode 1.22.1 MIT reusify grizzly-loadtester-vscode 1.0.4 MIT rimraf grizzly-loadtester-vscode 2.7.1 ISC rimraf flat-cache:grizzly-loadtester-vscode 3.0.2 ISC run-parallel grizzly-loadtester-vscode 1.2.0 MIT safe-buffer grizzly-loadtester-vscode 5.1.2 MIT semver normalize-package-data:grizzly-loadtester-vscode 4.3.6 ISC semver grizzly-loadtester-vscode 7.3.7 ISC serialize-javascript grizzly-loadtester-vscode 6.0.0 BSD-3-Clause setimmediate grizzly-loadtester-vscode 1.0.5 MIT shebang-command grizzly-loadtester-vscode 2.0.0 MIT shebang-regex grizzly-loadtester-vscode 3.0.0 MIT side-channel grizzly-loadtester-vscode 1.0.4 MIT slash grizzly-loadtester-vscode 3.0.0 MIT slide grizzly-loadtester-vscode 1.1.6 ISC string-width grizzly-loadtester-vscode 4.2.3 MIT string.prototype.trimend grizzly-loadtester-vscode 1.0.5 MIT string.prototype.trimstart grizzly-loadtester-vscode 1.0.5 MIT string_decoder grizzly-loadtester-vscode 1.1.1 MIT strip-ansi license-checker:grizzly-loadtester-vscode 0.3.0 MIT strip-ansi grizzly-loadtester-vscode 6.0.1 MIT strip-bom grizzly-loadtester-vscode 3.0.0 MIT strip-json-comments grizzly-loadtester-vscode 3.1.1 MIT supports-color license-checker:grizzly-loadtester-vscode 0.2.0 MIT supports-color npm-license-crawler:grizzly-loadtester-vscode 5.5.0 MIT supports-color grizzly-loadtester-vscode 7.2.0 MIT supports-color mocha:grizzly-loadtester-vscode 8.1.1 MIT supports-preserve-symlinks-flag grizzly-loadtester-vscode 1.0.0 MIT text-table grizzly-loadtester-vscode 0.2.0 MIT to-regex-range grizzly-loadtester-vscode 5.0.1 MIT traverse grizzly-loadtester-vscode 0.3.9 MIT/X11 treeify grizzly-loadtester-vscode 1.1.0 MIT tsconfig-paths grizzly-loadtester-vscode 3.14.1 MIT tslib grizzly-loadtester-vscode 1.14.1 0BSD tsutils grizzly-loadtester-vscode 3.21.0 MIT type-check grizzly-loadtester-vscode 0.4.0 MIT type-detect grizzly-loadtester-vscode 4.0.8 MIT type-fest grizzly-loadtester-vscode 0.20.2 (MIT OR CC0-1.0) typescript grizzly-loadtester-vscode 4.7.4 Apache-2.0 unbox-primitive grizzly-loadtester-vscode 1.0.2 MIT unzipper grizzly-loadtester-vscode 0.10.11 MIT uri-js grizzly-loadtester-vscode 4.4.1 BSD-2-Clause util-deprecate grizzly-loadtester-vscode 1.0.2 MIT util-extend grizzly-loadtester-vscode 1.0.3 MIT v8-compile-cache grizzly-loadtester-vscode 2.3.0 MIT vscode-jsonrpc grizzly-loadtester-vscode 6.0.0 MIT vscode-languageclient grizzly-loadtester-vscode 7.0.0 MIT vscode-languageserver-protocol grizzly-loadtester-vscode 3.16.0 MIT vscode-languageserver-types grizzly-loadtester-vscode 3.16.0 MIT which-boxed-primitive grizzly-loadtester-vscode 1.0.2 MIT which grizzly-loadtester-vscode 2.0.2 ISC word-wrap grizzly-loadtester-vscode 1.2.3 MIT workerpool grizzly-loadtester-vscode 6.2.0 Apache-2.0 wrap-ansi grizzly-loadtester-vscode 7.0.0 MIT wrappy grizzly-loadtester-vscode 1.0.2 ISC y18n grizzly-loadtester-vscode 5.0.8 ISC yallist grizzly-loadtester-vscode 4.0.0 ISC yargs-parser grizzly-loadtester-vscode 20.2.4 ISC yargs-unparser grizzly-loadtester-vscode 2.0.0 MIT yargs grizzly-loadtester-vscode 16.2.0 MIT yocto-queue grizzly-loadtester-vscode 0.1.0 MIT","title":"Licenses"},{"location":"editor-support/licenses/#licenses","text":"","title":"Licenses"},{"location":"editor-support/licenses/#the-mit-license-mit","text":"Copyright \u00a9 2021 Biometria Ekonomiska F\u00f6rening Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \u201cSoftware\u201d), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \u201cAS IS\u201d, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"The MIT License (MIT)"},{"location":"editor-support/licenses/#third-party-licenses","text":"","title":"Third party licenses"},{"location":"editor-support/licenses/#server","text":"Name Version License protobuf 4.21.12 3-Clause BSD License PyNaCl 1.5.0 Apache License 2.0 bcrypt 4.0.1 Apache Software License coverage 6.5.0 Apache Software License deprecation 2.1.0 Apache Software License google-api-core 2.11.0 Apache Software License google-auth 2.15.0 Apache Software License googleapis-common-protos 1.57.0 Apache Software License janus 1.0.0 Apache Software License jsonpath-ng 1.5.3 Apache Software License msgpack 1.0.4 Apache Software License opencensus 0.11.0 Apache Software License opencensus-context 0.1.3 Apache Software License opencensus-ext-azure 1.1.7 Apache Software License pygls 1.0.0 Apache Software License requests 2.28.1 Apache Software License requests-unixsocket 0.3.0 Apache Software License rsa 4.9 Apache Software License types-requests 2.28.11.5 Apache Software License types-urllib3 1.26.25.4 Apache Software License tzdata 2022.7 Apache Software License cryptography 38.0.4 Apache Software License; BSD License packaging 22.0 Apache Software License; BSD License python-dateutil 2.8.2 Apache Software License; BSD License PySocks 1.7.1 BSD ply 3.11 BSD Flask 2.2.2 BSD License Flask-BasicAuth 0.2.0 BSD License Jinja2 3.1.2 BSD License MarkupSafe 2.1.1 BSD License Werkzeug 2.2.2 BSD License aenum 3.1.11 BSD License behave 1.2.6 BSD License click 8.1.3 BSD License decorator 5.1.1 BSD License dill 0.3.6 BSD License idna 3.4 BSD License isodate 0.6.1 BSD License itsdangerous 2.1.2 BSD License lazy-object-proxy 1.8.0 BSD License lxml 4.9.2 BSD License oauthlib 3.2.2 BSD License parse 1.19.0 BSD License parse-type 0.6.0 BSD License psutil 5.9.4 BSD License pyasn1 0.4.8 BSD License pyasn1-modules 0.2.8 BSD License pycparser 2.21 BSD License requests-oauthlib 1.3.1 BSD License setproctitle 1.3.2 BSD License wrapt 1.14.1 BSD License pyzmq 22.3.0 BSD License; GNU Library or Lesser General Public License (LGPL) pytest-timeout 2.1.0 DFSG approved; MIT License paho-mqtt 1.6.1 Eclipse Public License v2.0 / Eclipse Distribution License v1.0 pylint 2.15.8 GNU General Public License v2 (GPLv2) astroid 2.12.13 GNU Lesser General Public License v2 (LGPLv2) chardet 5.1.0 GNU Lesser General Public License v2 or later (LGPLv2+) paramiko 2.12.0 GNU Library or Lesser General Public License (LGPL) geventhttpclient 2.0.8 MIT Brotli 1.0.9 MIT License ConfigArgParse 1.5.3 MIT License DataProperty 0.55.0 MIT License Flake8-pyproject 1.2.2 MIT License Flask-Cors 3.0.10 MIT License PyJWT 2.6.0 MIT License PyYAML 5.4.1 MIT License attrs 22.1.0 MIT License azure-common 1.1.28 MIT License azure-core 1.26.1 MIT License azure-identity 1.12.0 MIT License azure-iot-device 2.12.0 MIT License azure-servicebus 7.8.1 MIT License azure-storage-blob 12.14.1 MIT License black 22.12.0 MIT License cachetools 5.2.0 MIT License cattrs 22.2.0 MIT License cffi 1.15.1 MIT License charset-normalizer 2.1.1 MIT License exceptiongroup 1.0.4 MIT License flake8 6.0.0 MIT License gevent 22.10.2 MIT License greenlet 2.0.1 MIT License influxdb 5.3.1 MIT License iniconfig 1.1.1 MIT License isort 5.11.2 MIT License locust 2.12.2 MIT License lsprotocol 2022.0.0a9 MIT License mbstrdecoder 1.1.1 MIT License mccabe 0.7.0 MIT License msal 1.20.0 MIT License msal-extensions 1.0.0 MIT License msrest 0.7.1 MIT License mypy 0.991 MIT License mypy-extensions 0.4.3 MIT License pathvalidate 2.5.2 MIT License platformdirs 2.6.0 MIT License pluggy 1.0.0 MIT License pycodestyle 2.10.0 MIT License pyflakes 3.0.1 MIT License pytablewriter 0.64.2 MIT License pytest 7.2.0 MIT License pytest-cov 4.0.0 MIT License pytest-mock 3.10.0 MIT License pytz 2022.6 MIT License roundrobin 0.0.4 MIT License six 1.16.0 MIT License tabledata 1.3.0 MIT License tcolorpy 0.1.2 MIT License tomli 2.0.1 MIT License tomlkit 0.11.6 MIT License typeguard 2.13.3 MIT License typepy 1.3.0 MIT License uamqp 1.6.3 MIT License urllib3 1.26.13 MIT License certifi 2022.12.7 Mozilla Public License 2.0 (MPL 2.0) pathspec 0.10.3 Mozilla Public License 2.0 (MPL 2.0) portalocker 2.6.0 PSF typing_extensions 4.4.0 Python Software Foundation License zope.event 4.6 Zope Public License","title":"Server"},{"location":"editor-support/licenses/#client","text":"","title":"Client"},{"location":"editor-support/licenses/#visual-studio-code","text":"Name Parents Version License @eslint/eslintrc grizzly-loadtester-vscode 1.3.0 MIT @humanwhocodes/config-array grizzly-loadtester-vscode 0.10.4 Apache-2.0 @humanwhocodes/gitignore-to-minimatch grizzly-loadtester-vscode 1.0.2 Apache-2.0 @humanwhocodes/object-schema grizzly-loadtester-vscode 1.2.1 BSD-3-Clause @nodelib/fs.scandir grizzly-loadtester-vscode 2.1.5 MIT @nodelib/fs.stat grizzly-loadtester-vscode 2.0.5 MIT @nodelib/fs.walk grizzly-loadtester-vscode 1.2.8 MIT @tootallnate/once grizzly-loadtester-vscode 1.1.2 MIT @types/chai grizzly-loadtester-vscode 4.3.3 MIT @types/glob grizzly-loadtester-vscode 8.0.0 MIT @types/json-schema grizzly-loadtester-vscode 7.0.11 MIT @types/json5 grizzly-loadtester-vscode 0.0.29 MIT @types/minimatch grizzly-loadtester-vscode 5.1.2 MIT @types/mocha grizzly-loadtester-vscode 9.1.1 MIT @types/node grizzly-loadtester-vscode 16.11.58 MIT @types/vscode grizzly-loadtester-vscode 1.64.0 MIT @typescript-eslint/eslint-plugin grizzly-loadtester-vscode 5.33.1 MIT @typescript-eslint/parser grizzly-loadtester-vscode 5.33.1 BSD-2-Clause @typescript-eslint/scope-manager grizzly-loadtester-vscode 5.33.1 MIT @typescript-eslint/type-utils grizzly-loadtester-vscode 5.33.1 MIT @typescript-eslint/types grizzly-loadtester-vscode 5.33.1 MIT @typescript-eslint/typescript-estree grizzly-loadtester-vscode 5.33.1 BSD-2-Clause @typescript-eslint/utils grizzly-loadtester-vscode 5.33.1 MIT @typescript-eslint/visitor-keys grizzly-loadtester-vscode 5.33.1 MIT @ungap/promise-all-settled grizzly-loadtester-vscode 1.1.2 ISC @vscode/test-electron grizzly-loadtester-vscode 2.1.2 MIT abbrev grizzly-loadtester-vscode 1.1.1 ISC acorn-jsx grizzly-loadtester-vscode 5.3.2 MIT acorn grizzly-loadtester-vscode 8.8.0 MIT agent-base @vscode/test-electron:grizzly-loadtester-vscode 6.0.2 MIT ajv grizzly-loadtester-vscode 6.12.6 MIT ansi-colors grizzly-loadtester-vscode 4.1.1 MIT ansi-regex has-ansi:grizzly-loadtester-vscode 0.2.1 MIT ansi-regex grizzly-loadtester-vscode 5.0.1 MIT ansi-styles license-checker:grizzly-loadtester-vscode 1.1.0 MIT ansi-styles npm-license-crawler:grizzly-loadtester-vscode 3.2.1 MIT ansi-styles grizzly-loadtester-vscode 4.3.0 MIT anymatch grizzly-loadtester-vscode 3.1.2 ISC argparse grizzly-loadtester-vscode 2.0.1 Python-2.0 array-includes grizzly-loadtester-vscode 3.1.5 MIT array-union grizzly-loadtester-vscode 2.1.0 MIT array.prototype.flat grizzly-loadtester-vscode 1.3.0 MIT asap grizzly-loadtester-vscode 2.0.6 MIT assertion-error grizzly-loadtester-vscode 1.1.0 MIT async grizzly-loadtester-vscode 2.6.4 MIT balanced-match grizzly-loadtester-vscode 1.0.0 MIT big-integer grizzly-loadtester-vscode 1.6.48 Unlicense binary-extensions grizzly-loadtester-vscode 2.2.0 MIT binary grizzly-loadtester-vscode 0.3.0 MIT bluebird grizzly-loadtester-vscode 3.4.7 MIT brace-expansion grizzly-loadtester-vscode 1.1.11 MIT braces grizzly-loadtester-vscode 3.0.2 MIT browser-stdout grizzly-loadtester-vscode 1.3.1 ISC buffer-indexof-polyfill grizzly-loadtester-vscode 1.0.2 MIT buffers grizzly-loadtester-vscode 0.1.1 UNKNOWN builtins grizzly-loadtester-vscode 5.0.1 MIT call-bind grizzly-loadtester-vscode 1.0.2 MIT callsites grizzly-loadtester-vscode 3.1.0 MIT camelcase grizzly-loadtester-vscode 6.3.0 MIT chai grizzly-loadtester-vscode 4.3.6 MIT chainsaw grizzly-loadtester-vscode 0.1.0 MIT/X11 chalk license-checker:grizzly-loadtester-vscode 0.5.1 MIT chalk npm-license-crawler:grizzly-loadtester-vscode 2.4.2 MIT chalk grizzly-loadtester-vscode 4.1.2 MIT check-error grizzly-loadtester-vscode 1.0.2 MIT chokidar grizzly-loadtester-vscode 3.5.3 MIT cliui grizzly-loadtester-vscode 7.0.4 ISC color-convert npm-license-crawler:grizzly-loadtester-vscode 1.9.3 MIT color-convert grizzly-loadtester-vscode 2.0.1 MIT color-name npm-license-crawler:grizzly-loadtester-vscode 1.1.3 MIT color-name grizzly-loadtester-vscode 1.1.4 MIT concat-map grizzly-loadtester-vscode 0.0.1 MIT core-util-is grizzly-loadtester-vscode 1.0.2 MIT cross-spawn grizzly-loadtester-vscode 7.0.3 MIT debug eslint-plugin-import:grizzly-loadtester-vscode 2.6.9 MIT debug eslint-module-utils:grizzly-loadtester-vscode 3.2.7 MIT debug mocha:grizzly-loadtester-vscode 4.3.3 MIT debug grizzly-loadtester-vscode 4.3.4 MIT debuglog grizzly-loadtester-vscode 1.0.1 MIT decamelize grizzly-loadtester-vscode 4.0.0 MIT deep-eql grizzly-loadtester-vscode 3.0.1 MIT deep-is grizzly-loadtester-vscode 0.1.4 MIT define-properties grizzly-loadtester-vscode 1.1.4 MIT dezalgo grizzly-loadtester-vscode 1.0.4 ISC diff grizzly-loadtester-vscode 5.0.0 BSD-3-Clause dir-glob grizzly-loadtester-vscode 3.0.1 MIT doctrine eslint-plugin-import:grizzly-loadtester-vscode 2.1.0 Apache-2.0 doctrine grizzly-loadtester-vscode 3.0.0 Apache-2.0 duplexer2 grizzly-loadtester-vscode 0.1.4 BSD-3-Clause emoji-regex grizzly-loadtester-vscode 8.0.0 MIT es-abstract grizzly-loadtester-vscode 1.20.1 MIT es-shim-unscopables grizzly-loadtester-vscode 1.0.0 MIT es-to-primitive grizzly-loadtester-vscode 1.2.1 MIT esbuild-linux-64 grizzly-loadtester-vscode 0.15.7 MIT esbuild grizzly-loadtester-vscode 0.15.7 MIT escalade grizzly-loadtester-vscode 3.1.1 MIT escape-string-regexp npm-license-crawler:grizzly-loadtester-vscode 1.0.5 MIT escape-string-regexp grizzly-loadtester-vscode 4.0.0 MIT eslint-config-standard-with-typescript grizzly-loadtester-vscode 22.0.0 MIT eslint-config-standard grizzly-loadtester-vscode 17.0.0 MIT eslint-import-resolver-node grizzly-loadtester-vscode 0.3.6 MIT eslint-module-utils grizzly-loadtester-vscode 2.7.4 MIT eslint-plugin-es grizzly-loadtester-vscode 4.1.0 MIT eslint-plugin-import grizzly-loadtester-vscode 2.26.0 MIT eslint-plugin-n grizzly-loadtester-vscode 15.2.4 MIT eslint-plugin-promise grizzly-loadtester-vscode 6.0.0 ISC eslint-scope grizzly-loadtester-vscode 5.1.1 BSD-2-Clause eslint-scope eslint:grizzly-loadtester-vscode 7.1.1 BSD-2-Clause eslint-utils eslint-plugin-es:grizzly-loadtester-vscode 2.1.0 MIT eslint-utils grizzly-loadtester-vscode 3.0.0 MIT eslint-visitor-keys eslint-plugin-es:grizzly-loadtester-vscode 1.3.0 Apache-2.0 eslint-visitor-keys eslint-utils:grizzly-loadtester-vscode 2.1.0 Apache-2.0 eslint-visitor-keys grizzly-loadtester-vscode 3.3.0 Apache-2.0 eslint grizzly-loadtester-vscode 8.22.0 MIT espree grizzly-loadtester-vscode 9.3.3 BSD-2-Clause esquery grizzly-loadtester-vscode 1.4.0 BSD-3-Clause esrecurse grizzly-loadtester-vscode 4.3.0 BSD-2-Clause estraverse grizzly-loadtester-vscode 4.3.0 BSD-2-Clause estraverse esrecurse:grizzly-loadtester-vscode 5.3.0 BSD-2-Clause esutils grizzly-loadtester-vscode 2.0.3 BSD-2-Clause fast-deep-equal grizzly-loadtester-vscode 3.1.3 MIT fast-glob grizzly-loadtester-vscode 3.2.11 MIT fast-json-stable-stringify grizzly-loadtester-vscode 2.1.0 MIT fast-levenshtein grizzly-loadtester-vscode 2.0.6 MIT fastq grizzly-loadtester-vscode 1.13.0 ISC file-entry-cache grizzly-loadtester-vscode 6.0.1 MIT fill-range grizzly-loadtester-vscode 7.0.1 MIT find-up grizzly-loadtester-vscode 5.0.0 MIT flat-cache grizzly-loadtester-vscode 3.0.4 MIT flat grizzly-loadtester-vscode 5.0.2 BSD-3-Clause flatted grizzly-loadtester-vscode 3.2.5 ISC fs.realpath grizzly-loadtester-vscode 1.0.0 ISC fstream grizzly-loadtester-vscode 1.0.12 ISC function-bind grizzly-loadtester-vscode 1.1.1 MIT function.prototype.name grizzly-loadtester-vscode 1.1.5 MIT functional-red-black-tree grizzly-loadtester-vscode 1.0.1 MIT functions-have-names grizzly-loadtester-vscode 1.2.3 MIT get-caller-file grizzly-loadtester-vscode 2.0.5 ISC get-func-name grizzly-loadtester-vscode 2.0.0 MIT get-intrinsic grizzly-loadtester-vscode 1.1.2 MIT get-symbol-description grizzly-loadtester-vscode 1.0.0 MIT github-url-from-git grizzly-loadtester-vscode 1.5.0 MIT github-url-from-username-repo grizzly-loadtester-vscode 1.0.2 BSD-2-Clause glob-parent fast-glob:grizzly-loadtester-vscode 5.1.2 ISC glob-parent grizzly-loadtester-vscode 6.0.2 ISC glob read-package-json:grizzly-loadtester-vscode 5.0.15 ISC glob grizzly-loadtester-vscode 7.2.0 ISC globals grizzly-loadtester-vscode 13.15.0 MIT globby grizzly-loadtester-vscode 11.1.0 MIT graceful-fs read-package-json:grizzly-loadtester-vscode 3.0.12 ISC graceful-fs grizzly-loadtester-vscode 4.2.6 ISC grapheme-splitter grizzly-loadtester-vscode 1.0.4 MIT grizzly-loadtester-vscode 0.0.0 MIT growl grizzly-loadtester-vscode 1.10.5 MIT has-ansi grizzly-loadtester-vscode 0.1.0 MIT has-bigints grizzly-loadtester-vscode 1.0.2 MIT has-flag npm-license-crawler:grizzly-loadtester-vscode 3.0.0 MIT has-flag grizzly-loadtester-vscode 4.0.0 MIT has-property-descriptors grizzly-loadtester-vscode 1.0.0 MIT has-symbols grizzly-loadtester-vscode 1.0.3 MIT has-tostringtag grizzly-loadtester-vscode 1.0.0 MIT has grizzly-loadtester-vscode 1.0.3 MIT he grizzly-loadtester-vscode 1.2.0 MIT http-proxy-agent @vscode/test-electron:grizzly-loadtester-vscode 4.0.1 MIT https-proxy-agent @vscode/test-electron:grizzly-loadtester-vscode 5.0.0 MIT ignore grizzly-loadtester-vscode 5.2.0 MIT import-fresh grizzly-loadtester-vscode 3.3.0 MIT imurmurhash grizzly-loadtester-vscode 0.1.4 MIT inflight grizzly-loadtester-vscode 1.0.6 ISC inherits grizzly-loadtester-vscode 2.0.4 ISC internal-slot grizzly-loadtester-vscode 1.0.3 MIT is-bigint grizzly-loadtester-vscode 1.0.4 MIT is-binary-path grizzly-loadtester-vscode 2.1.0 MIT is-boolean-object grizzly-loadtester-vscode 1.1.2 MIT is-callable grizzly-loadtester-vscode 1.2.4 MIT is-core-module grizzly-loadtester-vscode 2.10.0 MIT is-date-object grizzly-loadtester-vscode 1.0.5 MIT is-extglob grizzly-loadtester-vscode 2.1.1 MIT is-fullwidth-code-point grizzly-loadtester-vscode 3.0.0 MIT is-glob grizzly-loadtester-vscode 4.0.3 MIT is-negative-zero grizzly-loadtester-vscode 2.0.2 MIT is-number-object grizzly-loadtester-vscode 1.0.7 MIT is-number grizzly-loadtester-vscode 7.0.0 MIT is-plain-obj grizzly-loadtester-vscode 2.1.0 MIT is-regex grizzly-loadtester-vscode 1.1.4 MIT is-shared-array-buffer grizzly-loadtester-vscode 1.0.2 MIT is-string grizzly-loadtester-vscode 1.0.7 MIT is-symbol grizzly-loadtester-vscode 1.0.4 MIT is-unicode-supported grizzly-loadtester-vscode 0.1.0 MIT is-weakref grizzly-loadtester-vscode 1.0.2 MIT isarray grizzly-loadtester-vscode 1.0.0 MIT isexe grizzly-loadtester-vscode 2.0.0 ISC jju grizzly-loadtester-vscode 1.4.0 MIT jquery-extend grizzly-loadtester-vscode 2.0.3 MIT js-yaml grizzly-loadtester-vscode 4.1.0 MIT json-parse-helpfulerror grizzly-loadtester-vscode 1.0.3 MIT json-schema-traverse grizzly-loadtester-vscode 0.4.1 MIT json-stable-stringify-without-jsonify grizzly-loadtester-vscode 1.0.1 MIT json5 grizzly-loadtester-vscode 1.0.1 MIT levn grizzly-loadtester-vscode 0.4.1 MIT license-checker grizzly-loadtester-vscode 1.0.0 BSD-3-Clause listenercount grizzly-loadtester-vscode 1.0.1 ISC locate-path grizzly-loadtester-vscode 6.0.0 MIT lodash.merge grizzly-loadtester-vscode 4.6.2 MIT lodash grizzly-loadtester-vscode 4.17.21 MIT log-symbols grizzly-loadtester-vscode 4.1.0 MIT loupe grizzly-loadtester-vscode 2.3.4 MIT lru-cache grizzly-loadtester-vscode 6.0.0 ISC merge2 grizzly-loadtester-vscode 1.4.1 MIT micromatch grizzly-loadtester-vscode 4.0.5 MIT minimatch grizzly-loadtester-vscode 3.1.2 ISC minimatch mocha:grizzly-loadtester-vscode 4.2.1 ISC minimist grizzly-loadtester-vscode 1.2.6 MIT mkdirp license-checker:grizzly-loadtester-vscode 0.3.5 MIT mkdirp grizzly-loadtester-vscode 0.5.5 MIT mocha grizzly-loadtester-vscode 9.2.2 MIT ms eslint-plugin-import:grizzly-loadtester-vscode 2.0.0 MIT ms grizzly-loadtester-vscode 2.1.2 MIT ms mocha:grizzly-loadtester-vscode 2.1.3 MIT nanoid grizzly-loadtester-vscode 3.3.1 MIT natives grizzly-loadtester-vscode 1.1.6 ISC natural-compare grizzly-loadtester-vscode 1.4.0 MIT nopt-defaults grizzly-loadtester-vscode 0.0.1 BSD-3-Clause nopt-usage grizzly-loadtester-vscode 0.1.0 MIT nopt license-checker:grizzly-loadtester-vscode 2.2.1 MIT nopt grizzly-loadtester-vscode 3.0.6 ISC normalize-package-data grizzly-loadtester-vscode 1.0.3 MIT* normalize-path grizzly-loadtester-vscode 3.0.0 MIT npm-license-crawler grizzly-loadtester-vscode 0.2.1 BSD-3-Clause object-inspect grizzly-loadtester-vscode 1.12.2 MIT object-keys grizzly-loadtester-vscode 1.1.1 MIT object.assign grizzly-loadtester-vscode 4.1.4 MIT object.values grizzly-loadtester-vscode 1.1.5 MIT once grizzly-loadtester-vscode 1.4.0 ISC optionator grizzly-loadtester-vscode 0.9.1 MIT p-limit grizzly-loadtester-vscode 3.1.0 MIT p-locate grizzly-loadtester-vscode 5.0.0 MIT parent-module grizzly-loadtester-vscode 1.0.1 MIT path-exists grizzly-loadtester-vscode 4.0.0 MIT path-is-absolute grizzly-loadtester-vscode 1.0.1 MIT path-key grizzly-loadtester-vscode 3.1.1 MIT path-parse grizzly-loadtester-vscode 1.0.7 MIT path-type grizzly-loadtester-vscode 4.0.0 MIT pathval grizzly-loadtester-vscode 1.1.1 MIT picomatch grizzly-loadtester-vscode 2.3.1 MIT prelude-ls grizzly-loadtester-vscode 1.2.1 MIT process-nextick-args grizzly-loadtester-vscode 2.0.1 MIT punycode grizzly-loadtester-vscode 2.1.1 MIT queue-microtask grizzly-loadtester-vscode 1.2.3 MIT randombytes grizzly-loadtester-vscode 2.1.0 MIT read-installed grizzly-loadtester-vscode 3.1.5 ISC read-package-json grizzly-loadtester-vscode 1.3.3 ISC readable-stream grizzly-loadtester-vscode 2.3.7 MIT readdir-scoped-modules grizzly-loadtester-vscode 1.1.0 ISC readdirp grizzly-loadtester-vscode 3.6.0 MIT regexp.prototype.flags grizzly-loadtester-vscode 1.4.3 MIT regexpp grizzly-loadtester-vscode 3.2.0 MIT require-directory grizzly-loadtester-vscode 2.1.1 MIT resolve-from grizzly-loadtester-vscode 4.0.0 MIT resolve grizzly-loadtester-vscode 1.22.1 MIT reusify grizzly-loadtester-vscode 1.0.4 MIT rimraf grizzly-loadtester-vscode 2.7.1 ISC rimraf flat-cache:grizzly-loadtester-vscode 3.0.2 ISC run-parallel grizzly-loadtester-vscode 1.2.0 MIT safe-buffer grizzly-loadtester-vscode 5.1.2 MIT semver normalize-package-data:grizzly-loadtester-vscode 4.3.6 ISC semver grizzly-loadtester-vscode 7.3.7 ISC serialize-javascript grizzly-loadtester-vscode 6.0.0 BSD-3-Clause setimmediate grizzly-loadtester-vscode 1.0.5 MIT shebang-command grizzly-loadtester-vscode 2.0.0 MIT shebang-regex grizzly-loadtester-vscode 3.0.0 MIT side-channel grizzly-loadtester-vscode 1.0.4 MIT slash grizzly-loadtester-vscode 3.0.0 MIT slide grizzly-loadtester-vscode 1.1.6 ISC string-width grizzly-loadtester-vscode 4.2.3 MIT string.prototype.trimend grizzly-loadtester-vscode 1.0.5 MIT string.prototype.trimstart grizzly-loadtester-vscode 1.0.5 MIT string_decoder grizzly-loadtester-vscode 1.1.1 MIT strip-ansi license-checker:grizzly-loadtester-vscode 0.3.0 MIT strip-ansi grizzly-loadtester-vscode 6.0.1 MIT strip-bom grizzly-loadtester-vscode 3.0.0 MIT strip-json-comments grizzly-loadtester-vscode 3.1.1 MIT supports-color license-checker:grizzly-loadtester-vscode 0.2.0 MIT supports-color npm-license-crawler:grizzly-loadtester-vscode 5.5.0 MIT supports-color grizzly-loadtester-vscode 7.2.0 MIT supports-color mocha:grizzly-loadtester-vscode 8.1.1 MIT supports-preserve-symlinks-flag grizzly-loadtester-vscode 1.0.0 MIT text-table grizzly-loadtester-vscode 0.2.0 MIT to-regex-range grizzly-loadtester-vscode 5.0.1 MIT traverse grizzly-loadtester-vscode 0.3.9 MIT/X11 treeify grizzly-loadtester-vscode 1.1.0 MIT tsconfig-paths grizzly-loadtester-vscode 3.14.1 MIT tslib grizzly-loadtester-vscode 1.14.1 0BSD tsutils grizzly-loadtester-vscode 3.21.0 MIT type-check grizzly-loadtester-vscode 0.4.0 MIT type-detect grizzly-loadtester-vscode 4.0.8 MIT type-fest grizzly-loadtester-vscode 0.20.2 (MIT OR CC0-1.0) typescript grizzly-loadtester-vscode 4.7.4 Apache-2.0 unbox-primitive grizzly-loadtester-vscode 1.0.2 MIT unzipper grizzly-loadtester-vscode 0.10.11 MIT uri-js grizzly-loadtester-vscode 4.4.1 BSD-2-Clause util-deprecate grizzly-loadtester-vscode 1.0.2 MIT util-extend grizzly-loadtester-vscode 1.0.3 MIT v8-compile-cache grizzly-loadtester-vscode 2.3.0 MIT vscode-jsonrpc grizzly-loadtester-vscode 6.0.0 MIT vscode-languageclient grizzly-loadtester-vscode 7.0.0 MIT vscode-languageserver-protocol grizzly-loadtester-vscode 3.16.0 MIT vscode-languageserver-types grizzly-loadtester-vscode 3.16.0 MIT which-boxed-primitive grizzly-loadtester-vscode 1.0.2 MIT which grizzly-loadtester-vscode 2.0.2 ISC word-wrap grizzly-loadtester-vscode 1.2.3 MIT workerpool grizzly-loadtester-vscode 6.2.0 Apache-2.0 wrap-ansi grizzly-loadtester-vscode 7.0.0 MIT wrappy grizzly-loadtester-vscode 1.0.2 ISC y18n grizzly-loadtester-vscode 5.0.8 ISC yallist grizzly-loadtester-vscode 4.0.0 ISC yargs-parser grizzly-loadtester-vscode 20.2.4 ISC yargs-unparser grizzly-loadtester-vscode 2.0.0 MIT yargs grizzly-loadtester-vscode 16.2.0 MIT yocto-queue grizzly-loadtester-vscode 0.1.0 MIT","title":"Visual Studio Code"},{"location":"editor-support/editors/","text":"Editors Implementations for your favorite editor is always welcome!","title":"Editors"},{"location":"editor-support/editors/#editors","text":"Implementations for your favorite editor is always welcome!","title":"Editors"},{"location":"editor-support/editors/vscode/","text":"grizzly-vscode This is the grizzly-loadtester Visual Studio Code extension that makes it easier to develop load test scenarios by providing auto-complete of step expressions! Download the extension from Visual Studio Marketplace . For the extension to work, you have to install the language server grizzly-loadtester-ls which is published on pypi.org . Install it with: python -m pip install grizzly-loadtester-ls And make sure it's in a directory that is part of your PATH environment variable.","title":"Visual Studio Code"},{"location":"editor-support/editors/vscode/#grizzly-vscode","text":"This is the grizzly-loadtester Visual Studio Code extension that makes it easier to develop load test scenarios by providing auto-complete of step expressions! Download the extension from Visual Studio Marketplace . For the extension to work, you have to install the language server grizzly-loadtester-ls which is published on pypi.org . Install it with: python -m pip install grizzly-loadtester-ls And make sure it's in a directory that is part of your PATH environment variable.","title":"grizzly-vscode"},{"location":"framework/changelog/","text":"Changelog v2.5.7 fc436358 : tag measurements with scenario they belong to (#185) 67abbb50 : write user count per user class name to influx every 5 seconds (#184) v2.5.6 516b119f : background variable declaration (#183) 2ae0c0b2 : updated workflow actions to remove warnings (#182) v2.5.5 2a4041eb : csv logging (#181) v2.5.4 65de8865 : concurrency fixes in MQ and SB related code (#180) v2.5.3 d9c89199 : get messages from MQ with SYNCPOINT and configuration of max message size (#179) 784f6b89 : IotHubUser, for uploading files to Azure IoT Hub (#177) 1a4a826f : improved support for jinja2 expressions (#176) c28e52d8 : grizzly.tasks.client.messagequeue needs unique worker for each instance of a scenario (#175) 5cceb577 : print returncode of locust to stdout (#174) v2.5.2 70d1d245 : azure.servicebus receiver sometimes returns no message, even if there... (#173) 7b63d1b6 : better handling of arthmetic when parsing out variables from templates (#172) caf9693d : on_consumer testdata variables needs information about current scenario (#171) v2.5.1 599db8eb : instructions in example docs on how to install vscode extension (#169) e57eea5d : corrected grizzly-cli run commands in example (#167) 161af067 : async-messaged returns un-encoded RFH2 payload after PUT (#165) 7d034b26 : removed deprecated set-output commands in workflow (#164) 5a35ffef : more MQ information (#162) v2.5.0 ef6a4675 : move out docs extras from pyproject.toml (#158) d4880ee2 : env conf inline resolving and \"generic\" UntilRequestTask (#157) 7285294b : refactoring of get_templates (#156) b694acaa : implementation of %g (GUID/UUID) formatter for AtomicRandomString (#152) a3854842 : Post XML, multipart/form-data and metadata per request (#151) 10883c87 : dependency update 2209 (#150) 1ce3a43c : persist variable values between runs (override initial value based on previous runs) (#149) b39247e8 : declared and found variable cross-check (#148) e4e353de : fixed broken release workflow (#147) v2.4.6 1a6e07da : fix missing variables due to filter (pipe) in templates (#145) e7e606b7 : checkout release tag correctly so edit url in docs is correct (#146) cc5bf649 : added documentation for editor support (#144) c37140aa : correct typings for release workflow inputs (#143) c3ed2eb7 : document response handler expression arguments (#142) 3d2aa051 : documentation of metadata comments in feature files (#141) 5db8bfe3 : allow templating strings as input to WaitTask (#140) e297da03 : e2e dist (#139) 7a491161 : run e2e tests distributed (#138) b24db98b : create zmq socket for each request (#136) 9777db82 : fix for last task not being executed when user is stopping (#135) v2.4.5 eba5ba1d : no testdata address, when running distributed (#134) 606c7a80 : changed mq version (#132) v2.4.4 501b5960 : allow an arbritary number of matches (#130) d8406a55 : loop task (#129) a7928eea : TransformerContentType should be permutated in y direction (#128) 2bb8c045 : updated dependencies due to lxml security fix (#127) aea3d97b : grizzly implementation of print_percentile_stats (#125) 4ba8066d : annotate non-enum custom types with __vector__ (#124) fa4a2b16 : annotations for enums used in step expressions (#123) v2.4.3 27ebe108 : mq rfh2 support (#122) 8b794ad1 : create list of tasks for pointer when switching (#121) 3e16160c : fixed examples for conditional task (#120) v2.4.2 da3c335d : conditional tasks task (#119) cbcb1b8b : new location for logo in repo (#118) v2.4.1 1ce7f0ad : fix for documentation build and deploy (#117) 484f8010 : changed to novella build backend and improved documentation (#116) v2.4.0 8e026ad8 : updated dependencies (#115) 5c747f53 : request wait task (#114) 6684c357 : TimerTask to measure \"response time\" for a group of tasks (#113) 5ceca1e2 : bug fixes in BlobStorageClient.put and scenario iterator (#112) 53ed0ad5 : remove debug print statement (#111) 4f0f01f7 : sort request statistics per scenario (#110) 35091c96 : grizzly.tasks.client must have a name (#109) v2.3.1 c754a8aa : support ISO 8601 formated DateTime and Time (#107) e33cd941 : client task ibm messagequeue (#103) eabe7b8f : possibility to implement custom (non-grizzly) atomic variables (#102) e4193dd4 : possibility to register custom locust message types and handlers (#101) 13b6c444 : scenario statistics (#98) ba37b60a : validating response step expression updated (#97) 89149d9d : \"end to end\" (E2E) test cases (#95) v2.3.0 b4fc150f : Change scenario hash to numerical index (#94) 6ecc7ab3 : support for parallell tasks (#92) 2f7025d9 : make tests runnable on windows (#91) v2.2.1 0ae1b373 : automagically check pypi for package url if unknown (#90) e6ef9d8f : install additional script dependencies correct (#89) c0a53532 : add support for requirements-script.txt to pip-sync wrapper (#88) 67f3d269 : install and cache script requirements (#87) ddd9929c : restructuring of code-quality workflow (#86) v2.2.0 d45b62d1 : github action action-push-tag@v1 is broken (#85) 283fe3fe : bug fix for iterations to stop when not finishing (#84) 0ed596f2 : Feature/clients tasks (#81) 6e6496ed : create docs/licenses if it does not exist, before trying to write md file (#79) 0dd489a3 : restructure of documentation (#78) v2.1.0 c4260a9e : Feature/response handlers (#77) 8278d17a : step to set user metadata/header key values (#75) 11de9b7f : clearer job name in code-quality workflow (#70) b6845b79 : Feature/issue 64 pep518 (#69) fbd96cfa : Feature/issue 61 pytz (#68) v2.0.0 af5e639b : twine: command not found (#67) 052a5ab9 : Feature/dependency update round 2 (#66) d4a3b935 : Feature/mq heartbeat (#65) 884b6761 : Feature/dependencies update (#63) 02c88045 : Plain text transformer fix, plus added rendering of date offset value (#62) 001cc5e5 : Bug/until task aborts (#60) v1.5.3 7c2b7a91 : Feature/cli docs (#59) a53f9159 : Bug/until stops too soon (#58) f53bb8b8 : removed debug print statements (#56) fb9f4933 : removed debug print statements (#56) v1.5.2 fb9f4933 : removed debug print statements (#56) v1.5.1 a2857569 : verify_certificates bug fixed (#55) v1.5.0 1c57c7f0 : Feature/restart scenario (#54) 9326218f : MQ concurrency fix (#53) cc178860 : renamed grizzly.tasks to grizzly.scenarios (#52) 281e9beb : fixed bug in parse_arguments if an argument value contained comma (#51) v1.4.4 e13ff471 : Feature/date parse task (#50) d16ef8e1 : handle exceptions during until retries (#49) 0994f9af : increased test coverage (#48) eaaeab22 : Fix for doing retry upon receiving MQRC_TRUNCATED_MSG_FAILED while browsing messages (#47) 88202428 : support for templating in arguments in condition (#46) v1.4.3 3e47adbd : fixed alignment i scenario summary (#45) v1.4.2 e976144b : Bug/async messaged logging (#44) b4b0be63 : Feature/request until (#42) v1.4.1 e6d8fb3f : fix for ensuring correct data type in metric written to influx (#41) v1.4.0 26b81305 : print start and stop date and time when finished (#40) 4aef0eef : request response_time fixes (#39) fb95268f : updated dependencies and devcontainer (#38) f98d904d : Feature/scenario info (#37) v1.3.1 73827bf4 : error logging in transformer class (#35) 3e5e03aa : init racecondition (#36) dd0c75a5 : support for request template files in combination with data tables (#34) 8d56f4fe : Feature/parameterize more (#33) v1.3.0 60f39988 : transparent support for setting content type in endpoint (#32) 423bc994 : expression support for service bus functionality (#31) 2e2695df : support for offset in AtomicDate (#30) 41b78e89 : AtomicMessageQueue content type support (#29) 979d4bbb : unified arguments handling through out grizzly (#28) 6fad96e4 : simplified AtomicMessageQueue and AtomicServiceBus (#27) 64888c05 : implementation of getter tasks (http) (#26) 2d6862d7 : Restored dummy_pymqi.py, the added stuff wasn't needed 4f21a8d3 : MessageQueueUser: get messages that matches expression 1e1edc44 : run code quality workflow when PR is updated 6dc839c9 : corrected sentence in documentation for SleepTask v1.2.0 6ee5fffe : added documentation for the different task types 1b91d79b : implementation of AtomicServiceBus variable b867d471 : ServiceBus support in async-messaged 83c0ac9c : refactoring of grizzly_extras.messagequeue 9b9953e6 : included mypy extension in devcontainer aea0c288 : implemented RECEIVE for ServiceBusUser b046b60c : Changed spawn_rate to float and fixed tests 3ce0b102 : Changed spawn rate from int to float a789a71d : Added support for user weight 29f7d047 : updated atomic variables getting value and arguments 81ccbed1 : change log level for grizzly_extras if started with verbose v1.1.0 b78be958 : new task to parse data b2ed98a1 : XmlTransformer: match parts of a document, and dump it to string 9c55e5a3 : move testdata production if variable has on_consumer = True cfe9875b : specify external dependencies for users and variables in the objects themself 2140fe79 : new variable AtomicMessageQueue 1f6dba03 : refactoring for clearer distinction between utils and step helpers. 99fab953 : fixing empty changelog in workflow@github c5ddeeb9 : generate changelog when building documentation 5e595637 : fixed missed float -> SleepTask change in test 2c688554 : improved base for adding different types of tasks cb8db862 : reafactor LocustContext* to GrizzlyContext* 3f1137b9 : refactoring of grizzly.tasks bd3382e0 : refactoring RequestContext to RequestTask 031a9595 : handle edge cases with Getitem nodes ca7c17d7 : handle Getitem nodes when parsing templates for variables a1cabb31 : only try to remove secrets from dicts 1145a651 : possibility to store json objects/list in variables v1.0.1 dae7be58 : Corrected string comparison operator 4b8a8470 : Adjusted test for messagequeue bd9bb977 : Fix for being able to log MQ request payload cc5dfff6 : updated mkdocs to 1.2.3 due to CVE-2021-40978 604f5704 : fixed url","title":"Changelog"},{"location":"framework/changelog/#changelog","text":"","title":"Changelog"},{"location":"framework/changelog/#v257","text":"fc436358 : tag measurements with scenario they belong to (#185) 67abbb50 : write user count per user class name to influx every 5 seconds (#184)","title":"v2.5.7"},{"location":"framework/changelog/#v256","text":"516b119f : background variable declaration (#183) 2ae0c0b2 : updated workflow actions to remove warnings (#182)","title":"v2.5.6"},{"location":"framework/changelog/#v255","text":"2a4041eb : csv logging (#181)","title":"v2.5.5"},{"location":"framework/changelog/#v254","text":"65de8865 : concurrency fixes in MQ and SB related code (#180)","title":"v2.5.4"},{"location":"framework/changelog/#v253","text":"d9c89199 : get messages from MQ with SYNCPOINT and configuration of max message size (#179) 784f6b89 : IotHubUser, for uploading files to Azure IoT Hub (#177) 1a4a826f : improved support for jinja2 expressions (#176) c28e52d8 : grizzly.tasks.client.messagequeue needs unique worker for each instance of a scenario (#175) 5cceb577 : print returncode of locust to stdout (#174)","title":"v2.5.3"},{"location":"framework/changelog/#v252","text":"70d1d245 : azure.servicebus receiver sometimes returns no message, even if there... (#173) 7b63d1b6 : better handling of arthmetic when parsing out variables from templates (#172) caf9693d : on_consumer testdata variables needs information about current scenario (#171)","title":"v2.5.2"},{"location":"framework/changelog/#v251","text":"599db8eb : instructions in example docs on how to install vscode extension (#169) e57eea5d : corrected grizzly-cli run commands in example (#167) 161af067 : async-messaged returns un-encoded RFH2 payload after PUT (#165) 7d034b26 : removed deprecated set-output commands in workflow (#164) 5a35ffef : more MQ information (#162)","title":"v2.5.1"},{"location":"framework/changelog/#v250","text":"ef6a4675 : move out docs extras from pyproject.toml (#158) d4880ee2 : env conf inline resolving and \"generic\" UntilRequestTask (#157) 7285294b : refactoring of get_templates (#156) b694acaa : implementation of %g (GUID/UUID) formatter for AtomicRandomString (#152) a3854842 : Post XML, multipart/form-data and metadata per request (#151) 10883c87 : dependency update 2209 (#150) 1ce3a43c : persist variable values between runs (override initial value based on previous runs) (#149) b39247e8 : declared and found variable cross-check (#148) e4e353de : fixed broken release workflow (#147)","title":"v2.5.0"},{"location":"framework/changelog/#v246","text":"1a6e07da : fix missing variables due to filter (pipe) in templates (#145) e7e606b7 : checkout release tag correctly so edit url in docs is correct (#146) cc5bf649 : added documentation for editor support (#144) c37140aa : correct typings for release workflow inputs (#143) c3ed2eb7 : document response handler expression arguments (#142) 3d2aa051 : documentation of metadata comments in feature files (#141) 5db8bfe3 : allow templating strings as input to WaitTask (#140) e297da03 : e2e dist (#139) 7a491161 : run e2e tests distributed (#138) b24db98b : create zmq socket for each request (#136) 9777db82 : fix for last task not being executed when user is stopping (#135)","title":"v2.4.6"},{"location":"framework/changelog/#v245","text":"eba5ba1d : no testdata address, when running distributed (#134) 606c7a80 : changed mq version (#132)","title":"v2.4.5"},{"location":"framework/changelog/#v244","text":"501b5960 : allow an arbritary number of matches (#130) d8406a55 : loop task (#129) a7928eea : TransformerContentType should be permutated in y direction (#128) 2bb8c045 : updated dependencies due to lxml security fix (#127) aea3d97b : grizzly implementation of print_percentile_stats (#125) 4ba8066d : annotate non-enum custom types with __vector__ (#124) fa4a2b16 : annotations for enums used in step expressions (#123)","title":"v2.4.4"},{"location":"framework/changelog/#v243","text":"27ebe108 : mq rfh2 support (#122) 8b794ad1 : create list of tasks for pointer when switching (#121) 3e16160c : fixed examples for conditional task (#120)","title":"v2.4.3"},{"location":"framework/changelog/#v242","text":"da3c335d : conditional tasks task (#119) cbcb1b8b : new location for logo in repo (#118)","title":"v2.4.2"},{"location":"framework/changelog/#v241","text":"1ce7f0ad : fix for documentation build and deploy (#117) 484f8010 : changed to novella build backend and improved documentation (#116)","title":"v2.4.1"},{"location":"framework/changelog/#v240","text":"8e026ad8 : updated dependencies (#115) 5c747f53 : request wait task (#114) 6684c357 : TimerTask to measure \"response time\" for a group of tasks (#113) 5ceca1e2 : bug fixes in BlobStorageClient.put and scenario iterator (#112) 53ed0ad5 : remove debug print statement (#111) 4f0f01f7 : sort request statistics per scenario (#110) 35091c96 : grizzly.tasks.client must have a name (#109)","title":"v2.4.0"},{"location":"framework/changelog/#v231","text":"c754a8aa : support ISO 8601 formated DateTime and Time (#107) e33cd941 : client task ibm messagequeue (#103) eabe7b8f : possibility to implement custom (non-grizzly) atomic variables (#102) e4193dd4 : possibility to register custom locust message types and handlers (#101) 13b6c444 : scenario statistics (#98) ba37b60a : validating response step expression updated (#97) 89149d9d : \"end to end\" (E2E) test cases (#95)","title":"v2.3.1"},{"location":"framework/changelog/#v230","text":"b4fc150f : Change scenario hash to numerical index (#94) 6ecc7ab3 : support for parallell tasks (#92) 2f7025d9 : make tests runnable on windows (#91)","title":"v2.3.0"},{"location":"framework/changelog/#v221","text":"0ae1b373 : automagically check pypi for package url if unknown (#90) e6ef9d8f : install additional script dependencies correct (#89) c0a53532 : add support for requirements-script.txt to pip-sync wrapper (#88) 67f3d269 : install and cache script requirements (#87) ddd9929c : restructuring of code-quality workflow (#86)","title":"v2.2.1"},{"location":"framework/changelog/#v220","text":"d45b62d1 : github action action-push-tag@v1 is broken (#85) 283fe3fe : bug fix for iterations to stop when not finishing (#84) 0ed596f2 : Feature/clients tasks (#81) 6e6496ed : create docs/licenses if it does not exist, before trying to write md file (#79) 0dd489a3 : restructure of documentation (#78)","title":"v2.2.0"},{"location":"framework/changelog/#v210","text":"c4260a9e : Feature/response handlers (#77) 8278d17a : step to set user metadata/header key values (#75) 11de9b7f : clearer job name in code-quality workflow (#70) b6845b79 : Feature/issue 64 pep518 (#69) fbd96cfa : Feature/issue 61 pytz (#68)","title":"v2.1.0"},{"location":"framework/changelog/#v200","text":"af5e639b : twine: command not found (#67) 052a5ab9 : Feature/dependency update round 2 (#66) d4a3b935 : Feature/mq heartbeat (#65) 884b6761 : Feature/dependencies update (#63) 02c88045 : Plain text transformer fix, plus added rendering of date offset value (#62) 001cc5e5 : Bug/until task aborts (#60)","title":"v2.0.0"},{"location":"framework/changelog/#v153","text":"7c2b7a91 : Feature/cli docs (#59) a53f9159 : Bug/until stops too soon (#58) f53bb8b8 : removed debug print statements (#56) fb9f4933 : removed debug print statements (#56)","title":"v1.5.3"},{"location":"framework/changelog/#v152","text":"fb9f4933 : removed debug print statements (#56)","title":"v1.5.2"},{"location":"framework/changelog/#v151","text":"a2857569 : verify_certificates bug fixed (#55)","title":"v1.5.1"},{"location":"framework/changelog/#v150","text":"1c57c7f0 : Feature/restart scenario (#54) 9326218f : MQ concurrency fix (#53) cc178860 : renamed grizzly.tasks to grizzly.scenarios (#52) 281e9beb : fixed bug in parse_arguments if an argument value contained comma (#51)","title":"v1.5.0"},{"location":"framework/changelog/#v144","text":"e13ff471 : Feature/date parse task (#50) d16ef8e1 : handle exceptions during until retries (#49) 0994f9af : increased test coverage (#48) eaaeab22 : Fix for doing retry upon receiving MQRC_TRUNCATED_MSG_FAILED while browsing messages (#47) 88202428 : support for templating in arguments in condition (#46)","title":"v1.4.4"},{"location":"framework/changelog/#v143","text":"3e47adbd : fixed alignment i scenario summary (#45)","title":"v1.4.3"},{"location":"framework/changelog/#v142","text":"e976144b : Bug/async messaged logging (#44) b4b0be63 : Feature/request until (#42)","title":"v1.4.2"},{"location":"framework/changelog/#v141","text":"e6d8fb3f : fix for ensuring correct data type in metric written to influx (#41)","title":"v1.4.1"},{"location":"framework/changelog/#v140","text":"26b81305 : print start and stop date and time when finished (#40) 4aef0eef : request response_time fixes (#39) fb95268f : updated dependencies and devcontainer (#38) f98d904d : Feature/scenario info (#37)","title":"v1.4.0"},{"location":"framework/changelog/#v131","text":"73827bf4 : error logging in transformer class (#35) 3e5e03aa : init racecondition (#36) dd0c75a5 : support for request template files in combination with data tables (#34) 8d56f4fe : Feature/parameterize more (#33)","title":"v1.3.1"},{"location":"framework/changelog/#v130","text":"60f39988 : transparent support for setting content type in endpoint (#32) 423bc994 : expression support for service bus functionality (#31) 2e2695df : support for offset in AtomicDate (#30) 41b78e89 : AtomicMessageQueue content type support (#29) 979d4bbb : unified arguments handling through out grizzly (#28) 6fad96e4 : simplified AtomicMessageQueue and AtomicServiceBus (#27) 64888c05 : implementation of getter tasks (http) (#26) 2d6862d7 : Restored dummy_pymqi.py, the added stuff wasn't needed 4f21a8d3 : MessageQueueUser: get messages that matches expression 1e1edc44 : run code quality workflow when PR is updated 6dc839c9 : corrected sentence in documentation for SleepTask","title":"v1.3.0"},{"location":"framework/changelog/#v120","text":"6ee5fffe : added documentation for the different task types 1b91d79b : implementation of AtomicServiceBus variable b867d471 : ServiceBus support in async-messaged 83c0ac9c : refactoring of grizzly_extras.messagequeue 9b9953e6 : included mypy extension in devcontainer aea0c288 : implemented RECEIVE for ServiceBusUser b046b60c : Changed spawn_rate to float and fixed tests 3ce0b102 : Changed spawn rate from int to float a789a71d : Added support for user weight 29f7d047 : updated atomic variables getting value and arguments 81ccbed1 : change log level for grizzly_extras if started with verbose","title":"v1.2.0"},{"location":"framework/changelog/#v110","text":"b78be958 : new task to parse data b2ed98a1 : XmlTransformer: match parts of a document, and dump it to string 9c55e5a3 : move testdata production if variable has on_consumer = True cfe9875b : specify external dependencies for users and variables in the objects themself 2140fe79 : new variable AtomicMessageQueue 1f6dba03 : refactoring for clearer distinction between utils and step helpers. 99fab953 : fixing empty changelog in workflow@github c5ddeeb9 : generate changelog when building documentation 5e595637 : fixed missed float -> SleepTask change in test 2c688554 : improved base for adding different types of tasks cb8db862 : reafactor LocustContext* to GrizzlyContext* 3f1137b9 : refactoring of grizzly.tasks bd3382e0 : refactoring RequestContext to RequestTask 031a9595 : handle edge cases with Getitem nodes ca7c17d7 : handle Getitem nodes when parsing templates for variables a1cabb31 : only try to remove secrets from dicts 1145a651 : possibility to store json objects/list in variables","title":"v1.1.0"},{"location":"framework/changelog/#v101","text":"dae7be58 : Corrected string comparison operator 4b8a8470 : Adjusted test for messagequeue bd9bb977 : Fix for being able to log MQ request payload cc5dfff6 : updated mkdocs to 1.2.3 due to CVE-2021-40978 604f5704 : fixed url","title":"v1.0.1"},{"location":"framework/licenses/","text":"Licenses The MIT License (MIT) Copyright \u00a9 2021 Biometria Ekonomiska F\u00f6rening Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \u201cSoftware\u201d), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \u201cAS IS\u201d, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Third party licenses Python dependencies Name Version License protobuf 4.21.12 3-Clause BSD License PyNaCl 1.5.0 Apache License 2.0 bcrypt 4.0.1 Apache Software License bleach 5.0.1 Apache Software License deprecation 2.1.0 Apache Software License ghp-import 2.1.0 Apache Software License google-api-core 2.11.0 Apache Software License google-auth 2.15.0 Apache Software License googleapis-common-protos 1.57.0 Apache Software License importlib-metadata 5.1.0 Apache Software License janus 1.0.0 Apache Software License jsonpath-ng 1.5.3 Apache Software License msgpack 1.0.4 Apache Software License opencensus 0.11.0 Apache Software License opencensus-context 0.1.3 Apache Software License opencensus-ext-azure 1.1.7 Apache Software License readme-renderer 37.3 Apache Software License requests 2.28.1 Apache Software License requests-toolbelt 0.10.1 Apache Software License requests-unixsocket 0.3.0 Apache Software License rfc3986 2.0.0 Apache Software License rsa 4.9 Apache Software License twine 3.8.0 Apache Software License tzdata 2022.7 Apache Software License watchdog 2.2.0 Apache Software License yapf 0.32.0 Apache Software License cryptography 38.0.4 Apache Software License; BSD License packaging 21.3 Apache Software License; BSD License python-dateutil 2.8.2 Apache Software License; BSD License PySocks 1.7.1 BSD ply 3.11 BSD Flask 2.2.2 BSD License Flask-BasicAuth 0.2.0 BSD License Jinja2 3.1.2 BSD License Markdown 3.3.7 BSD License MarkupSafe 2.1.1 BSD License Pygments 2.13.0 BSD License SecretStorage 3.3.3 BSD License Werkzeug 2.2.2 BSD License aenum 3.1.11 BSD License astor 0.8.1 BSD License behave 1.2.6 BSD License click 8.1.3 BSD License colorama 0.4.6 BSD License decorator 5.1.1 BSD License idna 3.4 BSD License isodate 0.6.1 BSD License itsdangerous 2.1.2 BSD License lxml 4.9.2 BSD License mkdocs 1.4.2 BSD License oauthlib 3.2.2 BSD License parse 1.19.0 BSD License parse-type 0.6.0 BSD License pip-tools 6.12.0 BSD License psutil 5.9.4 BSD License pyasn1 0.4.8 BSD License pyasn1-modules 0.2.8 BSD License pycparser 2.21 BSD License requests-oauthlib 1.3.1 BSD License setproctitle 1.3.2 BSD License webencodings 0.5.1 BSD License wrapt 1.14.1 BSD License docutils 0.19 BSD License; GNU General Public License (GPL); Public Domain; Python Software Foundation License pyzmq 22.3.0 BSD License; GNU Library or Lesser General Public License (LGPL) paho-mqtt 1.6.1 Eclipse Public License v2.0 / Eclipse Distribution License v1.0 chardet 4.0.0 GNU Library or Lesser General Public License (LGPL) paramiko 2.12.0 GNU Library or Lesser General Public License (LGPL) geventhttpclient 2.0.8 MIT Brotli 1.0.9 MIT License ConfigArgParse 1.5.3 MIT License DataProperty 0.55.0 MIT License Deprecated 1.2.13 MIT License Flask-Cors 3.0.10 MIT License PyJWT 2.6.0 MIT License PyYAML 5.4.1 MIT License azure-common 1.1.28 MIT License azure-core 1.26.1 MIT License azure-identity 1.12.0 MIT License azure-iot-device 2.12.0 MIT License azure-servicebus 7.8.1 MIT License azure-storage-blob 12.14.1 MIT License build 0.9.0 MIT License cachetools 5.2.0 MIT License cffi 1.15.1 MIT License charset-normalizer 2.1.1 MIT License craftr-dsl 0.7.7 MIT License databind 1.5.3 MIT License databind.core 1.5.3 MIT License databind.json 1.5.3 MIT License docspec 2.0.2 MIT License docspec-python 2.0.2 MIT License docstring-parser 0.11 MIT License gevent 22.10.2 MIT License greenlet 2.0.1 MIT License influxdb 5.3.1 MIT License jaraco.classes 3.2.3 MIT License jeepney 0.8.0 MIT License locust 2.12.2 MIT License mbstrdecoder 1.1.1 MIT License mergedeep 1.3.4 MIT License mkdocs-material 8.5.11 MIT License mkdocs-material-extensions 1.1.1 MIT License more-itertools 9.0.0 MIT License msal 1.20.0 MIT License msal-extensions 1.0.0 MIT License msrest 0.7.1 MIT License mypy-extensions 0.4.3 MIT License novella 0.2.3 MIT License nr.util 0.8.12 MIT License pathvalidate 2.5.2 MIT License pep517 0.13.0 MIT License pkginfo 1.9.2 MIT License pydoc-markdown 4.6.4 MIT License pymdown-extensions 9.9 MIT License pyparsing 3.0.9 MIT License pytablewriter 0.64.2 MIT License pytz 2022.6 MIT License pyyaml_env_tag 0.1 MIT License roundrobin 0.0.4 MIT License six 1.16.0 MIT License tabledata 1.3.0 MIT License tcolorpy 0.1.2 MIT License termcolor 1.1.0 MIT License tomli 2.0.1 MIT License tomli_w 1.0.0 MIT License typepy 1.3.0 MIT License uamqp 1.6.3 MIT License urllib3 1.26.13 MIT License zipp 3.11.0 MIT License tqdm 4.64.1 MIT License; Mozilla Public License 2.0 (MPL 2.0) keyring 23.11.0 MIT License; Python Software Foundation License certifi 2022.12.7 Mozilla Public License 2.0 (MPL 2.0) portalocker 2.6.0 PSF typing_extensions 4.4.0 Python Software Foundation License zope.event 4.6 Zope Public License zope.interface 5.5.2 Zope Public License Native dependencies Container images (both grizzly runtime and Microsoft Visual Code devcontainer) contains dependencies from IBM MQ Redistributable Components . The redistributable license terms may be found in the relevant IBM MQ Program license agreement, which may be found at the IBM Software License Agreements website, or in licenses/ directory in the archive .","title":"Licenses"},{"location":"framework/licenses/#licenses","text":"","title":"Licenses"},{"location":"framework/licenses/#the-mit-license-mit","text":"Copyright \u00a9 2021 Biometria Ekonomiska F\u00f6rening Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \u201cSoftware\u201d), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \u201cAS IS\u201d, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"The MIT License (MIT)"},{"location":"framework/licenses/#third-party-licenses","text":"","title":"Third party licenses"},{"location":"framework/licenses/#python-dependencies","text":"Name Version License protobuf 4.21.12 3-Clause BSD License PyNaCl 1.5.0 Apache License 2.0 bcrypt 4.0.1 Apache Software License bleach 5.0.1 Apache Software License deprecation 2.1.0 Apache Software License ghp-import 2.1.0 Apache Software License google-api-core 2.11.0 Apache Software License google-auth 2.15.0 Apache Software License googleapis-common-protos 1.57.0 Apache Software License importlib-metadata 5.1.0 Apache Software License janus 1.0.0 Apache Software License jsonpath-ng 1.5.3 Apache Software License msgpack 1.0.4 Apache Software License opencensus 0.11.0 Apache Software License opencensus-context 0.1.3 Apache Software License opencensus-ext-azure 1.1.7 Apache Software License readme-renderer 37.3 Apache Software License requests 2.28.1 Apache Software License requests-toolbelt 0.10.1 Apache Software License requests-unixsocket 0.3.0 Apache Software License rfc3986 2.0.0 Apache Software License rsa 4.9 Apache Software License twine 3.8.0 Apache Software License tzdata 2022.7 Apache Software License watchdog 2.2.0 Apache Software License yapf 0.32.0 Apache Software License cryptography 38.0.4 Apache Software License; BSD License packaging 21.3 Apache Software License; BSD License python-dateutil 2.8.2 Apache Software License; BSD License PySocks 1.7.1 BSD ply 3.11 BSD Flask 2.2.2 BSD License Flask-BasicAuth 0.2.0 BSD License Jinja2 3.1.2 BSD License Markdown 3.3.7 BSD License MarkupSafe 2.1.1 BSD License Pygments 2.13.0 BSD License SecretStorage 3.3.3 BSD License Werkzeug 2.2.2 BSD License aenum 3.1.11 BSD License astor 0.8.1 BSD License behave 1.2.6 BSD License click 8.1.3 BSD License colorama 0.4.6 BSD License decorator 5.1.1 BSD License idna 3.4 BSD License isodate 0.6.1 BSD License itsdangerous 2.1.2 BSD License lxml 4.9.2 BSD License mkdocs 1.4.2 BSD License oauthlib 3.2.2 BSD License parse 1.19.0 BSD License parse-type 0.6.0 BSD License pip-tools 6.12.0 BSD License psutil 5.9.4 BSD License pyasn1 0.4.8 BSD License pyasn1-modules 0.2.8 BSD License pycparser 2.21 BSD License requests-oauthlib 1.3.1 BSD License setproctitle 1.3.2 BSD License webencodings 0.5.1 BSD License wrapt 1.14.1 BSD License docutils 0.19 BSD License; GNU General Public License (GPL); Public Domain; Python Software Foundation License pyzmq 22.3.0 BSD License; GNU Library or Lesser General Public License (LGPL) paho-mqtt 1.6.1 Eclipse Public License v2.0 / Eclipse Distribution License v1.0 chardet 4.0.0 GNU Library or Lesser General Public License (LGPL) paramiko 2.12.0 GNU Library or Lesser General Public License (LGPL) geventhttpclient 2.0.8 MIT Brotli 1.0.9 MIT License ConfigArgParse 1.5.3 MIT License DataProperty 0.55.0 MIT License Deprecated 1.2.13 MIT License Flask-Cors 3.0.10 MIT License PyJWT 2.6.0 MIT License PyYAML 5.4.1 MIT License azure-common 1.1.28 MIT License azure-core 1.26.1 MIT License azure-identity 1.12.0 MIT License azure-iot-device 2.12.0 MIT License azure-servicebus 7.8.1 MIT License azure-storage-blob 12.14.1 MIT License build 0.9.0 MIT License cachetools 5.2.0 MIT License cffi 1.15.1 MIT License charset-normalizer 2.1.1 MIT License craftr-dsl 0.7.7 MIT License databind 1.5.3 MIT License databind.core 1.5.3 MIT License databind.json 1.5.3 MIT License docspec 2.0.2 MIT License docspec-python 2.0.2 MIT License docstring-parser 0.11 MIT License gevent 22.10.2 MIT License greenlet 2.0.1 MIT License influxdb 5.3.1 MIT License jaraco.classes 3.2.3 MIT License jeepney 0.8.0 MIT License locust 2.12.2 MIT License mbstrdecoder 1.1.1 MIT License mergedeep 1.3.4 MIT License mkdocs-material 8.5.11 MIT License mkdocs-material-extensions 1.1.1 MIT License more-itertools 9.0.0 MIT License msal 1.20.0 MIT License msal-extensions 1.0.0 MIT License msrest 0.7.1 MIT License mypy-extensions 0.4.3 MIT License novella 0.2.3 MIT License nr.util 0.8.12 MIT License pathvalidate 2.5.2 MIT License pep517 0.13.0 MIT License pkginfo 1.9.2 MIT License pydoc-markdown 4.6.4 MIT License pymdown-extensions 9.9 MIT License pyparsing 3.0.9 MIT License pytablewriter 0.64.2 MIT License pytz 2022.6 MIT License pyyaml_env_tag 0.1 MIT License roundrobin 0.0.4 MIT License six 1.16.0 MIT License tabledata 1.3.0 MIT License tcolorpy 0.1.2 MIT License termcolor 1.1.0 MIT License tomli 2.0.1 MIT License tomli_w 1.0.0 MIT License typepy 1.3.0 MIT License uamqp 1.6.3 MIT License urllib3 1.26.13 MIT License zipp 3.11.0 MIT License tqdm 4.64.1 MIT License; Mozilla Public License 2.0 (MPL 2.0) keyring 23.11.0 MIT License; Python Software Foundation License certifi 2022.12.7 Mozilla Public License 2.0 (MPL 2.0) portalocker 2.6.0 PSF typing_extensions 4.4.0 Python Software Foundation License zope.event 4.6 Zope Public License zope.interface 5.5.2 Zope Public License","title":"Python dependencies"},{"location":"framework/licenses/#native-dependencies","text":"Container images (both grizzly runtime and Microsoft Visual Code devcontainer) contains dependencies from IBM MQ Redistributable Components . The redistributable license terms may be found in the relevant IBM MQ Program license agreement, which may be found at the IBM Software License Agreements website, or in licenses/ directory in the archive .","title":"Native dependencies"},{"location":"framework/usage/load-users/","text":"This package contains implementation for different type of endpoints and protocols. These implementations are the basis for how to communicate with the system under test. Custom It is possible to implement custom users, the only requirement is that they inherit grizzly.users.base.GrizzlyUser . To get them to be executed by grizzly the full namespace has to be specified as user_class_name in the scenarios User step. There are examples of this in the Example .","title":"Load Users"},{"location":"framework/usage/load-users/#custom","text":"It is possible to implement custom users, the only requirement is that they inherit grizzly.users.base.GrizzlyUser . To get them to be executed by grizzly the full namespace has to be specified as user_class_name in the scenarios User step. There are examples of this in the Example .","title":"Custom"},{"location":"framework/usage/load-users/blobstorage/","text":"Put files to Azure Blob Storage. Request methods Supports the following request methods: send put Format Format of host is the following: [DefaultEndpointsProtocol=]https;EndpointSuffix=<hostname>;AccountName=<account name>;AccountKey=<account key> endpoint in the request is the name of the blob storage container. Name of the targeted file in the container is either name or based on the file name of source . Examples Example of how to use it in a scenario: Given a user of type \" BlobStorage \" load testing \" DefaultEndpointsProtocol=https;EndpointSuffix=core.windows.net;AccountName=examplestorage;AccountKey=xxxyyyyzzz== \" Then send request \" test/blob.file \" to endpoint \" azure-blobstorage-container-name \"","title":"Blobstorage"},{"location":"framework/usage/load-users/blobstorage/#request-methods","text":"Supports the following request methods: send put","title":"Request methods"},{"location":"framework/usage/load-users/blobstorage/#format","text":"Format of host is the following: [DefaultEndpointsProtocol=]https;EndpointSuffix=<hostname>;AccountName=<account name>;AccountKey=<account key> endpoint in the request is the name of the blob storage container. Name of the targeted file in the container is either name or based on the file name of source .","title":"Format"},{"location":"framework/usage/load-users/blobstorage/#examples","text":"Example of how to use it in a scenario: Given a user of type \" BlobStorage \" load testing \" DefaultEndpointsProtocol=https;EndpointSuffix=core.windows.net;AccountName=examplestorage;AccountKey=xxxyyyyzzz== \" Then send request \" test/blob.file \" to endpoint \" azure-blobstorage-container-name \"","title":"Examples"},{"location":"framework/usage/load-users/dummy/","text":"Does nothing. Can be used with any tasks except Request . Format Format of host can be anything. Examples Example of how to use it in a scenario: Given a user of type \" Dummy \" load testing \" /dev/null \"","title":"Dummy"},{"location":"framework/usage/load-users/dummy/#format","text":"Format of host can be anything.","title":"Format"},{"location":"framework/usage/load-users/dummy/#examples","text":"Example of how to use it in a scenario: Given a user of type \" Dummy \" load testing \" /dev/null \"","title":"Examples"},{"location":"framework/usage/load-users/iothub/","text":"Put files to Azure IoT hub. Request methods Supports the following request methods: send put Format Format of host is the following: HostName=<hostname>;DeviceId=<device key>;SharedAccessKey=<access key> endpoint in the request is the desired filename for the uploaded file. Examples Example of how to use it in a scenario: Given a user of type \" IotHub \" load testing \" HostName=my_iot_host_name;DeviceId=my_device;SharedAccessKey=xxxyyyyzzz== \" Then send request \" test/blob.file \" to endpoint \" uploaded_blob_filename \"","title":"IoTHub"},{"location":"framework/usage/load-users/iothub/#request-methods","text":"Supports the following request methods: send put","title":"Request methods"},{"location":"framework/usage/load-users/iothub/#format","text":"Format of host is the following: HostName=<hostname>;DeviceId=<device key>;SharedAccessKey=<access key> endpoint in the request is the desired filename for the uploaded file.","title":"Format"},{"location":"framework/usage/load-users/iothub/#examples","text":"Example of how to use it in a scenario: Given a user of type \" IotHub \" load testing \" HostName=my_iot_host_name;DeviceId=my_device;SharedAccessKey=xxxyyyyzzz== \" Then send request \" test/blob.file \" to endpoint \" uploaded_blob_filename \"","title":"Examples"},{"location":"framework/usage/load-users/messagequeue/","text":"Get and put messages on with IBM MQ queues. User is based on pymqi for communicating with IBM MQ. However pymqi uses native libraries which gevent (used by locust ) cannot patch, which causes any calls in pymqi to block the rest of locust . To get around this, the user implementation communicates with a stand-alone process via zmq, which in turn communicates with IBM MQ. async-messaged starts automagically when a scenario uses MessageQueueUser and pymqi dependencies are installed. Request methods Supports the following request methods: send put get receive Format Format of host is the following: mq://<hostname>:<port>/?QueueManager=<queue manager name>&Channel=<channel name> endpoint in the request is the name of an MQ queue. This can also be combined with an expression, if a specific message is to be retrieved from the queue. The format of endpoint is: queue:<queue_name>[, expression:<expression>][, max_message_size:<max_message_size>] Where <expression> can be a XPath or jsonpath expression, depending on the specified content type. See example below. Where <max_message_size> is the maximum number of bytes a message can be for being able to accept it. If not set, the client will reject the message with MQRC_TRUNCATED_MSG_FAILED , adjust the message buffer and try again. If set, and the message is bigger than the specified size, the message will be rejected by the client and will eventually fail. Examples Example of how to use it in a scenario: Given a user of type \" MessageQueue \" load testing \" mq://mq.example.com/?QueueManager=QM01&Channel=SRVCONN01 \" Then put request \" test/queue-message.j2.json \" with name \" queue-message \" to endpoint \" queue:INCOMING.MESSAGES \" Get message Default behavior is to fail directly if there is no message on the queue. If the request should wait until a message is available, set the time it should wait with message.wait (seconds) context variable. To keep the connection alive during longer waiting periods, a heartbeat interval can be configured using the connection.heartbeat_interval (seconds) context variable (default 300). Given a user of type \" MessageQueue \" load testing \" mq://mq.example.com/?QueueManager=QM01&Channel=SRVCONN01 \" And set context variable \" message.wait \" to \" 5 \" Then get request with name \" get-queue-message \" from endpoint \" queue:INCOMING.MESSAGES \" In this example, the request will not fail if there is a message on queue within 5 seconds. Get message with expression When specifying an expression, the messages on the queue are first browsed. If any message matches the expression, it is later consumed from the queue. If no matching message was found during browsing, it is repeated again after a slight delay, up until the specified message.wait seconds has elapsed. To use expressions, a content type must be specified for the get request, e.g. application/xml : Given a user of type \" MessageQueue \" load testing \" mq://mq.example.com/?QueueManager=QM01&Channel=SRVCONN01 \" And set context variable \" message.wait \" to \" 5 \" Then get request with name \" get-specific-queue-message \" from endpoint \" queue:INCOMING.MESSAGES, expression: //document[@id='abc123'] \" And set response content type to \" application/xml \" Authentication Username and password Given a user of type \" MessageQueue \" load testing \" mq://mqm:admin@mq.example.com/?QueueManager=QM01&Channel=SRVCONN01 \" And set context variable \" auth.username \" to \" <username> \" And set context variable \" auth.password \" to \" <password> \" With TLS A key repository (3 files; .kdb , .rdb and .sth ) for the user is needed, and is specified with auth.key_file excluding the file extension. Given a user of type \" MessageQueue \" load testing \" mq://mqm:admin@mq.example.com/?QueueManager=QM01&Channel=SRVCONN01 \" And set context variable \" auth.username \" to \" <username> \" And set context variable \" auth.password \" to \" <password> \" And set context variable \" auth.key_file \" to \" <path to key file, excl. file extension> \" Default SSL cipher is ECDHE_RSA_AES_256_GCM_SHA384 , change it by setting auth.ssl_cipher context variable. Default certificate label is set to auth.username , change it by setting auth.cert_label context variable. Header type Basic support exist for RFH2 , and communicating with MQ using gzip compressed messages. When receiving messages, the RFH2 is automatically detected and (somewhat) supported. If RFH2 should be added when sending messages, with gzip compression, the context variable message.header_type should be set to RFH2 : Given a user of type \" MessageQueue \" load testing \" mq://mq.example.com/?QueueManager=QM01&Channel=SRVCONN01 \" And set context variable \" message.header_type \" to \" rfh2 \" Then put request \" test/queue-message.j2.json \" with name \" gzipped-message \" to endpoint \" queue:GZIPPED.MESSAGES \" Default header type is none, i.e. no header is added to the sent messages. To use no header, either set message.header_type to None or omit setting the context variable at all. To set a user value in the RFH2 header of the message, set metadata after the request, e.g.: Then put request \" test/queue-message.j2.json \" with name \" gzipped-message \" to endpoint \" queue:GZIPPED.MESSAGES \" And metadata \" filename \" is \" my_filename \"","title":"Messagequeue"},{"location":"framework/usage/load-users/messagequeue/#request-methods","text":"Supports the following request methods: send put get receive","title":"Request methods"},{"location":"framework/usage/load-users/messagequeue/#format","text":"Format of host is the following: mq://<hostname>:<port>/?QueueManager=<queue manager name>&Channel=<channel name> endpoint in the request is the name of an MQ queue. This can also be combined with an expression, if a specific message is to be retrieved from the queue. The format of endpoint is: queue:<queue_name>[, expression:<expression>][, max_message_size:<max_message_size>] Where <expression> can be a XPath or jsonpath expression, depending on the specified content type. See example below. Where <max_message_size> is the maximum number of bytes a message can be for being able to accept it. If not set, the client will reject the message with MQRC_TRUNCATED_MSG_FAILED , adjust the message buffer and try again. If set, and the message is bigger than the specified size, the message will be rejected by the client and will eventually fail.","title":"Format"},{"location":"framework/usage/load-users/messagequeue/#examples","text":"Example of how to use it in a scenario: Given a user of type \" MessageQueue \" load testing \" mq://mq.example.com/?QueueManager=QM01&Channel=SRVCONN01 \" Then put request \" test/queue-message.j2.json \" with name \" queue-message \" to endpoint \" queue:INCOMING.MESSAGES \"","title":"Examples"},{"location":"framework/usage/load-users/messagequeue/#get-message","text":"Default behavior is to fail directly if there is no message on the queue. If the request should wait until a message is available, set the time it should wait with message.wait (seconds) context variable. To keep the connection alive during longer waiting periods, a heartbeat interval can be configured using the connection.heartbeat_interval (seconds) context variable (default 300). Given a user of type \" MessageQueue \" load testing \" mq://mq.example.com/?QueueManager=QM01&Channel=SRVCONN01 \" And set context variable \" message.wait \" to \" 5 \" Then get request with name \" get-queue-message \" from endpoint \" queue:INCOMING.MESSAGES \" In this example, the request will not fail if there is a message on queue within 5 seconds.","title":"Get message"},{"location":"framework/usage/load-users/messagequeue/#get-message-with-expression","text":"When specifying an expression, the messages on the queue are first browsed. If any message matches the expression, it is later consumed from the queue. If no matching message was found during browsing, it is repeated again after a slight delay, up until the specified message.wait seconds has elapsed. To use expressions, a content type must be specified for the get request, e.g. application/xml : Given a user of type \" MessageQueue \" load testing \" mq://mq.example.com/?QueueManager=QM01&Channel=SRVCONN01 \" And set context variable \" message.wait \" to \" 5 \" Then get request with name \" get-specific-queue-message \" from endpoint \" queue:INCOMING.MESSAGES, expression: //document[@id='abc123'] \" And set response content type to \" application/xml \"","title":"Get message with expression"},{"location":"framework/usage/load-users/messagequeue/#authentication","text":"","title":"Authentication"},{"location":"framework/usage/load-users/messagequeue/#username-and-password","text":"Given a user of type \" MessageQueue \" load testing \" mq://mqm:admin@mq.example.com/?QueueManager=QM01&Channel=SRVCONN01 \" And set context variable \" auth.username \" to \" <username> \" And set context variable \" auth.password \" to \" <password> \"","title":"Username and password"},{"location":"framework/usage/load-users/messagequeue/#with-tls","text":"A key repository (3 files; .kdb , .rdb and .sth ) for the user is needed, and is specified with auth.key_file excluding the file extension. Given a user of type \" MessageQueue \" load testing \" mq://mqm:admin@mq.example.com/?QueueManager=QM01&Channel=SRVCONN01 \" And set context variable \" auth.username \" to \" <username> \" And set context variable \" auth.password \" to \" <password> \" And set context variable \" auth.key_file \" to \" <path to key file, excl. file extension> \" Default SSL cipher is ECDHE_RSA_AES_256_GCM_SHA384 , change it by setting auth.ssl_cipher context variable. Default certificate label is set to auth.username , change it by setting auth.cert_label context variable.","title":"With TLS"},{"location":"framework/usage/load-users/messagequeue/#header-type","text":"Basic support exist for RFH2 , and communicating with MQ using gzip compressed messages. When receiving messages, the RFH2 is automatically detected and (somewhat) supported. If RFH2 should be added when sending messages, with gzip compression, the context variable message.header_type should be set to RFH2 : Given a user of type \" MessageQueue \" load testing \" mq://mq.example.com/?QueueManager=QM01&Channel=SRVCONN01 \" And set context variable \" message.header_type \" to \" rfh2 \" Then put request \" test/queue-message.j2.json \" with name \" gzipped-message \" to endpoint \" queue:GZIPPED.MESSAGES \" Default header type is none, i.e. no header is added to the sent messages. To use no header, either set message.header_type to None or omit setting the context variable at all. To set a user value in the RFH2 header of the message, set metadata after the request, e.g.: Then put request \" test/queue-message.j2.json \" with name \" gzipped-message \" to endpoint \" queue:GZIPPED.MESSAGES \" And metadata \" filename \" is \" my_filename \"","title":"Header type"},{"location":"framework/usage/load-users/restapi/","text":"Communicates with HTTP and HTTPS, with built-in support for Azure authenticated endpoints. Request methods Supports the following request methods: get put post Format Format of host is the following: http[s]://<hostname> Examples Example on how to use it in a scenario: Given a user of type \" RestApi \" load testing \" https://api.example.com \" Then post request \" test/request.j2.json \" to endpoint \" /api/test \" Then get request from endpoint \" /api/test \" To change how often the token should be refreshed, default is 3000 seconds: And set context variable \" auth.refresh_time \" to \" 3500 \" Authentication Client secret Given a user of type \" RestApi \" load testing \" https://api.example.com \" And set context variable \" auth.client.tenant \" \" <tenant name/guid> \" And set context variable \" auth.client.id \" to \" <client id> \" And set context variable \" auth.client.secret \" to \" <client secret> \" And set context variable \" auth.client.resource \" to \" <resource url/guid> \" Username and password auth.user.redirect_uri needs to correspond to the endpoint that the client secret is registrered for. Given a user of type \" RestApi \" load testing \" https://api.example.com \" And set context variable \" auth.client.id \" to \" <client id> \" And set context variable \" auth.user.username \" to \" alice@example.onmicrosoft.com \" And set context variable \" auth.user.password \" to \" HemL1gaArn3! \" And set context variable \" auth.user.redirect_uri \" to \" /app-registrered-redirect-uri \" Multipart/form-data RestApi supports posting of multipart/form-data content-type, and in that case additional arguments needs to be passed with the request: multipart_form_data_name str - the name of the input form multipart_form_data_filename str - the filename E.g: Then post request \" path/my_template.j2.xml \" with name \" FormPost \" to endpoint \" example.url.com | content_type=multipart/form-data, multipart_form_data_filename=my_filename, multipart_form_data_name=form_name \"","title":"RestAPI"},{"location":"framework/usage/load-users/restapi/#request-methods","text":"Supports the following request methods: get put post","title":"Request methods"},{"location":"framework/usage/load-users/restapi/#format","text":"Format of host is the following: http[s]://<hostname>","title":"Format"},{"location":"framework/usage/load-users/restapi/#examples","text":"Example on how to use it in a scenario: Given a user of type \" RestApi \" load testing \" https://api.example.com \" Then post request \" test/request.j2.json \" to endpoint \" /api/test \" Then get request from endpoint \" /api/test \" To change how often the token should be refreshed, default is 3000 seconds: And set context variable \" auth.refresh_time \" to \" 3500 \"","title":"Examples"},{"location":"framework/usage/load-users/restapi/#authentication","text":"","title":"Authentication"},{"location":"framework/usage/load-users/restapi/#client-secret","text":"Given a user of type \" RestApi \" load testing \" https://api.example.com \" And set context variable \" auth.client.tenant \" \" <tenant name/guid> \" And set context variable \" auth.client.id \" to \" <client id> \" And set context variable \" auth.client.secret \" to \" <client secret> \" And set context variable \" auth.client.resource \" to \" <resource url/guid> \"","title":"Client secret"},{"location":"framework/usage/load-users/restapi/#username-and-password","text":"auth.user.redirect_uri needs to correspond to the endpoint that the client secret is registrered for. Given a user of type \" RestApi \" load testing \" https://api.example.com \" And set context variable \" auth.client.id \" to \" <client id> \" And set context variable \" auth.user.username \" to \" alice@example.onmicrosoft.com \" And set context variable \" auth.user.password \" to \" HemL1gaArn3! \" And set context variable \" auth.user.redirect_uri \" to \" /app-registrered-redirect-uri \"","title":"Username and password"},{"location":"framework/usage/load-users/restapi/#multipartform-data","text":"RestApi supports posting of multipart/form-data content-type, and in that case additional arguments needs to be passed with the request: multipart_form_data_name str - the name of the input form multipart_form_data_filename str - the filename E.g: Then post request \" path/my_template.j2.xml \" with name \" FormPost \" to endpoint \" example.url.com | content_type=multipart/form-data, multipart_form_data_filename=my_filename, multipart_form_data_name=form_name \"","title":"Multipart/form-data"},{"location":"framework/usage/load-users/servicebus/","text":"Send and receive messages on Azure Service Bus queues and topics. Note If message.wait is not set, azure.servicebus will wait until there is a message available, and hence block the scenario. Attention Do not use expression to filter messages unless you do not care about the messages that does not match the expression. If you do care about them, you should setup a subscription to do the filtering in Azure. User is based on azure.servicebus for communicating with Azure Service Bus. But creating a connection and session towards a queue or a topic is a costly operation, and caching of the session was causing problems with gevent due to the sockets blocking and hence grizzly was blocking when finished. To get around this, the user implementation communicates with a stand-alone process via zmq , which in turn communicates with Azure Service Bus. async-messaged starts automagically when a scenario uses the ServiceBusUser . Request methods Supports the following request methods: send receive Format Format of host is the following: [Endpoint=]sb://<hostname>/;SharedAccessKeyName=<shared key name>;SharedAccessKey=<shared key> endpoint in the request must have the prefix queue: or topic: followed by the name of the targeted type. When receiving messages from a topic, the argument subscription: is mandatory. The format of endpoint is: [queue|topic]:<endpoint name>[, subscription:<subscription name>][, expression:<expression>] Where <expression> can be a XPath or jsonpath expression, depending on the specified content type. This argument is only allowed when receiving messages. See example below. Examples Example of how to use it in a scenario: Given a user of type \" ServiceBus \" load testing \" sb://sb.example.com/;SharedAccessKeyName=authorization-key;SharedAccessKey=c2VjcmV0LXN0dWZm \" And set context variable \" message.wait \" to \" 5 \" Then send request \" queue-send \" to endpoint \" queue:shared-queue \" Then send request \" topic-send \" to endpoint \" topic:shared-topic \" Then receive request \" queue-recv \" from endpoint \" queue:shared-queue \" Then receive request \" topic-recv \" from endpoint \" topic:shared-topic, subscription:my-subscription \" Get message with expression When specifying an expression, the messages on the endpoint is first peeked on. If any message matches the expression, it is later consumed from the endpoint. If no matching messages was found when peeking, it is repeated again after a slight delay, up until the specified message.wait seconds has elapsed. To use expressions, a content type must be specified for the request, e.g. application/xml . Given a user of type \" ServiceBus \" load testing \" sb://sb.example.com/;SharedAccessKeyName=authorization-key;SharedAccessKey=c2VjcmV0LXN0dWZm \" And set context variable \" message.wait \" to \" 5 \" Then receive request \" queue-recv \" from endpoint \" queue:shared-queue, expression:$.document[?(@.name=='TPM report')].id \" And set response content type to \" application/json \" Then receive request \" topic-recv \" from endpoint \" topic:shared-topic, subscription:my-subscription, expression:/documents/document[@name='TPM Report']/id/text() \" And set response content type to \" application/xml \"","title":"Servicebus"},{"location":"framework/usage/load-users/servicebus/#request-methods","text":"Supports the following request methods: send receive","title":"Request methods"},{"location":"framework/usage/load-users/servicebus/#format","text":"Format of host is the following: [Endpoint=]sb://<hostname>/;SharedAccessKeyName=<shared key name>;SharedAccessKey=<shared key> endpoint in the request must have the prefix queue: or topic: followed by the name of the targeted type. When receiving messages from a topic, the argument subscription: is mandatory. The format of endpoint is: [queue|topic]:<endpoint name>[, subscription:<subscription name>][, expression:<expression>] Where <expression> can be a XPath or jsonpath expression, depending on the specified content type. This argument is only allowed when receiving messages. See example below.","title":"Format"},{"location":"framework/usage/load-users/servicebus/#examples","text":"Example of how to use it in a scenario: Given a user of type \" ServiceBus \" load testing \" sb://sb.example.com/;SharedAccessKeyName=authorization-key;SharedAccessKey=c2VjcmV0LXN0dWZm \" And set context variable \" message.wait \" to \" 5 \" Then send request \" queue-send \" to endpoint \" queue:shared-queue \" Then send request \" topic-send \" to endpoint \" topic:shared-topic \" Then receive request \" queue-recv \" from endpoint \" queue:shared-queue \" Then receive request \" topic-recv \" from endpoint \" topic:shared-topic, subscription:my-subscription \"","title":"Examples"},{"location":"framework/usage/load-users/servicebus/#get-message-with-expression","text":"When specifying an expression, the messages on the endpoint is first peeked on. If any message matches the expression, it is later consumed from the endpoint. If no matching messages was found when peeking, it is repeated again after a slight delay, up until the specified message.wait seconds has elapsed. To use expressions, a content type must be specified for the request, e.g. application/xml . Given a user of type \" ServiceBus \" load testing \" sb://sb.example.com/;SharedAccessKeyName=authorization-key;SharedAccessKey=c2VjcmV0LXN0dWZm \" And set context variable \" message.wait \" to \" 5 \" Then receive request \" queue-recv \" from endpoint \" queue:shared-queue, expression:$.document[?(@.name=='TPM report')].id \" And set response content type to \" application/json \" Then receive request \" topic-recv \" from endpoint \" topic:shared-topic, subscription:my-subscription, expression:/documents/document[@name='TPM Report']/id/text() \" And set response content type to \" application/xml \"","title":"Get message with expression"},{"location":"framework/usage/load-users/sftp/","text":"Communicates with Secure File Transport Protocol. Attention Both local and remote files will be overwritten if they already exists. Downloaded files will be stored in requests/download . Request methods Supports the following request methods: put get Format Format of host is the following: sftp://<host>[:<port>] Examples Example of how to use it in a scenario: Given a user of type \" Sftp \" load testing \" sftp://sftp.example.com \" And set context variable \" auth.username \" to \" bob \" And set context variable \" auth.password \" to \" great-scott-42-file-bar \" Then put request \" test/blob.file \" to endpoint \" /pub/blobs \" Then get request from endpoint \" /pub/blobs/blob.file \"","title":"SFTP"},{"location":"framework/usage/load-users/sftp/#request-methods","text":"Supports the following request methods: put get","title":"Request methods"},{"location":"framework/usage/load-users/sftp/#format","text":"Format of host is the following: sftp://<host>[:<port>]","title":"Format"},{"location":"framework/usage/load-users/sftp/#examples","text":"Example of how to use it in a scenario: Given a user of type \" Sftp \" load testing \" sftp://sftp.example.com \" And set context variable \" auth.username \" to \" bob \" And set context variable \" auth.password \" to \" great-scott-42-file-bar \" Then put request \" test/blob.file \" to endpoint \" /pub/blobs \" Then get request from endpoint \" /pub/blobs/blob.file \"","title":"Examples"},{"location":"framework/usage/steps/","text":"This package contains all step implementations needed to write a feature file that describes a locust load test scenario for grizzly . A feature is described by using Gherkin . These expressions is then used by grizzly to configure and start locust , which takes care of generating the load. Feature: description of the test Background: steps that are common for all (if there is multiple) scenarios Given ... And ... Scenario: steps for a specific flow through a component in the target environment Given ... And ... Then ... When ... In this package there are modules with step implementations that can be used in both Background and Scenario sections in a feature file. Custom Custom steps are implemented in your grizzly project features/steps/steps.py file. This is also the file that imports all grizzly -defined step implementations. There are examples of this in the Example . Considerations When writing step expressions, the following should be taken into consideration. Class PermutationEnum class PermutationEnum ( Enum , metaclass = PermutationMeta ) [view_source] Interface class for getting __vector__ value from the class that inherits it. All objects used to represent possible values in step expressions and that has a registered custom parse type should inherit this class and set appropiate __vector__ values and make an implementation of from_string . This is so grizzly-ls can make educated suggestions on possible step expressions. __vector__ This class variable represents (x, y) dimensions on how the values can expand in a step expression. Consider the following Enum , being mapped to a custom parse type named FruitType : from behave import register_type class Fruit ( PermutationEnum ): __vector__ = None # see examples below BANANA = 0 APPLE = 1 ORANGE = 2 @classmethod def from_string ( cls , value : str ) -> Fruit : return cls [ value . upper ()] register_type ( FruitType = Fruit . from_string , ) None Variable occurs 1..N times in the expression When permutated, it will only produce one step expression and all instances of the variable in the expression will have been replaced with nothing. Then I want to eat a \" {fruit:FruitType} \" # --> Then I want to eat a \"\" Then I want to eat a \" {fruit1:FruitType} \" and a \" {fruit2:FruitType} \" # --> Then I want to eat a \"\" and a \"\" (False, True,) Variable occurs 1 time in the expression. When permutated, it will produce the number of step expressions as values in the enum. Then I want to eat a {fruit:FruitType} # --> Then I want to eat a banana Then I want to eat a apple Then I want to eat a orange (True, False,) Variable occurs 2..N times in the expression. When permutated, combination of all enum values will be produced, if the variable type occurs the same number of times as values in the enum. Then I want to eat a {fruit 1 :FruitType}, a {fruit 2 :FruitType} and a {fruit 3 :FruitType} # --> Then I want to eat a banana, a apple and a orange (True, True,) Variable occurs 2..N times in the expression, and should produce more than one combination of the step expression. Then I want to eat a {fruit 1 :FruitType}, a {fruit 2 :FruitType} and a {fruit 3 :FruitType} # --> Then I want to eat a banana, a apple and a orange Then I want to eat a apple, a banana and a orange Then I want to eat a orange, a banana and a apple Class permutation class permutation () [view_source] Decorator used to annotate parse methods that are not using Class PermutationEnum as a base. This could be for example parse methods that uses regular expressions via parse.with_pattern . import parse from behave import register_type from grizzly_extras.text import permutation @parse . with_pattern ( r '(hello|world)' ) @permutation ( vector = ( True , True ,)) def parse_hello_world ( text : str ) -> str : return text . strip () register_type ( HelloWorldType = parse_hello_world , ) See __vector__ for an explanation of possible values and their meaning.","title":"Steps"},{"location":"framework/usage/steps/#custom","text":"Custom steps are implemented in your grizzly project features/steps/steps.py file. This is also the file that imports all grizzly -defined step implementations. There are examples of this in the Example .","title":"Custom"},{"location":"framework/usage/steps/#considerations","text":"When writing step expressions, the following should be taken into consideration.","title":"Considerations"},{"location":"framework/usage/steps/#class-permutationenum","text":"class PermutationEnum ( Enum , metaclass = PermutationMeta ) [view_source] Interface class for getting __vector__ value from the class that inherits it. All objects used to represent possible values in step expressions and that has a registered custom parse type should inherit this class and set appropiate __vector__ values and make an implementation of from_string . This is so grizzly-ls can make educated suggestions on possible step expressions.","title":"Class PermutationEnum"},{"location":"framework/usage/steps/#__vector__","text":"This class variable represents (x, y) dimensions on how the values can expand in a step expression. Consider the following Enum , being mapped to a custom parse type named FruitType : from behave import register_type class Fruit ( PermutationEnum ): __vector__ = None # see examples below BANANA = 0 APPLE = 1 ORANGE = 2 @classmethod def from_string ( cls , value : str ) -> Fruit : return cls [ value . upper ()] register_type ( FruitType = Fruit . from_string , )","title":"__vector__"},{"location":"framework/usage/steps/#none","text":"Variable occurs 1..N times in the expression When permutated, it will only produce one step expression and all instances of the variable in the expression will have been replaced with nothing. Then I want to eat a \" {fruit:FruitType} \" # --> Then I want to eat a \"\" Then I want to eat a \" {fruit1:FruitType} \" and a \" {fruit2:FruitType} \" # --> Then I want to eat a \"\" and a \"\"","title":"None"},{"location":"framework/usage/steps/#false-true","text":"Variable occurs 1 time in the expression. When permutated, it will produce the number of step expressions as values in the enum. Then I want to eat a {fruit:FruitType} # --> Then I want to eat a banana Then I want to eat a apple Then I want to eat a orange","title":"(False, True,)"},{"location":"framework/usage/steps/#true-false","text":"Variable occurs 2..N times in the expression. When permutated, combination of all enum values will be produced, if the variable type occurs the same number of times as values in the enum. Then I want to eat a {fruit 1 :FruitType}, a {fruit 2 :FruitType} and a {fruit 3 :FruitType} # --> Then I want to eat a banana, a apple and a orange","title":"(True, False,)"},{"location":"framework/usage/steps/#true-true","text":"Variable occurs 2..N times in the expression, and should produce more than one combination of the step expression. Then I want to eat a {fruit 1 :FruitType}, a {fruit 2 :FruitType} and a {fruit 3 :FruitType} # --> Then I want to eat a banana, a apple and a orange Then I want to eat a apple, a banana and a orange Then I want to eat a orange, a banana and a apple","title":"(True, True,)"},{"location":"framework/usage/steps/#class-permutation","text":"class permutation () [view_source] Decorator used to annotate parse methods that are not using Class PermutationEnum as a base. This could be for example parse methods that uses regular expressions via parse.with_pattern . import parse from behave import register_type from grizzly_extras.text import permutation @parse . with_pattern ( r '(hello|world)' ) @permutation ( vector = ( True , True ,)) def parse_hello_world ( text : str ) -> str : return text . strip () register_type ( HelloWorldType = parse_hello_world , ) See __vector__ for an explanation of possible values and their meaning.","title":"Class permutation"},{"location":"framework/usage/steps/setup/","text":"step_setup_variable_value_ask @then ( u 'ask for value of variable \" {name} \"' ) @given ( u 'ask for value of variable \" {name} \"' ) def step_setup_variable_value_ask ( context : Context , name : str ) -> None [view_source] This step is used to indicate for grizzly-cli that it should ask for an initial value for the variable. It will then inject the value into the locust runtime environment, and in this step read it and insert it into the locust context which grizzly will use to setup locust. If grizzly-cli is not used, one has to manually set the environment variable, which requires a prefix of TESTDATA_VARIABLE_ and the suffix should match the variable name in question. Use this step for variables that should have different initial values for each run of the feature. And ask for value for variable \" AtomicIntegerIncrementer.messageID \" Arguments : name str - variable name used in templates step_setup_variable_value @given ( u 'value for variable \" {name} \" is \" {value} \"' ) def step_setup_variable_value ( context : Context , name : str , value : str ) -> None [view_source] Use this step to initialize a variable that should have the same [start] value for every run of the scenario. Data type for the value of the variable is based on the type of variable. If the variable is an testdata Variables then the value needs to match the format and type that the variable has implemented. If it is not a testdata variable grizzly will try to guess the data type. E.g.: \"10\" becomes int \"1.0\" becomes float \"True\" becomes bool everything else becomes str It is also possible to set the value of a variable based on another variable, which can be usable if you have a variable in multiple scenarios which all should have the same initial value. Example : example.feature Feature: Background: And ask for value of variable \" messageID \" And value for variable \" HelloWorld \" is \" default \" Scenario: And value for variable \" AtomicIntegerIncrementer.mid1 \" is \" {{ messageID }} \" And value for variable \" AtomicIntegerIncrementer.persistent \" is \" 1 | step=10, persist=True \" If the file features/persistent/example.json (name of feature file and feature extension replaced with json ) exists, and contains an entry for the variable, the initial value will be read from the file and override the value specified in the feature file. Arguments : name str - variable name value Any - initial value","title":"Setup"},{"location":"framework/usage/steps/setup/#step_setup_variable_value_ask","text":"@then ( u 'ask for value of variable \" {name} \"' ) @given ( u 'ask for value of variable \" {name} \"' ) def step_setup_variable_value_ask ( context : Context , name : str ) -> None [view_source] This step is used to indicate for grizzly-cli that it should ask for an initial value for the variable. It will then inject the value into the locust runtime environment, and in this step read it and insert it into the locust context which grizzly will use to setup locust. If grizzly-cli is not used, one has to manually set the environment variable, which requires a prefix of TESTDATA_VARIABLE_ and the suffix should match the variable name in question. Use this step for variables that should have different initial values for each run of the feature. And ask for value for variable \" AtomicIntegerIncrementer.messageID \" Arguments : name str - variable name used in templates","title":"step_setup_variable_value_ask"},{"location":"framework/usage/steps/setup/#step_setup_variable_value","text":"@given ( u 'value for variable \" {name} \" is \" {value} \"' ) def step_setup_variable_value ( context : Context , name : str , value : str ) -> None [view_source] Use this step to initialize a variable that should have the same [start] value for every run of the scenario. Data type for the value of the variable is based on the type of variable. If the variable is an testdata Variables then the value needs to match the format and type that the variable has implemented. If it is not a testdata variable grizzly will try to guess the data type. E.g.: \"10\" becomes int \"1.0\" becomes float \"True\" becomes bool everything else becomes str It is also possible to set the value of a variable based on another variable, which can be usable if you have a variable in multiple scenarios which all should have the same initial value. Example : example.feature Feature: Background: And ask for value of variable \" messageID \" And value for variable \" HelloWorld \" is \" default \" Scenario: And value for variable \" AtomicIntegerIncrementer.mid1 \" is \" {{ messageID }} \" And value for variable \" AtomicIntegerIncrementer.persistent \" is \" 1 | step=10, persist=True \" If the file features/persistent/example.json (name of feature file and feature extension replaced with json ) exists, and contains an entry for the variable, the initial value will be read from the file and override the value specified in the feature file. Arguments : name str - variable name value Any - initial value","title":"step_setup_variable_value"},{"location":"framework/usage/steps/utils/","text":"This package contains steps that can be useful during development or troubleshooting of a feature file, but should not be included in a finished, testable, feature. step_utils_fail @then ( u 'fail' ) def step_utils_fail ( context : Context ) -> None [view_source] Force a failed scenario. Can be useful when writing a new scenario. Then fail","title":"Utils"},{"location":"framework/usage/steps/utils/#step_utils_fail","text":"@then ( u 'fail' ) def step_utils_fail ( context : Context ) -> None [view_source] Force a failed scenario. Can be useful when writing a new scenario. Then fail","title":"step_utils_fail"},{"location":"framework/usage/steps/background/","text":"This package contains step implementations that only is allowed in the Background section in a Feature . The steps in Background is only executed once . The feature will fail if they are added into any other section. Feature: Example Background: # Here Scenario: # Not here! They are only allowed in the Background -section since they modify parts of the context that are used for all scenarios, which can translate to basic locust configuration.","title":"Background Steps"},{"location":"framework/usage/steps/background/setup/","text":"This module contains step implementations that configures the load test scenario with parameters applicable for all scenarios. step_setup_save_statistics @given ( u 'save statistics to \" {url} \"' ) def step_setup_save_statistics ( context : Context , url : str ) -> None [view_source] Sets an URL where locust statistics should be sent. It has support for InfluxDB and Azure Application Insights endpoints. For InfluxDB the following format must be used: For Azure Application Insights the following format must be used: influxdb://[<username>:<password>@]<hostname>[:<port>]/<database>?TargetEnviroment=<target environment>[&Testplan=<test plan>] [&TargetEnvironment=<target environment>][&ProfileName=<profile name>][&Description=<description>] insights://?InstrumentationKey=<instrumentation key>&IngestionEndpoint=<ingestion endpoint>[&Testplan=<test plan>] insights://<ingestion endpoint>/?InstrumentationKey=<instrumentation key>[&Testplan=<test plan>] And save statistics to \" influxdb://grizzly:secret-password@influx.example.com/grizzly-statistics \" And save statistics to \" insights://?IngestionEndpoint=https://insights.example.com&Testplan=grizzly-statistics&InstrumentationKey=asdfasdfasdf= \" And save statistics to \" insights://insights.example.com/?Testplan=grizzly-statistics&InstrumentationKey=asdfasdfasdf= \" And save statistics to \" influxdb://$conf::statistics.username$:$conf::statistics.password$@influx.example.com/$conf::statistics.database$ \" Arguments : url str - URL for statistics endpoint step_setup_log_level @given ( u 'log level is \" {log_level} \"' ) def step_setup_log_level ( context : Context , log_level : str ) -> None [view_source] Configure log level for grizzly . Default value is INFO , by changing to DEBUG there is more information what grizzly is doing behind the curtains. And log level is \" DEBUG \" Arguments : log_level str - allowed values INFO , DEBUG , WARNING och ERROR step_setup_run_time @given ( u 'run for maximum \" {timespan} \"' ) def step_setup_run_time ( context : Context , timespan : str ) -> None [view_source] Configures the time period a headless test should run for. If available test data is infinite, the test will run forever if this step is not used. And run for maximum \" 1h \" Arguments : timespan str - description of how long the test should run for, e.g. 10s, 1h, 40m etc. step_setup_set_global_context_variable @given ( u 'set global context variable \" {variable} \" to \" {value} \"' ) def step_setup_set_global_context_variable ( context : Context , variable : str , value : str ) -> None [view_source] Create a global variable in the context. Depending on which type of user a scenario is configured for, different variables are available. Check grizzly.users documentation for which context variables are available for each user. This step can be used if the feature file has multiple scenarios and all of them have the same context variables. Variable names can contain (one ore more) dot ( . ) or slash ( / ) to indicate that the variable is in a structure. All names will also be converted to lower case. E.g. token.url and token/URL results in: Space in variable names is also allowed and will then be translated to an underscore ( _ ) E.g. Client ID results in client_id . Data type of values will be guessed, if not explicitly specified by the type of variable used ( Atomic* ). E.g. the last two examples above will result in: { ' t oke n ' : { 'url' : '<value>' } } And set global context variable \" token.url \" to \" http://example.com/api/auth \" And set global context variable \" token/client_id \" to \" aaaa-bbbb-cccc-dddd \" And set global context variable \" token/client secret \" to \" aasdfasdfasdf== \" And set global context variable \" token.resource \" to \" 0000-aaaaaaa-1111-1111-1111 \" And set global context variable \" log_all_requests \" to \" True \" And set global context variable \" validate_certificates \" to \" False \" And set global context variable \" run_id \" to \" 13 \" { 'valida te _cer t i f ica tes ' : False , 'ru n _id' : 13 } Arguments : variable str - variable name, as used in templates value str - variable value","title":"Setup"},{"location":"framework/usage/steps/background/setup/#step_setup_save_statistics","text":"@given ( u 'save statistics to \" {url} \"' ) def step_setup_save_statistics ( context : Context , url : str ) -> None [view_source] Sets an URL where locust statistics should be sent. It has support for InfluxDB and Azure Application Insights endpoints. For InfluxDB the following format must be used: For Azure Application Insights the following format must be used: influxdb://[<username>:<password>@]<hostname>[:<port>]/<database>?TargetEnviroment=<target environment>[&Testplan=<test plan>] [&TargetEnvironment=<target environment>][&ProfileName=<profile name>][&Description=<description>] insights://?InstrumentationKey=<instrumentation key>&IngestionEndpoint=<ingestion endpoint>[&Testplan=<test plan>] insights://<ingestion endpoint>/?InstrumentationKey=<instrumentation key>[&Testplan=<test plan>] And save statistics to \" influxdb://grizzly:secret-password@influx.example.com/grizzly-statistics \" And save statistics to \" insights://?IngestionEndpoint=https://insights.example.com&Testplan=grizzly-statistics&InstrumentationKey=asdfasdfasdf= \" And save statistics to \" insights://insights.example.com/?Testplan=grizzly-statistics&InstrumentationKey=asdfasdfasdf= \" And save statistics to \" influxdb://$conf::statistics.username$:$conf::statistics.password$@influx.example.com/$conf::statistics.database$ \" Arguments : url str - URL for statistics endpoint","title":"step_setup_save_statistics"},{"location":"framework/usage/steps/background/setup/#step_setup_log_level","text":"@given ( u 'log level is \" {log_level} \"' ) def step_setup_log_level ( context : Context , log_level : str ) -> None [view_source] Configure log level for grizzly . Default value is INFO , by changing to DEBUG there is more information what grizzly is doing behind the curtains. And log level is \" DEBUG \" Arguments : log_level str - allowed values INFO , DEBUG , WARNING och ERROR","title":"step_setup_log_level"},{"location":"framework/usage/steps/background/setup/#step_setup_run_time","text":"@given ( u 'run for maximum \" {timespan} \"' ) def step_setup_run_time ( context : Context , timespan : str ) -> None [view_source] Configures the time period a headless test should run for. If available test data is infinite, the test will run forever if this step is not used. And run for maximum \" 1h \" Arguments : timespan str - description of how long the test should run for, e.g. 10s, 1h, 40m etc.","title":"step_setup_run_time"},{"location":"framework/usage/steps/background/setup/#step_setup_set_global_context_variable","text":"@given ( u 'set global context variable \" {variable} \" to \" {value} \"' ) def step_setup_set_global_context_variable ( context : Context , variable : str , value : str ) -> None [view_source] Create a global variable in the context. Depending on which type of user a scenario is configured for, different variables are available. Check grizzly.users documentation for which context variables are available for each user. This step can be used if the feature file has multiple scenarios and all of them have the same context variables. Variable names can contain (one ore more) dot ( . ) or slash ( / ) to indicate that the variable is in a structure. All names will also be converted to lower case. E.g. token.url and token/URL results in: Space in variable names is also allowed and will then be translated to an underscore ( _ ) E.g. Client ID results in client_id . Data type of values will be guessed, if not explicitly specified by the type of variable used ( Atomic* ). E.g. the last two examples above will result in: { ' t oke n ' : { 'url' : '<value>' } } And set global context variable \" token.url \" to \" http://example.com/api/auth \" And set global context variable \" token/client_id \" to \" aaaa-bbbb-cccc-dddd \" And set global context variable \" token/client secret \" to \" aasdfasdfasdf== \" And set global context variable \" token.resource \" to \" 0000-aaaaaaa-1111-1111-1111 \" And set global context variable \" log_all_requests \" to \" True \" And set global context variable \" validate_certificates \" to \" False \" And set global context variable \" run_id \" to \" 13 \" { 'valida te _cer t i f ica tes ' : False , 'ru n _id' : 13 } Arguments : variable str - variable name, as used in templates value str - variable value","title":"step_setup_set_global_context_variable"},{"location":"framework/usage/steps/background/shapes/","text":"This module contains step implementations that describes how the load for all scenarios in a feature will look like. step_shapes_user_count @given ( u '\" {value} \" {grammar:UserGramaticalNumber}' ) def step_shapes_user_count ( context : Context , value : str , ** kwargs : Dict [ str , Any ]) -> None [view_source] Set number of users that will generate load. Given \" 5 \" users Given \" 1 \" user Given \" {{ user_count }} \" Arguments : user_count int - Number of users locust should create step_shapes_spawn_rate @given ( u 'spawn rate is \" {value} \" {grammar:UserGramaticalNumber} per second' ) def step_shapes_spawn_rate ( context : Context , value : str , ** kwargs : Dict [ str , Any ]) -> None [view_source] Set rate in which locust shall swarm new user instances. And spawn rate is \" 5 \" users per second And spawn rate is \" 1 \" user per second And spawn rate is \" 0.1 \" users per second Arguments : spawn_rate float - number of users per second","title":"Shapes"},{"location":"framework/usage/steps/background/shapes/#step_shapes_user_count","text":"@given ( u '\" {value} \" {grammar:UserGramaticalNumber}' ) def step_shapes_user_count ( context : Context , value : str , ** kwargs : Dict [ str , Any ]) -> None [view_source] Set number of users that will generate load. Given \" 5 \" users Given \" 1 \" user Given \" {{ user_count }} \" Arguments : user_count int - Number of users locust should create","title":"step_shapes_user_count"},{"location":"framework/usage/steps/background/shapes/#step_shapes_spawn_rate","text":"@given ( u 'spawn rate is \" {value} \" {grammar:UserGramaticalNumber} per second' ) def step_shapes_spawn_rate ( context : Context , value : str , ** kwargs : Dict [ str , Any ]) -> None [view_source] Set rate in which locust shall swarm new user instances. And spawn rate is \" 5 \" users per second And spawn rate is \" 1 \" user per second And spawn rate is \" 0.1 \" users per second Arguments : spawn_rate float - number of users per second","title":"step_shapes_spawn_rate"},{"location":"framework/usage/steps/scenario/","text":"This package contains step implementations that only is allowed in the Scenario section in a feature file. Feature: Example Background: # Not here! Scenario: # Here The steps in the Scenario section modifies the context only for the scenario that they are defined in.","title":"Scenario Steps"},{"location":"framework/usage/steps/scenario/response/","text":"This module contains step implementations that handles Request responses. Arguments expression Valid for: step_response_save_matches , step_response_save , step_response_validate expected_matches int (optional): number of expected matches that expression should get, a value of -1 means Any number of matches (default: 1 ) as_json bool (optional): always return matches as a JSON list, by default if there's a single match it will be returned as a string (default: False ) step_response_save_matches @then ( u 'save response {target:ResponseTarget} \" {expression} \" that matches \" {match_with} \" in variable \" {variable} \"' ) def step_response_save_matches ( context : Context , target : ResponseTarget , expression : str , match_with : str , variable : str ) -> None [view_source] Save specified parts of a response, either from meta data (header) or payload (body), in a variable. With this step it is possible to change variable values and as such use values from a response later on in the load test. The Request task preceded by this step will fail if the specified expression has no or more than one match. Example : # only token is matched and saved in TOKEN, by using regexp match groups And value for variable \" TOKEN \" is \" none \" Then save response metadata \" $.Authentication \" that matches \" Bearer (.*)$ \" in variabel \" TOKEN \" # the whole value is saved, as long as Authentication starts with \"Bearer\" And value for variable \" HEADER_AUTHENTICATION \" is \" none \" Then save response metadata \" $.Authentication \" that matches \" ^Bearer .*$ \" in variable \" HEADER_AUTHENTICATION \" # only the numerical suffix is saved in the variable And value for variable \" AtomicIntegerIncrementer.measurermentId \" is \" 1 \" Then save response payload \" $.measurement.id \" that matches \" ^cpu([\\\\d]+)$ \" in \" measurementId \" # the whole value is saved, as long as the value starts with \"cpu\" And value for variable \" measurementId \" is \" 0 \" Then save response payload \" $.measurement.id \" that matches \" ^cpu[\\\\d]+$ \" in \" measurementId \" # xpath example And value for variable \" xmlMeasurementId \" is \" none \" Then save response payload \" //measurement[0]/id/text() | content_type=xml \" that matches \" ^cpu[\\\\d]+$ \" in \" xmlMeasurementId \" Arguments : target enum - \"metadata\" or \"payload\", depending on which part of the response should be used expression str - JSON path or XPath expression for finding the property match_with str - static value or a regular expression variable str - name of the already initialized variable to save the value in step_response_save @then ( u 'save response {target:ResponseTarget} \" {expression} \" in variable \" {variable} \"' ) def step_response_save ( context : Context , target : ResponseTarget , expression : str , variable : str ) -> None [view_source] Save metadata (header) or payload (body) value from a response in a variable. This step expression is the same as step_response_save_matches if match_with is set to .* . With this step it is possible to change variable values and as such use values from a response later on in the load test. The Request task preceded by this step will fail if the specified expression has no or more than one match. Example : Then save response metadata \" $.Authentication \" in variable \" HEADER_AUTHENTICATION \" Then save response payload \" $.Result.ShipmentId \" in variable \" ShipmentId \" Then save response payload \" //measurement[0]/id/text() \" in \" xmlMeasurementId \" Arguments : target enum - \"metadata\" or \"payload\", depending on which part of the response should be used expression str - JSON path or XPath expression for finding the property variable str - name of the already initialized variable to save the value in step_response_validate @when ( u 'response {target:ResponseTarget} \" {expression} \" {condition:Condition} \" {match_with} \" fail request' ) def step_response_validate ( context : Context , target : ResponseTarget , expression : str , condition : bool , match_with : str ) -> None [view_source] Fails the request based on the value of a response meta data (header) or payload (body). Example : And restart scenario on failure When response metadata \" $.['content-type'] \" is not \" .*application/json.* \" fail request When response metadata \" $.['x-test-command'] \" is \" abort \" fail request When response metadata \" $.Authentication \" is not \" Bearer .*$ \" fail request And stop user on failure When response payload \" $.measurement.id \" is not \" cpu[0-9]+ \" fail request When response payload \" $.success \" is \" false \" fail request When response payload \" /root/measurement[@id= \"cpu\" ]/success/text() \" is \" 'false' \" fail request Arguments : target enum - \"metadata\" or \"payload\", depending on which part of the response should be used expression str - JSON path or XPath expression for finding the property condition enum - \"is\" or \"is not\" depending on negative or postive matching match_with str - static value or a regular expression step_response_allow_status_codes @then ( u 'allow response status codes \" {status_list} \"' ) def step_response_allow_status_codes ( context : Context , status_list : str ) -> None [view_source] Set allowed response status codes for the latest defined request in the scenario. By default 200 is the only allowed respoonse status code. By prefixing a code with minus ( - ), it will be removed from the list of allowed response status codes. Example : Then get request with name \" test-get-1 \" from endpoint \" /api/test \" And allow response status \" 200,302 \" Then get request with name \" test-failed-get-2 \" from endpoint \" /api/non-existing \" And allow response status \" -200,404 \" Arguments : status_list str - comma separated list of integers step_response_allow_status_codes_table @then ( u 'allow response status codes' ) def step_response_allow_status_codes_table ( context : Context ) -> None [view_source] Set allowed response status codes for the latest defined requests based on a data table. Specifies a comma separeated list of allowed return codes for the latest requests in a data table. By default 200 is the only allowed respoonse status code. By prefixing a code with minus ( - ), it will be removed from the list of allowed response status codes. Number of rows in the table specifies which of the latest defined requests the allowed response status codes should map to. The table must have the column header status . Example : Then get request with name \" test-get-1 \" from endpoint \" /api/test \" Then get request with name \" test-get-2 \" from endpoint \" /api/test \" And allow response status | status | | 200, 302 | | 200,404 | Allowed response status codes for test-get-1 is now 200 and 302 , and for test-get-2 is now 200 and 404 . step_response_content_type @then ( u 'set response content type to \"{content_type:ContentType}\"' ) def step_response_content_type ( context : Context , content_type : TransformerContentType ) -> None [view_source] Set the content type of a response, instead of guessing it. This is applicable when there is a step_response_validate or step_response_save is included in the scenario, and is valid only for the latest defined request. Example : And set response content type to \" json \" And set response content type to \" application/json \" And set response content type to \" xml \" And set response content type to \" application/xml \" And set response content type to \" plain \" And set response content type to \" text/plain \" Arguments : content_type TransformerContentType - expected content type of response","title":"Response"},{"location":"framework/usage/steps/scenario/response/#arguments","text":"","title":"Arguments"},{"location":"framework/usage/steps/scenario/response/#expression","text":"Valid for: step_response_save_matches , step_response_save , step_response_validate expected_matches int (optional): number of expected matches that expression should get, a value of -1 means Any number of matches (default: 1 ) as_json bool (optional): always return matches as a JSON list, by default if there's a single match it will be returned as a string (default: False )","title":"expression"},{"location":"framework/usage/steps/scenario/response/#step_response_save_matches","text":"@then ( u 'save response {target:ResponseTarget} \" {expression} \" that matches \" {match_with} \" in variable \" {variable} \"' ) def step_response_save_matches ( context : Context , target : ResponseTarget , expression : str , match_with : str , variable : str ) -> None [view_source] Save specified parts of a response, either from meta data (header) or payload (body), in a variable. With this step it is possible to change variable values and as such use values from a response later on in the load test. The Request task preceded by this step will fail if the specified expression has no or more than one match. Example : # only token is matched and saved in TOKEN, by using regexp match groups And value for variable \" TOKEN \" is \" none \" Then save response metadata \" $.Authentication \" that matches \" Bearer (.*)$ \" in variabel \" TOKEN \" # the whole value is saved, as long as Authentication starts with \"Bearer\" And value for variable \" HEADER_AUTHENTICATION \" is \" none \" Then save response metadata \" $.Authentication \" that matches \" ^Bearer .*$ \" in variable \" HEADER_AUTHENTICATION \" # only the numerical suffix is saved in the variable And value for variable \" AtomicIntegerIncrementer.measurermentId \" is \" 1 \" Then save response payload \" $.measurement.id \" that matches \" ^cpu([\\\\d]+)$ \" in \" measurementId \" # the whole value is saved, as long as the value starts with \"cpu\" And value for variable \" measurementId \" is \" 0 \" Then save response payload \" $.measurement.id \" that matches \" ^cpu[\\\\d]+$ \" in \" measurementId \" # xpath example And value for variable \" xmlMeasurementId \" is \" none \" Then save response payload \" //measurement[0]/id/text() | content_type=xml \" that matches \" ^cpu[\\\\d]+$ \" in \" xmlMeasurementId \" Arguments : target enum - \"metadata\" or \"payload\", depending on which part of the response should be used expression str - JSON path or XPath expression for finding the property match_with str - static value or a regular expression variable str - name of the already initialized variable to save the value in","title":"step_response_save_matches"},{"location":"framework/usage/steps/scenario/response/#step_response_save","text":"@then ( u 'save response {target:ResponseTarget} \" {expression} \" in variable \" {variable} \"' ) def step_response_save ( context : Context , target : ResponseTarget , expression : str , variable : str ) -> None [view_source] Save metadata (header) or payload (body) value from a response in a variable. This step expression is the same as step_response_save_matches if match_with is set to .* . With this step it is possible to change variable values and as such use values from a response later on in the load test. The Request task preceded by this step will fail if the specified expression has no or more than one match. Example : Then save response metadata \" $.Authentication \" in variable \" HEADER_AUTHENTICATION \" Then save response payload \" $.Result.ShipmentId \" in variable \" ShipmentId \" Then save response payload \" //measurement[0]/id/text() \" in \" xmlMeasurementId \" Arguments : target enum - \"metadata\" or \"payload\", depending on which part of the response should be used expression str - JSON path or XPath expression for finding the property variable str - name of the already initialized variable to save the value in","title":"step_response_save"},{"location":"framework/usage/steps/scenario/response/#step_response_validate","text":"@when ( u 'response {target:ResponseTarget} \" {expression} \" {condition:Condition} \" {match_with} \" fail request' ) def step_response_validate ( context : Context , target : ResponseTarget , expression : str , condition : bool , match_with : str ) -> None [view_source] Fails the request based on the value of a response meta data (header) or payload (body). Example : And restart scenario on failure When response metadata \" $.['content-type'] \" is not \" .*application/json.* \" fail request When response metadata \" $.['x-test-command'] \" is \" abort \" fail request When response metadata \" $.Authentication \" is not \" Bearer .*$ \" fail request And stop user on failure When response payload \" $.measurement.id \" is not \" cpu[0-9]+ \" fail request When response payload \" $.success \" is \" false \" fail request When response payload \" /root/measurement[@id= \"cpu\" ]/success/text() \" is \" 'false' \" fail request Arguments : target enum - \"metadata\" or \"payload\", depending on which part of the response should be used expression str - JSON path or XPath expression for finding the property condition enum - \"is\" or \"is not\" depending on negative or postive matching match_with str - static value or a regular expression","title":"step_response_validate"},{"location":"framework/usage/steps/scenario/response/#step_response_allow_status_codes","text":"@then ( u 'allow response status codes \" {status_list} \"' ) def step_response_allow_status_codes ( context : Context , status_list : str ) -> None [view_source] Set allowed response status codes for the latest defined request in the scenario. By default 200 is the only allowed respoonse status code. By prefixing a code with minus ( - ), it will be removed from the list of allowed response status codes. Example : Then get request with name \" test-get-1 \" from endpoint \" /api/test \" And allow response status \" 200,302 \" Then get request with name \" test-failed-get-2 \" from endpoint \" /api/non-existing \" And allow response status \" -200,404 \" Arguments : status_list str - comma separated list of integers","title":"step_response_allow_status_codes"},{"location":"framework/usage/steps/scenario/response/#step_response_allow_status_codes_table","text":"@then ( u 'allow response status codes' ) def step_response_allow_status_codes_table ( context : Context ) -> None [view_source] Set allowed response status codes for the latest defined requests based on a data table. Specifies a comma separeated list of allowed return codes for the latest requests in a data table. By default 200 is the only allowed respoonse status code. By prefixing a code with minus ( - ), it will be removed from the list of allowed response status codes. Number of rows in the table specifies which of the latest defined requests the allowed response status codes should map to. The table must have the column header status . Example : Then get request with name \" test-get-1 \" from endpoint \" /api/test \" Then get request with name \" test-get-2 \" from endpoint \" /api/test \" And allow response status | status | | 200, 302 | | 200,404 | Allowed response status codes for test-get-1 is now 200 and 302 , and for test-get-2 is now 200 and 404 .","title":"step_response_allow_status_codes_table"},{"location":"framework/usage/steps/scenario/response/#step_response_content_type","text":"@then ( u 'set response content type to \"{content_type:ContentType}\"' ) def step_response_content_type ( context : Context , content_type : TransformerContentType ) -> None [view_source] Set the content type of a response, instead of guessing it. This is applicable when there is a step_response_validate or step_response_save is included in the scenario, and is valid only for the latest defined request. Example : And set response content type to \" json \" And set response content type to \" application/json \" And set response content type to \" xml \" And set response content type to \" application/xml \" And set response content type to \" plain \" And set response content type to \" text/plain \" Arguments : content_type TransformerContentType - expected content type of response","title":"step_response_content_type"},{"location":"framework/usage/steps/scenario/results/","text":"This module contains step implementations that validates the total response results for all Tasks in a scenario, based on locust statistics like response time and failures. step_results_fail_ratio @when ( u 'fail ratio is greater than \" {fail_ratio:d} \" % f ail scenario' ) def step_results_fail_ratio ( context : Context , fail_ratio : int ) -> None [view_source] Sets how many percentages of requests that are allowed to fail before the whole scenario will be set as failed. This step cannot be used in combination with: step_setup_stop_user_on_failure step_setup_restart_scenario_on_failure Default behavior is not to validate the result for a scenario based on failed requests. Example : When fail ratio is greater than \" 8 \"% fail scenario Arguments : fail_ratio int - percentage of requests that are allowed to fail step_results_avg_response_time @when ( u 'average response time is greater than \" {avg_response_time:d} \" milliseconds fail scenario' ) def step_results_avg_response_time ( context : Context , avg_response_time : int ) -> None [view_source] Sets the average response time (milliseconds) that all requests in a scenario must be below for it to pass. Default behavior is not to validate the result for a scenario based on average response time. Example : When average response time is greater than \" 200 \" milliseconds fail scenario Arguments : avg_response_time int - allowed average response time in milliseconds step_results_response_time_percentile @when ( u 'response time percentile \" {percentile:d} \" % i s greater than \" {response_time:d} \" milliseconds fail scenario' ) def step_results_response_time_percentile ( context : Context , percentile : float , response_time : int ) -> None [view_source] Sets the response time that a specified percentile of the requests needs to be below for the scenario to pass. Default behavior is not to validate the result for a scenario based on percetile response times. Example : When response time percentile \" 95 \"% is greater than \" 200 \" milliseconds fail scenario Arguments : percentile int - percentile to validate (1-100) response_time int - response time in milliseconds","title":"Results"},{"location":"framework/usage/steps/scenario/results/#step_results_fail_ratio","text":"@when ( u 'fail ratio is greater than \" {fail_ratio:d} \" % f ail scenario' ) def step_results_fail_ratio ( context : Context , fail_ratio : int ) -> None [view_source] Sets how many percentages of requests that are allowed to fail before the whole scenario will be set as failed. This step cannot be used in combination with: step_setup_stop_user_on_failure step_setup_restart_scenario_on_failure Default behavior is not to validate the result for a scenario based on failed requests. Example : When fail ratio is greater than \" 8 \"% fail scenario Arguments : fail_ratio int - percentage of requests that are allowed to fail","title":"step_results_fail_ratio"},{"location":"framework/usage/steps/scenario/results/#step_results_avg_response_time","text":"@when ( u 'average response time is greater than \" {avg_response_time:d} \" milliseconds fail scenario' ) def step_results_avg_response_time ( context : Context , avg_response_time : int ) -> None [view_source] Sets the average response time (milliseconds) that all requests in a scenario must be below for it to pass. Default behavior is not to validate the result for a scenario based on average response time. Example : When average response time is greater than \" 200 \" milliseconds fail scenario Arguments : avg_response_time int - allowed average response time in milliseconds","title":"step_results_avg_response_time"},{"location":"framework/usage/steps/scenario/results/#step_results_response_time_percentile","text":"@when ( u 'response time percentile \" {percentile:d} \" % i s greater than \" {response_time:d} \" milliseconds fail scenario' ) def step_results_response_time_percentile ( context : Context , percentile : float , response_time : int ) -> None [view_source] Sets the response time that a specified percentile of the requests needs to be below for the scenario to pass. Default behavior is not to validate the result for a scenario based on percetile response times. Example : When response time percentile \" 95 \"% is greater than \" 200 \" milliseconds fail scenario Arguments : percentile int - percentile to validate (1-100) response_time int - response time in milliseconds","title":"step_results_response_time_percentile"},{"location":"framework/usage/steps/scenario/setup/","text":"This module contains step implementations that setup the load test scenario with parameters that is going to be used in the scenario they are defined in. step_setup_set_context_variable @given ( u 'set context variable \" {variable} \" to \" {value} \"' ) def step_setup_set_context_variable ( context : Context , variable : str , value : str ) -> None [view_source] Sets a variable in the scenario context. Variable names can contain (one or more) dot ( . ) or slash ( / ) to indicate that the variable has a nested structure. E.g. token.url and token/url results in {'token': {'url': '<value'>}} It is also possible to have spaces in a variable names, they will then be replaced with underscore ( _ ), and the name will be converted to lowercase. E.g. Client ID results in client_id . Example : And set context variable \" token.url \" to \" https://example.com/api/auth \" And set context variable \" token/client_id \" to \" aaaa-bbbb-cccc-dddd \" And set context variable \" token/client secret \" to \" aasdfasdfasdf== \" And set context variable \" token.resource \" to \" 0000-aaaaaaa-1111-1111-1111 \" And set context variable \" log_all_requests \" to \" True \" And set context variable \" validate_certificates \" to \" False \" Arguments : variable str - name, can contain . and / value str - value, data type will be guessed and casted step_setup_iterations @given ( u 'repeat for \" {value} \" {iteration_number:IterationGramaticalNumber}' ) def step_setup_iterations ( context : Context , value : str , iteration_number : str ) -> None [view_source] Sets how many iterations of the Tasks in the scenario should execute. Default value is 1 . A value of 0 means to run until all test data is consumed, or that the (optional) specified runtime for the scenario is reached. Example : And repeat for \" 10 \" iterations And repeat for \" 1 \" iteration And value for variable \" leveranser \" is \" 100 \" And repeat for \" {{ leveranser * 0.25 }} \" iterations Arguments : value str - number of iterations of the scenario, can be a templatning string or a environment configuration variable step_setup_set_variable_alias @given ( u 'set alias \" {alias} \" for variable \" {variable} \"' ) def step_setup_set_variable_alias ( context : Context , alias : str , variable : str ) -> None [view_source] Creates an alias for a variable that points to another structure in the context. This is useful if you have test data that somehow should change the behavior for a user, e.g. username and password. Example : And value for variable \" AtomicCsvRow.users \" is \" users.csv | repeat=True \" And set alias \" auth.user.username \" for variable \" AtomicCsvRow.users.username \" And set alias \" auth.user.password \" for variable \" AtomicCsvRow.users.password \" Variables in payload templates are not allowed to have an alias. Arguments : alias str - which node in the context that should get the value of variable variable str - an already initialized variable that should be renamed step_setup_log_all_requests @given ( u 'log all requests' ) def step_setup_log_all_requests ( context : Context ) -> None [view_source] Sets if all requests should be logged to a file. By default only failed requests (and responses) will be logged. Example : And log all requests step_setup_stop_user_on_failure @given ( u 'stop user on failure' ) def step_setup_stop_user_on_failure ( context : Context ) -> None [view_source] Stop user if a request fails. Default behavior is to continue the scenario if a request fails. Example : And stop user on failure step_setup_restart_scenario_on_failure @given ( u 'restart scenario on failure' ) def step_setup_restart_scenario_on_failure ( context : Context ) -> None [view_source] Restart scenario, from first task, if a request fails. Default behavior is to continue the scenario if a request fails. Example : And restart scenario on failure step_setup_metadata @then ( u 'metadata \" {key} \" is \" {value} \"' ) @given ( u 'metadata \" {key} \" is \" {value} \"' ) def step_setup_metadata ( context : Context , key : str , value : str ) -> None [view_source] Set a metadata (header) value to be used by the user when sending requests. Example : And metadata \" Content-Type \" is \" application/xml \" And metadata \" Ocp-Apim-Subscription-Key \" is \" 9asdf00asdf00adsf034 \" Or, for use in one request only, specify metadata after the request: Then post request ... And metadata \" x-header \" is \" {{ value }} \"","title":"Setup"},{"location":"framework/usage/steps/scenario/setup/#step_setup_set_context_variable","text":"@given ( u 'set context variable \" {variable} \" to \" {value} \"' ) def step_setup_set_context_variable ( context : Context , variable : str , value : str ) -> None [view_source] Sets a variable in the scenario context. Variable names can contain (one or more) dot ( . ) or slash ( / ) to indicate that the variable has a nested structure. E.g. token.url and token/url results in {'token': {'url': '<value'>}} It is also possible to have spaces in a variable names, they will then be replaced with underscore ( _ ), and the name will be converted to lowercase. E.g. Client ID results in client_id . Example : And set context variable \" token.url \" to \" https://example.com/api/auth \" And set context variable \" token/client_id \" to \" aaaa-bbbb-cccc-dddd \" And set context variable \" token/client secret \" to \" aasdfasdfasdf== \" And set context variable \" token.resource \" to \" 0000-aaaaaaa-1111-1111-1111 \" And set context variable \" log_all_requests \" to \" True \" And set context variable \" validate_certificates \" to \" False \" Arguments : variable str - name, can contain . and / value str - value, data type will be guessed and casted","title":"step_setup_set_context_variable"},{"location":"framework/usage/steps/scenario/setup/#step_setup_iterations","text":"@given ( u 'repeat for \" {value} \" {iteration_number:IterationGramaticalNumber}' ) def step_setup_iterations ( context : Context , value : str , iteration_number : str ) -> None [view_source] Sets how many iterations of the Tasks in the scenario should execute. Default value is 1 . A value of 0 means to run until all test data is consumed, or that the (optional) specified runtime for the scenario is reached. Example : And repeat for \" 10 \" iterations And repeat for \" 1 \" iteration And value for variable \" leveranser \" is \" 100 \" And repeat for \" {{ leveranser * 0.25 }} \" iterations Arguments : value str - number of iterations of the scenario, can be a templatning string or a environment configuration variable","title":"step_setup_iterations"},{"location":"framework/usage/steps/scenario/setup/#step_setup_set_variable_alias","text":"@given ( u 'set alias \" {alias} \" for variable \" {variable} \"' ) def step_setup_set_variable_alias ( context : Context , alias : str , variable : str ) -> None [view_source] Creates an alias for a variable that points to another structure in the context. This is useful if you have test data that somehow should change the behavior for a user, e.g. username and password. Example : And value for variable \" AtomicCsvRow.users \" is \" users.csv | repeat=True \" And set alias \" auth.user.username \" for variable \" AtomicCsvRow.users.username \" And set alias \" auth.user.password \" for variable \" AtomicCsvRow.users.password \" Variables in payload templates are not allowed to have an alias. Arguments : alias str - which node in the context that should get the value of variable variable str - an already initialized variable that should be renamed","title":"step_setup_set_variable_alias"},{"location":"framework/usage/steps/scenario/setup/#step_setup_log_all_requests","text":"@given ( u 'log all requests' ) def step_setup_log_all_requests ( context : Context ) -> None [view_source] Sets if all requests should be logged to a file. By default only failed requests (and responses) will be logged. Example : And log all requests","title":"step_setup_log_all_requests"},{"location":"framework/usage/steps/scenario/setup/#step_setup_stop_user_on_failure","text":"@given ( u 'stop user on failure' ) def step_setup_stop_user_on_failure ( context : Context ) -> None [view_source] Stop user if a request fails. Default behavior is to continue the scenario if a request fails. Example : And stop user on failure","title":"step_setup_stop_user_on_failure"},{"location":"framework/usage/steps/scenario/setup/#step_setup_restart_scenario_on_failure","text":"@given ( u 'restart scenario on failure' ) def step_setup_restart_scenario_on_failure ( context : Context ) -> None [view_source] Restart scenario, from first task, if a request fails. Default behavior is to continue the scenario if a request fails. Example : And restart scenario on failure","title":"step_setup_restart_scenario_on_failure"},{"location":"framework/usage/steps/scenario/setup/#step_setup_metadata","text":"@then ( u 'metadata \" {key} \" is \" {value} \"' ) @given ( u 'metadata \" {key} \" is \" {value} \"' ) def step_setup_metadata ( context : Context , key : str , value : str ) -> None [view_source] Set a metadata (header) value to be used by the user when sending requests. Example : And metadata \" Content-Type \" is \" application/xml \" And metadata \" Ocp-Apim-Subscription-Key \" is \" 9asdf00asdf00adsf034 \" Or, for use in one request only, specify metadata after the request: Then post request ... And metadata \" x-header \" is \" {{ value }} \"","title":"step_setup_metadata"},{"location":"framework/usage/steps/scenario/tasks/","text":"This module contains step implementations that creates requests executed by the specified Load User in the scenario. step_task_request_with_name_endpoint_until @then ( u '{method:Method} request with name \" {name} \" from endpoint \" {endpoint} \" until \" {condition} \"' ) def step_task_request_with_name_endpoint_until ( context : Context , method : RequestMethod , name : str , endpoint : str , condition : str ) -> None [view_source] Creates an instance of the Until task, see task documentation for more information. Example : Then get request with name \" test-get \" from endpoint \" /api/test | content_type=json \" until \" $.`this`[?success==true] \" Then receive request with name \" test-receive \" from endpoint \" queue:receive-queue | content_type=xml \" until \" /header/success[. == 'True'] \" Arguments : method RequestMethod - type of request name str - name of the requests in logs, can contain variables direction RequestDirection - one of to or from depending on the value of method endpoint str - URI relative to host in the scenario, can contain variables and in certain cases user_class_name specific parameters condition str - JSON or XPath expression for specific value in response payload step_task_request_text_with_name_endpoint @then ( u '{method:Method} request with name \" {name} \" {direction:Direction} endpoint \" {endpoint} \"' ) def step_task_request_text_with_name_endpoint ( context : Context , method : RequestMethod , name : str , direction : RequestDirection , endpoint : str ) -> None [view_source] Creates an instance of the Request task, where optional payload is defined directly in the feature file. See Request task documentation for more information about arguments. If method in the expression is get or receive ; the direction must be from . If method in the expression is post , pust , or send ; the direction must be to , and payload defined in the feature file. Example : Then post request with name \" test-post \" to endpoint \" /api/test \" \\\" \\ \"\\\" { \"test\" : \"hello world\" } \\ \"\\\" \\ \" Then put request with name \" test-put \" to endpoint \" /api/test \" \\\" \\ \"\\\" { \"test\" : \"hello world\" } \\ \"\\\" \\ \" Then get request with name \" test-get \" from endpoint \" /api/test \" Then send request with name \" test-send \" to endpoint \" queue:receive-queue \" \\\" \\ \"\\\" { \"value\" : \"do something\" } \\ \"\\\" \\ \" Then receive request with name \" test-receive \" from endpoint \" queue:receive-queue \" Arguments : method RequestMethod - type of request name str - name of the requests in logs, can contain variables direction RequestDirection - one of to or from depending on the value of method endpoint str - URI relative to host in the scenario, can contain variables and in certain cases user_class_name specific parameters step_task_request_file_with_name_endpoint @then ( u '{method:Method} request \" {source} \" with name \" {name} \" to endpoint \" {endpoint} \"' ) def step_task_request_file_with_name_endpoint ( context : Context , method : RequestMethod , source : str , name : str , endpoint : str ) -> None [view_source] Creates an instance of the Request task, where the payload is defined in a template file. See Request task documentation for more information about arguments. Example : Then send request \" test/request.j2.json \" with name \" test-send \" to endpoint \" queue:receive-queue \" Then post request \" test/request.j2.json \" with name \" test-post \" to endpoint \" /api/test \" Then put request \" test/request.j2.json \" with name \" test-put \" to endpoint \" /api/test \" Arguments : method RequestMethod - type of request source str - path to a template file relative to the directory requests/ , which must exist in the directory the feature file is located name str - name of the requests in logs, can contain variables endpoint str - URI relative to host in the scenario, can contain variables and in certain cases user_class_name specific parameters step_task_request_file_with_name @then ( u '{method:Method} request \" {source} \" with name \" {name} \"' ) def step_task_request_file_with_name ( context : Context , method : RequestMethod , source : str , name : str ) -> None [view_source] Creates an instance of the Request task, with the same endpoint as the previous Request task, where the payload is defined in a template file. See Request task documentation for more information about arguments. Example : Then post request \" test/request1.j2.json \" with name \" test-post1 \" to endpoint \" /api/test \" Then post request \" test/request2.j2.json \" with name \" test-post2 \" # same as Then post request \" test/request1.j2.json \" with name \" test-post1 \" to endpoint \" /api/test \" Then post request \" test/request2.j2.json \" with name \" test-post2 \" to endpoint \" /api/test \" Arguments : method RequestMethod - type of request source str - path to a template file relative to the directory requests/ , which must exist in the directory the feature file is located name str - name of the requests in logs, can contain variables step_task_request_text_with_name @then ( u '{method:Method} request with name \" {name} \"' ) def step_task_request_text_with_name ( context : Context , method : RequestMethod , name : str ) -> None [view_source] Creates an instance of the Request task, where optional payload is defined directly in the feature file. See Request task documentation for more information about arguments. If method in the expression is post , put or send the payload in the request must be defined directly in the feature file after the step. This step is useful if method and endpoint are the same as previous request, but the payload should be different. Example : # example-1 Then post request with name \" test-post-1 \" to endpoint \" /api/test \" \\\" \\ \"\\\" { \"value\" : \"hello world!\" } \\ \"\\\" \\ \" Then post request with name \" test-post-2 \" \\\" \\ \"\\\" { \"value\" : \"i have good news!\" } \\ \"\\\" \\ \" # same as example-1 Then post request with name \" test-post-1 \" to endpoint \" /api/test \" \\\" \\ \"\\\" { \"value\" : \"hello world!\" } \\ \"\\\" \\ \" Then post request with name \" test-post-2 \" to endpoint \" /api/test \" \\\" \\ \"\\\" { \"value\" : \"i have good news!\" } \\ \"\\\" \\ \" # example-2 Then get request with name \" test-get-1 \" from endpoint \" /api/test \" Then get request with name \" test-get-2 \" # same as example-2 Then get request with name \" test-get-1 \" from endpoint \" /api/test \" Then get request with name \" test-get-2 \" from endpoint \" /api/test \" Arguments : method RequestMethod - type of request name str - name of the requests in logs, can contain variables step_task_wait_seconds @then ( u 'wait for \" {wait_time_expression} \" seconds' ) def step_task_wait_seconds ( context : Context , wait_time_expression : str ) -> None [view_source] Creates an instace of the Wait task. The scenario will wait the specified time (seconds) in additional to the wait time specified by Task Wait . See Wait task documentation for more information about the task. Example : And ask for value of variable \" wait_time \" And wait \" 1.5..2.5 \" seconds between tasks ... Then wait for \" 1.5 \" seconds ... Then wait for \" {{ wait_time }} \" seconds Above combinations of steps will result in a wait time between 3 and 4 seconds for the first Tasks that is defined after the Then wait for... -step. Arguments : wait_time float - wait time in seconds step_task_log_message @then ( u 'log message \" {message} \"' ) def step_task_log_message ( context : Context , message : str ) -> None [view_source] Creates an instance of the Log Message task. Prints a log message in the console, useful for troubleshooting values of variables or set markers in log files. The message supports Templating . See Log Message task documentation for more information about the task. Example : And log message \" context_variable='{{ context_variable }}' Arguments : message str - message to print step_task_transform @then ( u 'parse \" {content} \" as \"{content_type:ContentType}\" and save value of \" {expression} \" in variable \" {variable} \"' ) def step_task_transform ( context : Context , content : str , content_type : TransformerContentType , expression : str , variable : str ) -> None [view_source] Creates an instance of the Transformer task. Transforms the specified content with content_type to an object that an transformer can extract information from with the specified expression . See Transformer task documentation for more information about the task. Example : And value for variable \" document_id \" is \" None \" And value for variable \" document_title \" is \" None \" And value for variable \" document \" is \" {\\ \"document\\\" : {\\ \"id\\\" : \\ \"DOCUMENT_ 8843 - 1 \\\" , \\ \"title\\\" : \\ \"TPM Report 2021 \\\" }} \" ... Then parse \" {{ document }} \" as \" json \" and save value of \" $.document.id \" in variable \" document_id \" Then parse \" {{ document }} \" as \" json \" and save value of \" $.document.title \" in variable \" document_title \" Arguments : contents str - contents to parse, supports Templating or a static string content_type TransformerContentType - MIME type of contents expression str - JSON or XPath expression for specific value in contents variable str - name of variable to save value to, must have been initialized step_task_client_get_endpoint @then ( u 'get \" {endpoint} \" with name \" {name} \" and save response in \" {variable} \"' ) def step_task_client_get_endpoint ( context : Context , endpoint : str , name : str , variable : str ) -> None [view_source] Creates an instance of a Clients task, actual implementation of the task is determined based on the URL scheme specified in endpoint . Gets information from another host or endpoint than the scenario is load testing and saves the response in a variable. See Clients task documentation for more information about client tasks. Example : Then get \" https://www.example.org/example.json \" with name \" example-1 \" and save response in \" example_openapi \" Then get \" http://{{ endpoint }} \" with name \" example-2 \" and save response in \" endpoint_result \" Arguments : endpoint str - information about where to get information, see the specific getter task implementations for more information name str - name of the request, used in request statistics variable str - name of, initialized, variable where response will be saved in step_task_client_get_endpoint_until @then ( u 'get \" {endpoint} \" with name \" {name} \" until \" {condition} \"' ) def step_task_client_get_endpoint_until ( context : Context , endpoint : str , name : str , condition : str ) -> None [view_source] Creates an instance of a Clients task, actual implementation of the task is determined based on the URL scheme specified in endpoint . Gets information, repeated from another host or endpoint than the scenario is load testing until the response matches expression . See Clients task documentation for more information about client tasks. Example : Then get \" https://www.example.org/example.json \" with name \" example-1 \" until \" $.response[status='Success'] Then get \"http://{{ endpoint }}\" with name \"example- 2 \" until \"//*[@status='Success']\" Arguments : endpoint str - information about where to get information, see the specific getter task implementations for more information name str - name of the request, used in request statistics condition str - JSON or XPath expression for specific value in response payload step_task_client_put_endpoint_file_destination @then ( u 'put \" {source} \" to \" {endpoint} \" with name \" {name} \" as \" {destination} \"' ) def step_task_client_put_endpoint_file_destination ( context : Context , source : str , endpoint : str , name : str , destination : str ) -> None [view_source] Creates an instance of a Clients task, actual implementation of the task is determined based on the URL scheme specified in endpoint . Puts information, source being a file, to another host or endpoint than the scenario is load testing and saves the response in a variable See Clients task documentation for more information about client tasks. Example : Then put \" test-file.json \" to \" bs://my-storage?AccountKey=aaaabbb=&Container=my-container \" with name \" upload-file \" as \" uploaded-test-file.json \" Arguments : source str - relative path to file in feature/requests , supports Templating endpoint str - information about where to get information, see the specific getter task implementations for more information name str - name of the request, used in request statistics destination str - name of source on the destination step_task_client_put_endpoint_file @then ( u 'put \" {source} \" to \" {endpoint} \" with name \" {name} \"' ) def step_task_client_put_endpoint_file ( context : Context , source : str , endpoint : str , name : str ) -> None [view_source] Creates an instance of a Clients task, actual implementation of the task is determined based on the URL scheme specified in endpoint . Puts information, source being a file, to another host or endpoint than the scenario is load testing and saves the response in a variable See Clients task documentation for more information about client tasks. Example : Then put \" test-file.json \" to \" bs://my-storage?AccountKey=aaaabbb=&Container=my-container \" with name \" upload-file \" Arguments : source str - relative path to file in feature/requests , supports Templating endpoint str - information about where to get information, see the specific getter task implementations for more information name str - name of the request, used in request statistics step_task_date @then ( u 'parse date \" {value} \" and save in variable \" {variable} \"' ) def step_task_date ( context : Context , value : str , variable : str ) -> None [view_source] Creates an instance of the Date task. Parses a datetime string and transforms it according to specified arguments. See Date task documentation for more information about arguments. This step is useful when changes has to be made to a datetime representation during an iteration of a scenario. Example : ... And value for variable \" date1 \" is \" none \" And value for variable \" date2 \" is \" none \" And value for variable \" date3 \" is \" none \" And value for variable \" AtomicDate.test \" is \" now \" Then parse date \" 2022-01-17 12:21:37 | timezone=UTC, format= \"%Y-%m-%dT%H:%M:%S.%f\" , offset=1D \" and save in variable \" date1 \" Then parse date \" {{ AtomicDate.test }} | offset=-1D \" and save in variable \" date2 \" Then parse date \" {{ datetime.now() }} | offset=1Y \" and save in variable \" date3 \" Arguments : value str - datetime string and arguments variable str - name of, initialized, variable where response will be saved in step_task_async_group_start @given ( u 'an async request group with name \" {name} \"' ) def step_task_async_group_start ( context : Context , name : str ) -> None [view_source] Creates an instance of the Async Group task. All Request tasks created after this step will be added to the request group, until the group is closed. See Async Group task documentation for more information. Example : Given an async request group with name \" async-group-1 \" Then post request with name \" test-post-2 \" to endpoint \" /api/test \" \\\" \\ \"\\\" { \"value\" : \"i have good news!\" } \\ \"\\\" \\ \" Then get request with name \" test-get-1 \" from endpoint \" /api/test \" And close async request group In this example, the put and get requests will run asynchronously, and both requests will block following requests until both are finished. step_task_async_group_close @then ( u 'close async request group' ) def step_task_async_group_close ( context : Context ) -> None [view_source] Closes the instance created in step_task_async_group_start , and adds the Async Group task to the list of tasks that the scenario is going to execute. See Async Group task documentation for more information. Example : Given an async request group with name \" async-group-1 \" Then post request with name \" test-post-2 \" to endpoint \" /api/test \" \\\" \\ \"\\\" { \"value\" : \"i have good news!\" } \\ \"\\\" \\ \" Then get request with name \" test-get-1 \" from endpoint \" /api/test \" And close async request group step_task_timer_start @then ( u 'start timer with name \" {name} \"' ) def step_task_timer_start ( context : Context , name : str ) -> None [view_source] Creates an instance of the Timer task. Starts a timer to measure the \"request time\" for all tasks between the start and stop of the timer. See Timer task documentation for more information. Example : Then start timer with name \" parsing-xml \" ... And stop timer with name \" parsing-xml \" step_task_timer_stop @then ( u 'stop timer with name \" {name} \"' ) def step_task_timer_stop ( context : Context , name : str ) -> None [view_source] Adds the instance created by step_task_timer_start to the list of scenario tasks. See Timer task documentation for more information. Example : Then start timer with name \" parsing-xml \" ... And stop timer with name \" parsing-xml \" step_task_wait_between @given ( u 'wait \" {min_time:g} .. {max_time:g} \" seconds between tasks' ) def step_task_wait_between ( context : Context , min_time : float , max_time : float ) -> None [view_source] Creates an instance of the Task Wait task. Sets number of, randomly, seconds the Load User will wait between executing each task. See Task Wait task documentation for more information. Example : And wait \" 1.4..1.7 \" seconds between tasks # wait between 1.4 and 1.7 seconds Then get request with name \" test-get-1 \" from endpoint \" ... \" # wait between 1.4 and 1.7 seconds Then get request with name \" test-get-2 \" from endpoint \" ... \" # wait between 1.4 and 1.7 seconds And wait \" 0.1 \" seconds between tasks # wait 0.1 seconds Then get request with name \" test-get-3 \" from endpoint \" ... \" # wait 0.1 seconds ... step_task_wait_constant @given ( u 'wait \" {time:g} \" seconds between tasks' ) def step_task_wait_constant ( context : Context , time : float ) -> None [view_source] Creates an instance of the Task Wait task. Sets number of, constant, seconds the Load User will wait between executing each task. See Task Wait task documentation for more information. Example : And wait \" 1.4 \" seconds between tasks # wait 1.4 seconds Then get request with name \" test-get-1 \" from endpoint \" ... \" # wait 1.4 seconds Then get request with name \" test-get-2 \" from endpoint \" ... \" # wait 1.4 seconds And wait \" 0.1 \" seconds between tasks # wait 0.1 seconds Then get request with name \" test-get-3 \" from endpoint \" ... \" # wait 0.1 seconds ... step_task_conditional_if @when ( u 'condition \" {condition} \" with name \" {name} \" is true, execute these tasks' ) def step_task_conditional_if ( context : Context , condition : str , name : str ) -> None [view_source] Creates an instance of the Conditional task which executes different sets of task depending on condition . Also sets the task in a state that any following tasks will be run when condition is true. See Conditional task documentation for more information. Example : When condition \" {{ value | int > 0 }} \" with name \" value-conditional \" is true, execute these tasks Then get request with name \" get-when-true \" from endpoint \" /api/true \" Then parse date \" 2022-01-17 12:21:37 | timezone=UTC, format= \"%Y-%m-%dT%H:%M:%S.%f\" , offset=1D \" and save in variable \" date1 \" But if condition is false, execute these tasks Then get request with name \" get-when-false \" from endpoint \" /api/false \" Then end condition step_task_conditional_else @then ( u 'if condition is false, execute these tasks' ) def step_task_conditional_else ( context : Context ) -> None [view_source] Changes the state of Conditional task instance created by step_task_conditional_if so that any following tasks will be run when condition is false. See Conditional task documentation for more information. Example : When condition \" {{ value | int > 0 }} \" with name \" value-conditional \" is true, execute these tasks Then get request with name \" get-when-true \" from endpoint \" /api/true \" Then parse date \" 2022-01-17 12:21:37 | timezone=UTC, format= \"%Y-%m-%dT%H:%M:%S.%f\" , offset=1D \" and save in variable \" date1 \" But if condition is false, execute these tasks Then get request with name \" get-when-false \" from endpoint \" /api/false \" Then end condition step_task_conditional_end @then ( u 'end condition' ) def step_task_conditional_end ( context : Context ) -> None [view_source] Closes the Conditional task instance created by step_task_conditional_if . This means that any following tasks specified will not be part of the conditional. See Conditional task documentation for more information. Example : When condition \" {{ value | int > 0 }} \" with name \" value-conditional \" is true, execute these tasks Then get request with name \" get-when-true \" from endpoint \" /api/true \" Then parse date \" 2022-01-17 12:21:37 | timezone=UTC, format= \"%Y-%m-%dT%H:%M:%S.%f\" , offset=1D \" and save in variable \" date1 \" But if condition is false, execute these tasks Then get request with name \" get-when-false \" from endpoint \" /api/false \" Then end condition step_task_loop_start @then ( u 'loop \" {values} \" as variable \" {variable} \" with name \" {name} \"' ) def step_task_loop_start ( context : Context , values : str , variable : str , name : str ) -> None [view_source] Creates an instance of the Loop tasks which executes all wrapped tasks with a value from the list values . values must be a valid JSON list and supports Templating . See Loop task documentation for more information. Example : Then loop \" {{ loop_values }} \" as variable \" loop_value \" with name \" test-loop \" Then log message \" loop_value={{ loop_value }} \" Then end loop step_task_loop_end @then ( u 'end loop' ) def step_task_loop_end ( context : Context ) -> None [view_source] Closes the Loop task created by step_task_loop_start . This means that any following tasks specified will not be part of the loop. See Loop task documentation for more information. Example : Then loop \" {{ loop_values }} \" as variable \" loop_value \" with name \" test-loop \" Then log message \" loop_value={{ loop_value }} \" Then end loop","title":"Tasks"},{"location":"framework/usage/steps/scenario/tasks/#step_task_request_with_name_endpoint_until","text":"@then ( u '{method:Method} request with name \" {name} \" from endpoint \" {endpoint} \" until \" {condition} \"' ) def step_task_request_with_name_endpoint_until ( context : Context , method : RequestMethod , name : str , endpoint : str , condition : str ) -> None [view_source] Creates an instance of the Until task, see task documentation for more information. Example : Then get request with name \" test-get \" from endpoint \" /api/test | content_type=json \" until \" $.`this`[?success==true] \" Then receive request with name \" test-receive \" from endpoint \" queue:receive-queue | content_type=xml \" until \" /header/success[. == 'True'] \" Arguments : method RequestMethod - type of request name str - name of the requests in logs, can contain variables direction RequestDirection - one of to or from depending on the value of method endpoint str - URI relative to host in the scenario, can contain variables and in certain cases user_class_name specific parameters condition str - JSON or XPath expression for specific value in response payload","title":"step_task_request_with_name_endpoint_until"},{"location":"framework/usage/steps/scenario/tasks/#step_task_request_text_with_name_endpoint","text":"@then ( u '{method:Method} request with name \" {name} \" {direction:Direction} endpoint \" {endpoint} \"' ) def step_task_request_text_with_name_endpoint ( context : Context , method : RequestMethod , name : str , direction : RequestDirection , endpoint : str ) -> None [view_source] Creates an instance of the Request task, where optional payload is defined directly in the feature file. See Request task documentation for more information about arguments. If method in the expression is get or receive ; the direction must be from . If method in the expression is post , pust , or send ; the direction must be to , and payload defined in the feature file. Example : Then post request with name \" test-post \" to endpoint \" /api/test \" \\\" \\ \"\\\" { \"test\" : \"hello world\" } \\ \"\\\" \\ \" Then put request with name \" test-put \" to endpoint \" /api/test \" \\\" \\ \"\\\" { \"test\" : \"hello world\" } \\ \"\\\" \\ \" Then get request with name \" test-get \" from endpoint \" /api/test \" Then send request with name \" test-send \" to endpoint \" queue:receive-queue \" \\\" \\ \"\\\" { \"value\" : \"do something\" } \\ \"\\\" \\ \" Then receive request with name \" test-receive \" from endpoint \" queue:receive-queue \" Arguments : method RequestMethod - type of request name str - name of the requests in logs, can contain variables direction RequestDirection - one of to or from depending on the value of method endpoint str - URI relative to host in the scenario, can contain variables and in certain cases user_class_name specific parameters","title":"step_task_request_text_with_name_endpoint"},{"location":"framework/usage/steps/scenario/tasks/#step_task_request_file_with_name_endpoint","text":"@then ( u '{method:Method} request \" {source} \" with name \" {name} \" to endpoint \" {endpoint} \"' ) def step_task_request_file_with_name_endpoint ( context : Context , method : RequestMethod , source : str , name : str , endpoint : str ) -> None [view_source] Creates an instance of the Request task, where the payload is defined in a template file. See Request task documentation for more information about arguments. Example : Then send request \" test/request.j2.json \" with name \" test-send \" to endpoint \" queue:receive-queue \" Then post request \" test/request.j2.json \" with name \" test-post \" to endpoint \" /api/test \" Then put request \" test/request.j2.json \" with name \" test-put \" to endpoint \" /api/test \" Arguments : method RequestMethod - type of request source str - path to a template file relative to the directory requests/ , which must exist in the directory the feature file is located name str - name of the requests in logs, can contain variables endpoint str - URI relative to host in the scenario, can contain variables and in certain cases user_class_name specific parameters","title":"step_task_request_file_with_name_endpoint"},{"location":"framework/usage/steps/scenario/tasks/#step_task_request_file_with_name","text":"@then ( u '{method:Method} request \" {source} \" with name \" {name} \"' ) def step_task_request_file_with_name ( context : Context , method : RequestMethod , source : str , name : str ) -> None [view_source] Creates an instance of the Request task, with the same endpoint as the previous Request task, where the payload is defined in a template file. See Request task documentation for more information about arguments. Example : Then post request \" test/request1.j2.json \" with name \" test-post1 \" to endpoint \" /api/test \" Then post request \" test/request2.j2.json \" with name \" test-post2 \" # same as Then post request \" test/request1.j2.json \" with name \" test-post1 \" to endpoint \" /api/test \" Then post request \" test/request2.j2.json \" with name \" test-post2 \" to endpoint \" /api/test \" Arguments : method RequestMethod - type of request source str - path to a template file relative to the directory requests/ , which must exist in the directory the feature file is located name str - name of the requests in logs, can contain variables","title":"step_task_request_file_with_name"},{"location":"framework/usage/steps/scenario/tasks/#step_task_request_text_with_name","text":"@then ( u '{method:Method} request with name \" {name} \"' ) def step_task_request_text_with_name ( context : Context , method : RequestMethod , name : str ) -> None [view_source] Creates an instance of the Request task, where optional payload is defined directly in the feature file. See Request task documentation for more information about arguments. If method in the expression is post , put or send the payload in the request must be defined directly in the feature file after the step. This step is useful if method and endpoint are the same as previous request, but the payload should be different. Example : # example-1 Then post request with name \" test-post-1 \" to endpoint \" /api/test \" \\\" \\ \"\\\" { \"value\" : \"hello world!\" } \\ \"\\\" \\ \" Then post request with name \" test-post-2 \" \\\" \\ \"\\\" { \"value\" : \"i have good news!\" } \\ \"\\\" \\ \" # same as example-1 Then post request with name \" test-post-1 \" to endpoint \" /api/test \" \\\" \\ \"\\\" { \"value\" : \"hello world!\" } \\ \"\\\" \\ \" Then post request with name \" test-post-2 \" to endpoint \" /api/test \" \\\" \\ \"\\\" { \"value\" : \"i have good news!\" } \\ \"\\\" \\ \" # example-2 Then get request with name \" test-get-1 \" from endpoint \" /api/test \" Then get request with name \" test-get-2 \" # same as example-2 Then get request with name \" test-get-1 \" from endpoint \" /api/test \" Then get request with name \" test-get-2 \" from endpoint \" /api/test \" Arguments : method RequestMethod - type of request name str - name of the requests in logs, can contain variables","title":"step_task_request_text_with_name"},{"location":"framework/usage/steps/scenario/tasks/#step_task_wait_seconds","text":"@then ( u 'wait for \" {wait_time_expression} \" seconds' ) def step_task_wait_seconds ( context : Context , wait_time_expression : str ) -> None [view_source] Creates an instace of the Wait task. The scenario will wait the specified time (seconds) in additional to the wait time specified by Task Wait . See Wait task documentation for more information about the task. Example : And ask for value of variable \" wait_time \" And wait \" 1.5..2.5 \" seconds between tasks ... Then wait for \" 1.5 \" seconds ... Then wait for \" {{ wait_time }} \" seconds Above combinations of steps will result in a wait time between 3 and 4 seconds for the first Tasks that is defined after the Then wait for... -step. Arguments : wait_time float - wait time in seconds","title":"step_task_wait_seconds"},{"location":"framework/usage/steps/scenario/tasks/#step_task_log_message","text":"@then ( u 'log message \" {message} \"' ) def step_task_log_message ( context : Context , message : str ) -> None [view_source] Creates an instance of the Log Message task. Prints a log message in the console, useful for troubleshooting values of variables or set markers in log files. The message supports Templating . See Log Message task documentation for more information about the task. Example : And log message \" context_variable='{{ context_variable }}' Arguments : message str - message to print","title":"step_task_log_message"},{"location":"framework/usage/steps/scenario/tasks/#step_task_transform","text":"@then ( u 'parse \" {content} \" as \"{content_type:ContentType}\" and save value of \" {expression} \" in variable \" {variable} \"' ) def step_task_transform ( context : Context , content : str , content_type : TransformerContentType , expression : str , variable : str ) -> None [view_source] Creates an instance of the Transformer task. Transforms the specified content with content_type to an object that an transformer can extract information from with the specified expression . See Transformer task documentation for more information about the task. Example : And value for variable \" document_id \" is \" None \" And value for variable \" document_title \" is \" None \" And value for variable \" document \" is \" {\\ \"document\\\" : {\\ \"id\\\" : \\ \"DOCUMENT_ 8843 - 1 \\\" , \\ \"title\\\" : \\ \"TPM Report 2021 \\\" }} \" ... Then parse \" {{ document }} \" as \" json \" and save value of \" $.document.id \" in variable \" document_id \" Then parse \" {{ document }} \" as \" json \" and save value of \" $.document.title \" in variable \" document_title \" Arguments : contents str - contents to parse, supports Templating or a static string content_type TransformerContentType - MIME type of contents expression str - JSON or XPath expression for specific value in contents variable str - name of variable to save value to, must have been initialized","title":"step_task_transform"},{"location":"framework/usage/steps/scenario/tasks/#step_task_client_get_endpoint","text":"@then ( u 'get \" {endpoint} \" with name \" {name} \" and save response in \" {variable} \"' ) def step_task_client_get_endpoint ( context : Context , endpoint : str , name : str , variable : str ) -> None [view_source] Creates an instance of a Clients task, actual implementation of the task is determined based on the URL scheme specified in endpoint . Gets information from another host or endpoint than the scenario is load testing and saves the response in a variable. See Clients task documentation for more information about client tasks. Example : Then get \" https://www.example.org/example.json \" with name \" example-1 \" and save response in \" example_openapi \" Then get \" http://{{ endpoint }} \" with name \" example-2 \" and save response in \" endpoint_result \" Arguments : endpoint str - information about where to get information, see the specific getter task implementations for more information name str - name of the request, used in request statistics variable str - name of, initialized, variable where response will be saved in","title":"step_task_client_get_endpoint"},{"location":"framework/usage/steps/scenario/tasks/#step_task_client_get_endpoint_until","text":"@then ( u 'get \" {endpoint} \" with name \" {name} \" until \" {condition} \"' ) def step_task_client_get_endpoint_until ( context : Context , endpoint : str , name : str , condition : str ) -> None [view_source] Creates an instance of a Clients task, actual implementation of the task is determined based on the URL scheme specified in endpoint . Gets information, repeated from another host or endpoint than the scenario is load testing until the response matches expression . See Clients task documentation for more information about client tasks. Example : Then get \" https://www.example.org/example.json \" with name \" example-1 \" until \" $.response[status='Success'] Then get \"http://{{ endpoint }}\" with name \"example- 2 \" until \"//*[@status='Success']\" Arguments : endpoint str - information about where to get information, see the specific getter task implementations for more information name str - name of the request, used in request statistics condition str - JSON or XPath expression for specific value in response payload","title":"step_task_client_get_endpoint_until"},{"location":"framework/usage/steps/scenario/tasks/#step_task_client_put_endpoint_file_destination","text":"@then ( u 'put \" {source} \" to \" {endpoint} \" with name \" {name} \" as \" {destination} \"' ) def step_task_client_put_endpoint_file_destination ( context : Context , source : str , endpoint : str , name : str , destination : str ) -> None [view_source] Creates an instance of a Clients task, actual implementation of the task is determined based on the URL scheme specified in endpoint . Puts information, source being a file, to another host or endpoint than the scenario is load testing and saves the response in a variable See Clients task documentation for more information about client tasks. Example : Then put \" test-file.json \" to \" bs://my-storage?AccountKey=aaaabbb=&Container=my-container \" with name \" upload-file \" as \" uploaded-test-file.json \" Arguments : source str - relative path to file in feature/requests , supports Templating endpoint str - information about where to get information, see the specific getter task implementations for more information name str - name of the request, used in request statistics destination str - name of source on the destination","title":"step_task_client_put_endpoint_file_destination"},{"location":"framework/usage/steps/scenario/tasks/#step_task_client_put_endpoint_file","text":"@then ( u 'put \" {source} \" to \" {endpoint} \" with name \" {name} \"' ) def step_task_client_put_endpoint_file ( context : Context , source : str , endpoint : str , name : str ) -> None [view_source] Creates an instance of a Clients task, actual implementation of the task is determined based on the URL scheme specified in endpoint . Puts information, source being a file, to another host or endpoint than the scenario is load testing and saves the response in a variable See Clients task documentation for more information about client tasks. Example : Then put \" test-file.json \" to \" bs://my-storage?AccountKey=aaaabbb=&Container=my-container \" with name \" upload-file \" Arguments : source str - relative path to file in feature/requests , supports Templating endpoint str - information about where to get information, see the specific getter task implementations for more information name str - name of the request, used in request statistics","title":"step_task_client_put_endpoint_file"},{"location":"framework/usage/steps/scenario/tasks/#step_task_date","text":"@then ( u 'parse date \" {value} \" and save in variable \" {variable} \"' ) def step_task_date ( context : Context , value : str , variable : str ) -> None [view_source] Creates an instance of the Date task. Parses a datetime string and transforms it according to specified arguments. See Date task documentation for more information about arguments. This step is useful when changes has to be made to a datetime representation during an iteration of a scenario. Example : ... And value for variable \" date1 \" is \" none \" And value for variable \" date2 \" is \" none \" And value for variable \" date3 \" is \" none \" And value for variable \" AtomicDate.test \" is \" now \" Then parse date \" 2022-01-17 12:21:37 | timezone=UTC, format= \"%Y-%m-%dT%H:%M:%S.%f\" , offset=1D \" and save in variable \" date1 \" Then parse date \" {{ AtomicDate.test }} | offset=-1D \" and save in variable \" date2 \" Then parse date \" {{ datetime.now() }} | offset=1Y \" and save in variable \" date3 \" Arguments : value str - datetime string and arguments variable str - name of, initialized, variable where response will be saved in","title":"step_task_date"},{"location":"framework/usage/steps/scenario/tasks/#step_task_async_group_start","text":"@given ( u 'an async request group with name \" {name} \"' ) def step_task_async_group_start ( context : Context , name : str ) -> None [view_source] Creates an instance of the Async Group task. All Request tasks created after this step will be added to the request group, until the group is closed. See Async Group task documentation for more information. Example : Given an async request group with name \" async-group-1 \" Then post request with name \" test-post-2 \" to endpoint \" /api/test \" \\\" \\ \"\\\" { \"value\" : \"i have good news!\" } \\ \"\\\" \\ \" Then get request with name \" test-get-1 \" from endpoint \" /api/test \" And close async request group In this example, the put and get requests will run asynchronously, and both requests will block following requests until both are finished.","title":"step_task_async_group_start"},{"location":"framework/usage/steps/scenario/tasks/#step_task_async_group_close","text":"@then ( u 'close async request group' ) def step_task_async_group_close ( context : Context ) -> None [view_source] Closes the instance created in step_task_async_group_start , and adds the Async Group task to the list of tasks that the scenario is going to execute. See Async Group task documentation for more information. Example : Given an async request group with name \" async-group-1 \" Then post request with name \" test-post-2 \" to endpoint \" /api/test \" \\\" \\ \"\\\" { \"value\" : \"i have good news!\" } \\ \"\\\" \\ \" Then get request with name \" test-get-1 \" from endpoint \" /api/test \" And close async request group","title":"step_task_async_group_close"},{"location":"framework/usage/steps/scenario/tasks/#step_task_timer_start","text":"@then ( u 'start timer with name \" {name} \"' ) def step_task_timer_start ( context : Context , name : str ) -> None [view_source] Creates an instance of the Timer task. Starts a timer to measure the \"request time\" for all tasks between the start and stop of the timer. See Timer task documentation for more information. Example : Then start timer with name \" parsing-xml \" ... And stop timer with name \" parsing-xml \"","title":"step_task_timer_start"},{"location":"framework/usage/steps/scenario/tasks/#step_task_timer_stop","text":"@then ( u 'stop timer with name \" {name} \"' ) def step_task_timer_stop ( context : Context , name : str ) -> None [view_source] Adds the instance created by step_task_timer_start to the list of scenario tasks. See Timer task documentation for more information. Example : Then start timer with name \" parsing-xml \" ... And stop timer with name \" parsing-xml \"","title":"step_task_timer_stop"},{"location":"framework/usage/steps/scenario/tasks/#step_task_wait_between","text":"@given ( u 'wait \" {min_time:g} .. {max_time:g} \" seconds between tasks' ) def step_task_wait_between ( context : Context , min_time : float , max_time : float ) -> None [view_source] Creates an instance of the Task Wait task. Sets number of, randomly, seconds the Load User will wait between executing each task. See Task Wait task documentation for more information. Example : And wait \" 1.4..1.7 \" seconds between tasks # wait between 1.4 and 1.7 seconds Then get request with name \" test-get-1 \" from endpoint \" ... \" # wait between 1.4 and 1.7 seconds Then get request with name \" test-get-2 \" from endpoint \" ... \" # wait between 1.4 and 1.7 seconds And wait \" 0.1 \" seconds between tasks # wait 0.1 seconds Then get request with name \" test-get-3 \" from endpoint \" ... \" # wait 0.1 seconds ...","title":"step_task_wait_between"},{"location":"framework/usage/steps/scenario/tasks/#step_task_wait_constant","text":"@given ( u 'wait \" {time:g} \" seconds between tasks' ) def step_task_wait_constant ( context : Context , time : float ) -> None [view_source] Creates an instance of the Task Wait task. Sets number of, constant, seconds the Load User will wait between executing each task. See Task Wait task documentation for more information. Example : And wait \" 1.4 \" seconds between tasks # wait 1.4 seconds Then get request with name \" test-get-1 \" from endpoint \" ... \" # wait 1.4 seconds Then get request with name \" test-get-2 \" from endpoint \" ... \" # wait 1.4 seconds And wait \" 0.1 \" seconds between tasks # wait 0.1 seconds Then get request with name \" test-get-3 \" from endpoint \" ... \" # wait 0.1 seconds ...","title":"step_task_wait_constant"},{"location":"framework/usage/steps/scenario/tasks/#step_task_conditional_if","text":"@when ( u 'condition \" {condition} \" with name \" {name} \" is true, execute these tasks' ) def step_task_conditional_if ( context : Context , condition : str , name : str ) -> None [view_source] Creates an instance of the Conditional task which executes different sets of task depending on condition . Also sets the task in a state that any following tasks will be run when condition is true. See Conditional task documentation for more information. Example : When condition \" {{ value | int > 0 }} \" with name \" value-conditional \" is true, execute these tasks Then get request with name \" get-when-true \" from endpoint \" /api/true \" Then parse date \" 2022-01-17 12:21:37 | timezone=UTC, format= \"%Y-%m-%dT%H:%M:%S.%f\" , offset=1D \" and save in variable \" date1 \" But if condition is false, execute these tasks Then get request with name \" get-when-false \" from endpoint \" /api/false \" Then end condition","title":"step_task_conditional_if"},{"location":"framework/usage/steps/scenario/tasks/#step_task_conditional_else","text":"@then ( u 'if condition is false, execute these tasks' ) def step_task_conditional_else ( context : Context ) -> None [view_source] Changes the state of Conditional task instance created by step_task_conditional_if so that any following tasks will be run when condition is false. See Conditional task documentation for more information. Example : When condition \" {{ value | int > 0 }} \" with name \" value-conditional \" is true, execute these tasks Then get request with name \" get-when-true \" from endpoint \" /api/true \" Then parse date \" 2022-01-17 12:21:37 | timezone=UTC, format= \"%Y-%m-%dT%H:%M:%S.%f\" , offset=1D \" and save in variable \" date1 \" But if condition is false, execute these tasks Then get request with name \" get-when-false \" from endpoint \" /api/false \" Then end condition","title":"step_task_conditional_else"},{"location":"framework/usage/steps/scenario/tasks/#step_task_conditional_end","text":"@then ( u 'end condition' ) def step_task_conditional_end ( context : Context ) -> None [view_source] Closes the Conditional task instance created by step_task_conditional_if . This means that any following tasks specified will not be part of the conditional. See Conditional task documentation for more information. Example : When condition \" {{ value | int > 0 }} \" with name \" value-conditional \" is true, execute these tasks Then get request with name \" get-when-true \" from endpoint \" /api/true \" Then parse date \" 2022-01-17 12:21:37 | timezone=UTC, format= \"%Y-%m-%dT%H:%M:%S.%f\" , offset=1D \" and save in variable \" date1 \" But if condition is false, execute these tasks Then get request with name \" get-when-false \" from endpoint \" /api/false \" Then end condition","title":"step_task_conditional_end"},{"location":"framework/usage/steps/scenario/tasks/#step_task_loop_start","text":"@then ( u 'loop \" {values} \" as variable \" {variable} \" with name \" {name} \"' ) def step_task_loop_start ( context : Context , values : str , variable : str , name : str ) -> None [view_source] Creates an instance of the Loop tasks which executes all wrapped tasks with a value from the list values . values must be a valid JSON list and supports Templating . See Loop task documentation for more information. Example : Then loop \" {{ loop_values }} \" as variable \" loop_value \" with name \" test-loop \" Then log message \" loop_value={{ loop_value }} \" Then end loop","title":"step_task_loop_start"},{"location":"framework/usage/steps/scenario/tasks/#step_task_loop_end","text":"@then ( u 'end loop' ) def step_task_loop_end ( context : Context ) -> None [view_source] Closes the Loop task created by step_task_loop_start . This means that any following tasks specified will not be part of the loop. See Loop task documentation for more information. Example : Then loop \" {{ loop_values }} \" as variable \" loop_value \" with name \" test-loop \" Then log message \" loop_value={{ loop_value }} \" Then end loop","title":"step_task_loop_end"},{"location":"framework/usage/steps/scenario/user/","text":"This module contains step implementations that describes a Load User . step_user_type_with_weight @given ( u 'a user of type \" {user_class_name} \" with weight \" {weight_value} \" load testing \" {host} \"' ) def step_user_type_with_weight ( context : Context , user_class_name : str , weight_value : str , host : str ) -> None [view_source] Sets which type of Load User the scenario should use and which host is the target, together with weight of the user (how many instances of this user should spawn relative to others). Example : Given a user of type \" RestApi \" with weight \" 2 \" load testing \" ... \" Given a user of type \" MessageQueue \" with weight \" 1 \" load testing \" ... \" Given a user of type \" ServiceBus \" with weight \" 1 \" load testing \" ... \" Given a user of type \" BlobStorage \" with weight \" 4 \" load testing \" ... \" Arguments : user_class_name str - name of an implementation of Load User , with or without User -suffix weight_value str - weight value for the user, default is 1 (see writing a locustfile ) host str - an URL for the target host, format depends on which Load User is specified step_user_type @given ( u 'a user of type \" {user_class_name} \" load testing \" {host} \"' ) def step_user_type ( context : Context , user_class_name : str , host : str ) -> None [view_source] Sets which type of Load User the scenario should use and which host is the target. Example : Given a user of type \" RestApi \" load testing \" http://api.example.com \" Given a user of type \" MessageQueue \" load testing \" mq://mqm:secret@mq.example.com/?QueueManager=QMGR01&Channel=Channel01 \" Given a user of type \" ServiceBus \" load testing \" sb://sb.example.com/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=abc123def456ghi789= \" Given a user of type \" BlobStorage \" load testing \" DefaultEndpointsProtocol=https;EndpointSuffix=core.windows.net;AccountName=examplestorage;AccountKey=xxxyyyyzzz== \" Arguments : user_class_name str - name of an implementation of Load User , with or without User -suffix host str - an URL for the target host, format depends on which Load User is specified","title":"User"},{"location":"framework/usage/steps/scenario/user/#step_user_type_with_weight","text":"@given ( u 'a user of type \" {user_class_name} \" with weight \" {weight_value} \" load testing \" {host} \"' ) def step_user_type_with_weight ( context : Context , user_class_name : str , weight_value : str , host : str ) -> None [view_source] Sets which type of Load User the scenario should use and which host is the target, together with weight of the user (how many instances of this user should spawn relative to others). Example : Given a user of type \" RestApi \" with weight \" 2 \" load testing \" ... \" Given a user of type \" MessageQueue \" with weight \" 1 \" load testing \" ... \" Given a user of type \" ServiceBus \" with weight \" 1 \" load testing \" ... \" Given a user of type \" BlobStorage \" with weight \" 4 \" load testing \" ... \" Arguments : user_class_name str - name of an implementation of Load User , with or without User -suffix weight_value str - weight value for the user, default is 1 (see writing a locustfile ) host str - an URL for the target host, format depends on which Load User is specified","title":"step_user_type_with_weight"},{"location":"framework/usage/steps/scenario/user/#step_user_type","text":"@given ( u 'a user of type \" {user_class_name} \" load testing \" {host} \"' ) def step_user_type ( context : Context , user_class_name : str , host : str ) -> None [view_source] Sets which type of Load User the scenario should use and which host is the target. Example : Given a user of type \" RestApi \" load testing \" http://api.example.com \" Given a user of type \" MessageQueue \" load testing \" mq://mqm:secret@mq.example.com/?QueueManager=QMGR01&Channel=Channel01 \" Given a user of type \" ServiceBus \" load testing \" sb://sb.example.com/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=abc123def456ghi789= \" Given a user of type \" BlobStorage \" load testing \" DefaultEndpointsProtocol=https;EndpointSuffix=core.windows.net;AccountName=examplestorage;AccountKey=xxxyyyyzzz== \" Arguments : user_class_name str - name of an implementation of Load User , with or without User -suffix host str - an URL for the target host, format depends on which Load User is specified","title":"step_user_type"},{"location":"framework/usage/tasks/","text":"Tasks are functionality that is executed by locust at run time as they are specified in the feature file. The most essential task is Request , which all Load User is using to make requests to the endpoint that is being load tested. All other tasks are helper tasks for things that needs to happen after or before a Request , stuff like extracting information from a previous response or fetching additional test data from a different endpoint (\" Clients \"). Custom It is possible to implement custom tasks, the only requirement is that they inherit grizzly.tasks.GrizzlyTask . To get them to be executed by grizzly , a step implementation is also needed. There are examples of this in the Example .","title":"Tasks"},{"location":"framework/usage/tasks/#custom","text":"It is possible to implement custom tasks, the only requirement is that they inherit grizzly.tasks.GrizzlyTask . To get them to be executed by grizzly , a step implementation is also needed. There are examples of this in the Example .","title":"Custom"},{"location":"framework/usage/tasks/async_group/","text":"This task runs all requests in the group asynchronously. The name of requests added to the group will be prefixed with async group <name>: Enable gevent debugging for this task by running with argument --verbose and setting environment variable GEVENT_MONITOR_THREAD_ENABLE . Step implementations step_task_async_group_start step_task_async_group_close Requests are added to the group with the same step implementations as Request task. Statistics Executions of this task will be visible in locust request statistics with request type ASYNC . name will be suffixed with (<n>) , where <n> is the number of requests in the group. Each request in the group will have its own entry in the statistics as an ordinary Request task. Arguments name (str): name of the group of asynchronously requests","title":"Async Group"},{"location":"framework/usage/tasks/async_group/#step-implementations","text":"step_task_async_group_start step_task_async_group_close Requests are added to the group with the same step implementations as Request task.","title":"Step implementations"},{"location":"framework/usage/tasks/async_group/#statistics","text":"Executions of this task will be visible in locust request statistics with request type ASYNC . name will be suffixed with (<n>) , where <n> is the number of requests in the group. Each request in the group will have its own entry in the statistics as an ordinary Request task.","title":"Statistics"},{"location":"framework/usage/tasks/async_group/#arguments","text":"name (str): name of the group of asynchronously requests","title":"Arguments"},{"location":"framework/usage/tasks/conditional/","text":"This task executes one or more other tasks based on condition . This is useful when a set of tasks should be executed if condition is True , and another set of tasks if condition is False . All tasks created between step_task_conditional_if and step_task_conditional_end will be wrapped in this instance and executed conditionally. If the task has its own name attribute, it will be prefixed with this tasks name . The step_task_conditional_else step expression is optional, if not used no additional tasks will be executed if condition is false. Step implementations step_task_conditional_if step_task_conditional_else (optional) step_task_conditional_end Statistics Executions of this task will be visible in locust request statistics with request type COND . name is suffixed with <condition> (<n>) , where <condition> is the runtime resolved condition and <n> is the number of tasks that is executed for the resolved condition. Each task in the set for condition will have its own entry in the statistics, see respective Tasks documentation. Arguments name str : name of the conditional, used in locust statistics condition str : Templating string that must render True or False","title":"Conditional"},{"location":"framework/usage/tasks/conditional/#step-implementations","text":"step_task_conditional_if step_task_conditional_else (optional) step_task_conditional_end","title":"Step implementations"},{"location":"framework/usage/tasks/conditional/#statistics","text":"Executions of this task will be visible in locust request statistics with request type COND . name is suffixed with <condition> (<n>) , where <condition> is the runtime resolved condition and <n> is the number of tasks that is executed for the resolved condition. Each task in the set for condition will have its own entry in the statistics, see respective Tasks documentation.","title":"Statistics"},{"location":"framework/usage/tasks/conditional/#arguments","text":"name str : name of the conditional, used in locust statistics condition str : Templating string that must render True or False","title":"Arguments"},{"location":"framework/usage/tasks/date/","text":"This task parses a string representation of a date/time and allows transformation of it, such as specifying an offset or changing the format, and saves the result as a date/time string in an variable. Step implementations step_task_date Arguments variable str - name of, initialized, variable the parsed date should be saved in value str - value Format value <date> [| format=<format>][, timezone=<timezone>][, offset=<offset>] date str/datetime - string representation of a date and/or time or a datetime object, e.g. datetime.now() format str - a python strftime format string or ISO-8601:[DateTime|Time][:ms] , this argument is required timezone str (optional) - a valid timezone name offset str (optional) - a time span string describing the offset, Y = years, M = months, D = days, h = hours, m = minutes, s = seconds, e.g. 1Y-2M10D","title":"Date"},{"location":"framework/usage/tasks/date/#step-implementations","text":"step_task_date","title":"Step implementations"},{"location":"framework/usage/tasks/date/#arguments","text":"variable str - name of, initialized, variable the parsed date should be saved in value str - value","title":"Arguments"},{"location":"framework/usage/tasks/date/#format","text":"","title":"Format"},{"location":"framework/usage/tasks/date/#value","text":"<date> [| format=<format>][, timezone=<timezone>][, offset=<offset>] date str/datetime - string representation of a date and/or time or a datetime object, e.g. datetime.now() format str - a python strftime format string or ISO-8601:[DateTime|Time][:ms] , this argument is required timezone str (optional) - a valid timezone name offset str (optional) - a time span string describing the offset, Y = years, M = months, D = days, h = hours, m = minutes, s = seconds, e.g. 1Y-2M10D","title":"value"},{"location":"framework/usage/tasks/log_message/","text":"This task calls the grizzly logger to print a log message at level INFO . It can be used to visualize values for Templating variables. Step implementations step_task_log_message Statistics This task does not have any request statistics entries. Arguments message str - message to log at INFO level, can be a template","title":"Log Message"},{"location":"framework/usage/tasks/log_message/#step-implementations","text":"step_task_log_message","title":"Step implementations"},{"location":"framework/usage/tasks/log_message/#statistics","text":"This task does not have any request statistics entries.","title":"Statistics"},{"location":"framework/usage/tasks/log_message/#arguments","text":"message str - message to log at INFO level, can be a template","title":"Arguments"},{"location":"framework/usage/tasks/loop/","text":"This task executes the wraped tasks for all values in provided list. All task created between step_task_loop_start and step_task_loop_end will be wrapped in this instance and executed for all values in the provided list (must be in JSON format). Step implementations step_task_loop_start step_task_loop_end Statistics Executions of this task will be visible in locust request statistics with request type LOOP and name is suffixed with (<n>) , where n is the number of wrapped tasks. Each wrapped task will have its own entry in the statistics, see respective Tasks documentation. Arguments name str : name of the for loop, used in locust statistics values str : Templating string which must be valid json and render to a list of values variable str : name of variable that a value from input_list will be accessible in","title":"Loop"},{"location":"framework/usage/tasks/loop/#step-implementations","text":"step_task_loop_start step_task_loop_end","title":"Step implementations"},{"location":"framework/usage/tasks/loop/#statistics","text":"Executions of this task will be visible in locust request statistics with request type LOOP and name is suffixed with (<n>) , where n is the number of wrapped tasks. Each wrapped task will have its own entry in the statistics, see respective Tasks documentation.","title":"Statistics"},{"location":"framework/usage/tasks/loop/#arguments","text":"name str : name of the for loop, used in locust statistics values str : Templating string which must be valid json and render to a list of values variable str : name of variable that a value from input_list will be accessible in","title":"Arguments"},{"location":"framework/usage/tasks/request/","text":"This task calls the request method of a grizzly.users implementation. This is the most essential task in grizzly , it defines requests that the specified load user is going to execute against the target under test. Optionally, the MIME type of the response can be set, this has to be done if any of the Response steps is going to be used. Step implementations step_task_request_text_with_name_endpoint step_task_request_file_with_name_endpoint step_task_request_file_with_name step_task_request_text_with_name Statistics Executions of this task will be visible in locust request statistics with request type method . Arguments method RequestMethod - method used for the request, e.g. GET or POST , also includes the direction (to or from) name str - name of the request, used in locust statistics endpoint str - endpoint on the load testing target, have different meaning depending on the specified Load User source str (optional) - payload data sent to endpoint , can be a file path Format endpoint All arguments will be removed from endpoint before creating the task instance. <endpoint> [| content_type=<content_type>] endpoint str - endpoint in format that the specified Load User understands content_type TransformerContentType (optional) - MIME type of response from endpoint Specifying MIME/content type as an argument to endpoint is the same as using step_response_content_type . Then put request \" test/request.j2.json \" with name \" test-put \" to endpoint \" /api/test | content_type=json \" # same as Then put request \" test/request.j2.json \" with name \" test-put \" to endpoint \" /api/test \" And set response content type to \" application/json \"","title":"Request"},{"location":"framework/usage/tasks/request/#step-implementations","text":"step_task_request_text_with_name_endpoint step_task_request_file_with_name_endpoint step_task_request_file_with_name step_task_request_text_with_name","title":"Step implementations"},{"location":"framework/usage/tasks/request/#statistics","text":"Executions of this task will be visible in locust request statistics with request type method .","title":"Statistics"},{"location":"framework/usage/tasks/request/#arguments","text":"method RequestMethod - method used for the request, e.g. GET or POST , also includes the direction (to or from) name str - name of the request, used in locust statistics endpoint str - endpoint on the load testing target, have different meaning depending on the specified Load User source str (optional) - payload data sent to endpoint , can be a file path","title":"Arguments"},{"location":"framework/usage/tasks/request/#format","text":"","title":"Format"},{"location":"framework/usage/tasks/request/#endpoint","text":"All arguments will be removed from endpoint before creating the task instance. <endpoint> [| content_type=<content_type>] endpoint str - endpoint in format that the specified Load User understands content_type TransformerContentType (optional) - MIME type of response from endpoint Specifying MIME/content type as an argument to endpoint is the same as using step_response_content_type . Then put request \" test/request.j2.json \" with name \" test-put \" to endpoint \" /api/test | content_type=json \" # same as Then put request \" test/request.j2.json \" with name \" test-put \" to endpoint \" /api/test \" And set response content type to \" application/json \"","title":"endpoint"},{"location":"framework/usage/tasks/task_wait/","text":"This task sets the wait time between tasks in a scenario. The default is to wait 0 seconds between each task. This is useful in a scenario with many tasks that should have some wait time between them, but there are a group of tasks (e.g. Transform, Date or Log Messages) that should execute as fast as possible. If max_time is not provided, the wait between tasks is constant min_time . If both are provided there will be a random wait between (and including) min_time and max_time between tasks. Step implementations step_task_wait_constant step_task_wait_between Statistics This task does not have any request statistics entries. Arguments min_time float - minimum time to wait max_time float (optional) - maximum time to wait","title":"Task Wait"},{"location":"framework/usage/tasks/task_wait/#step-implementations","text":"step_task_wait_constant step_task_wait_between","title":"Step implementations"},{"location":"framework/usage/tasks/task_wait/#statistics","text":"This task does not have any request statistics entries.","title":"Statistics"},{"location":"framework/usage/tasks/task_wait/#arguments","text":"min_time float - minimum time to wait max_time float (optional) - maximum time to wait","title":"Arguments"},{"location":"framework/usage/tasks/timer/","text":"This task \"wraps\" a group of other tasks, that might not have any requests and hence no statistics, to measure how long time they took. Request content length for this task in the scenario is number of tasks between starting and stopping the timer. Odd executions of this task starts the timer by setting a timestamp for the task. Even executions of this task stops the timer and logs the \"response time\" in the locust statistics. Step implementations step_task_timer_start step_task_timer_stop Statistics Executions of this task will be visible in locust statistics with request type TIMR . name will be prefixed with (<n>) , where <n> indicates how many tasks was run between the start and stop of this timer. Response time is the total time it took for the <n> tasks to run. Arguments name str - name of the timer","title":"Timer"},{"location":"framework/usage/tasks/timer/#step-implementations","text":"step_task_timer_start step_task_timer_stop","title":"Step implementations"},{"location":"framework/usage/tasks/timer/#statistics","text":"Executions of this task will be visible in locust statistics with request type TIMR . name will be prefixed with (<n>) , where <n> indicates how many tasks was run between the start and stop of this timer. Response time is the total time it took for the <n> tasks to run.","title":"Statistics"},{"location":"framework/usage/tasks/timer/#arguments","text":"name str - name of the timer","title":"Arguments"},{"location":"framework/usage/tasks/transformer/","text":"This task transforms a variable value to a document of correct type, so an expression can be used to extract values from the document to be used in another variable. This is especially useful when used in combination with other variables variables containing a lot of information, where many parts of a message can be useful to re-use. Instances of this task is created with the step expression: Step implementations step_task_transform Statistics Executions of this task will not be visible in locust request statistics, unless something goes wrong. It will then have the request type TRNSF . Arguments contents str - text to parse, supports Templating or a static string content_type TransformerContentType - MIME type of contents , which transformer to use expression str - JSON- or XPath expression to extract specific values in contents variable str - name of variable to save value to, must have been intialized","title":"Transformer"},{"location":"framework/usage/tasks/transformer/#step-implementations","text":"step_task_transform","title":"Step implementations"},{"location":"framework/usage/tasks/transformer/#statistics","text":"Executions of this task will not be visible in locust request statistics, unless something goes wrong. It will then have the request type TRNSF .","title":"Statistics"},{"location":"framework/usage/tasks/transformer/#arguments","text":"contents str - text to parse, supports Templating or a static string content_type TransformerContentType - MIME type of contents , which transformer to use expression str - JSON- or XPath expression to extract specific values in contents variable str - name of variable to save value to, must have been intialized","title":"Arguments"},{"location":"framework/usage/tasks/until/","text":"This task calls the request method of a grizzly.users implementation, until condition matches the payload returned for the request. Step implementations step_task_request_with_name_endpoint_until step_task_client_get_endpoint_until Statistics Executions of this task will be visible in locust request statistics with request type UNTL indicating how long time it took to finish the task. name will be suffixed with r=<retries>, w=<wait>, em=<expected_matches> . The request task that is being repeated until condition is true will have it's own entry in the statistics as an ordinary Request or Clients task. Arguments request Request / Clients - request that is going to be repeated condition str - condition expression that specifies how request should be repeated Format condition <expression> [| [retries=<retries>][, wait=<wait>][, expected_matches=<expected_matches>]] expression str - JSON- or Xpath expression retries int (optional) - maximum number of times to repeat the request if condition is not met (default 3 ) wait float (optional) - number of seconds to wait between retries (default 1.0 ) expected_matches int (optional): number of matches that the expression should match (default 1 )","title":"Until"},{"location":"framework/usage/tasks/until/#step-implementations","text":"step_task_request_with_name_endpoint_until step_task_client_get_endpoint_until","title":"Step implementations"},{"location":"framework/usage/tasks/until/#statistics","text":"Executions of this task will be visible in locust request statistics with request type UNTL indicating how long time it took to finish the task. name will be suffixed with r=<retries>, w=<wait>, em=<expected_matches> . The request task that is being repeated until condition is true will have it's own entry in the statistics as an ordinary Request or Clients task.","title":"Statistics"},{"location":"framework/usage/tasks/until/#arguments","text":"request Request / Clients - request that is going to be repeated condition str - condition expression that specifies how request should be repeated","title":"Arguments"},{"location":"framework/usage/tasks/until/#format","text":"","title":"Format"},{"location":"framework/usage/tasks/until/#condition","text":"<expression> [| [retries=<retries>][, wait=<wait>][, expected_matches=<expected_matches>]] expression str - JSON- or Xpath expression retries int (optional) - maximum number of times to repeat the request if condition is not met (default 3 ) wait float (optional) - number of seconds to wait between retries (default 1.0 ) expected_matches int (optional): number of matches that the expression should match (default 1 )","title":"condition"},{"location":"framework/usage/tasks/wait/","text":"This task executes a gevent.sleep and is used to manually create delays between steps in a scenario. Step implementations step_task_wait_seconds Arguments time_expression str - float as string or a {@pydocfractions of seconds to excplicitly sleep in the scenario","title":"Wait"},{"location":"framework/usage/tasks/wait/#step-implementations","text":"step_task_wait_seconds","title":"Step implementations"},{"location":"framework/usage/tasks/wait/#arguments","text":"time_expression str - float as string or a {@pydocfractions of seconds to excplicitly sleep in the scenario","title":"Arguments"},{"location":"framework/usage/tasks/clients/","text":"Client tasks is functionality that is executed by locust and is registred to an URL scheme. These tasks is used to make a request to another host than the scenario is actually load testing. Statistics Executions of all client tasks will be visible with request type CLNT . Arguments endpoint str - describes the request If endpoint is a template variable which includes the scheme, the scheme for the request must be specified so the correct grizzly.tasks.client implementation is used. The additional scheme will be removed when the request is performed.","title":"Clients"},{"location":"framework/usage/tasks/clients/#statistics","text":"Executions of all client tasks will be visible with request type CLNT .","title":"Statistics"},{"location":"framework/usage/tasks/clients/#arguments","text":"endpoint str - describes the request If endpoint is a template variable which includes the scheme, the scheme for the request must be specified so the correct grizzly.tasks.client implementation is used. The additional scheme will be removed when the request is performed.","title":"Arguments"},{"location":"framework/usage/tasks/clients/blobstorage/","text":"This task performs Azure Blob Storage put operations to a specified endpoint. This is useful if the scenario is another user type than BlobStorageUser , but the scenario still requires an action towards a blob container. Only supports RequestDirection.TO . Step implementations step_task_client_put_endpoint_file_destination Arguments direction RequestDirection - if the request is upstream or downstream endpoint str - specifies details to be able to perform the request, e.g. account and container information name str - name used in locust statistics destination str (optional) - name of the file when uploaded, if not specified the basename of source will be used source str (optional) - file path of local file that should be saved in Container Format endpoint bs[s]://<AccountName>?AccountKey=<AccountKey>&Container=<Container> AccountName str - name of storage account AccountKey str - secret key to be able to \"connect\" to the storage account Container str - name of the container to perform the request on All variables in the endpoint supports Templating , but not the whole string. destination The MIME type of an uploaded file will automagically be guessed based on the [rendered] destination file extension.","title":"Blobstorage"},{"location":"framework/usage/tasks/clients/blobstorage/#step-implementations","text":"step_task_client_put_endpoint_file_destination","title":"Step implementations"},{"location":"framework/usage/tasks/clients/blobstorage/#arguments","text":"direction RequestDirection - if the request is upstream or downstream endpoint str - specifies details to be able to perform the request, e.g. account and container information name str - name used in locust statistics destination str (optional) - name of the file when uploaded, if not specified the basename of source will be used source str (optional) - file path of local file that should be saved in Container","title":"Arguments"},{"location":"framework/usage/tasks/clients/blobstorage/#format","text":"","title":"Format"},{"location":"framework/usage/tasks/clients/blobstorage/#endpoint","text":"bs[s]://<AccountName>?AccountKey=<AccountKey>&Container=<Container> AccountName str - name of storage account AccountKey str - secret key to be able to \"connect\" to the storage account Container str - name of the container to perform the request on All variables in the endpoint supports Templating , but not the whole string.","title":"endpoint"},{"location":"framework/usage/tasks/clients/blobstorage/#destination","text":"The MIME type of an uploaded file will automagically be guessed based on the [rendered] destination file extension.","title":"destination"},{"location":"framework/usage/tasks/clients/http/","text":"This task performs a HTTP request to a specified endpoint. This is useful if the scenario is using a non-HTTP user or a request to a URL other than the one under testing is needed, e.g. for testdata. Only supports RequestDirection.FROM . Step implementations step_task_client_get_endpoint Arguments direction RequestDirection - only RequestDirection.FROM is implemented endpoint str - URL to perform GET request from name str - name used in locust statistics","title":"HTTP"},{"location":"framework/usage/tasks/clients/http/#step-implementations","text":"step_task_client_get_endpoint","title":"Step implementations"},{"location":"framework/usage/tasks/clients/http/#arguments","text":"direction RequestDirection - only RequestDirection.FROM is implemented endpoint str - URL to perform GET request from name str - name used in locust statistics","title":"Arguments"},{"location":"framework/usage/tasks/clients/messagequeue/","text":"This task performs IBM MQM get and put opertions to a specified queue or topic. This is useful if the scenario is another user type than MessageQueueUser , but the scenario still requires an action towards an MQ server. Use Transformer task to extract specific parts of the message. Grizzly must have been installed with the extra mq package and native IBM MQ libraries must be installed for being able to use this variable: pip3 install grizzly-loadtester[mq] Step implementations step_task_client_get_endpoint step_task_client_put_endpoint_file Arguments direction RequestDirection - if the request is upstream or downstream endpoint str - specifies details to be able to perform the request, e.g. account and container information name str - name used in locust statistics destination str (optional) - not used by this client source str (optional) - file path of local file that should be put on endpoint Format endpoint mq[s]://<username>:<password>@]<hostname>[:<port>]/<endpoint>?QueueManager=<queue manager>&Channel=<channel>[&wait=<wait>][&heartbeat=<heartbeat>][&KeyFile=<key repo path>[&SslCipher=<ssl cipher>][&CertLabel=<certificate label>]][&HeaderType=<header type>][&MaxMessageSize=<number of bytes>] All variables in the URL have support for Templating . mq[s] str - must be specified, mqs implies connecting with TLS, if KeyFile is not set in querystring, it will look for a key repository in ./<username> username str (optional) - username to authenticate with, default None password str (optional) - password to authenticate with, default None hostname str - hostname of MQ server port int (optional) - port on MQ server, default 1414 endpoint str - prefixed with either topic: or queue: and then the name of the endpoint to perform operations on wait int (optional) - number of seconds to wait for an message, default is to wait infinite (0 seconds) heartbeat int (optional) - number of seconds between heartbeats, default is 300 seconds QueueManager str - name of queue manager Channel str - name of channel to connect to KeyFile str (optional) - path to key repository for certificates needed to connect over TLS SslCipher str (optional) - SSL cipher to use for connection, default ECDHE_RSA_AES_256_GCM_SHA384 CertLabel str (optional) - label of certificate in key repository, default username HeaderType str (optional) - header type, can be RFH2 for sending gzip compressed messages using RFH2 header, default None MaxMessageSize int (optional) - maximum number of bytes a message can be for the client to accept it, default is None which implies that the client will throw MQRC_TRUNCATED_MSG_FAILED , adjust buffer and try again.","title":"Messagequeue"},{"location":"framework/usage/tasks/clients/messagequeue/#step-implementations","text":"step_task_client_get_endpoint step_task_client_put_endpoint_file","title":"Step implementations"},{"location":"framework/usage/tasks/clients/messagequeue/#arguments","text":"direction RequestDirection - if the request is upstream or downstream endpoint str - specifies details to be able to perform the request, e.g. account and container information name str - name used in locust statistics destination str (optional) - not used by this client source str (optional) - file path of local file that should be put on endpoint","title":"Arguments"},{"location":"framework/usage/tasks/clients/messagequeue/#format","text":"","title":"Format"},{"location":"framework/usage/tasks/clients/messagequeue/#endpoint","text":"mq[s]://<username>:<password>@]<hostname>[:<port>]/<endpoint>?QueueManager=<queue manager>&Channel=<channel>[&wait=<wait>][&heartbeat=<heartbeat>][&KeyFile=<key repo path>[&SslCipher=<ssl cipher>][&CertLabel=<certificate label>]][&HeaderType=<header type>][&MaxMessageSize=<number of bytes>] All variables in the URL have support for Templating . mq[s] str - must be specified, mqs implies connecting with TLS, if KeyFile is not set in querystring, it will look for a key repository in ./<username> username str (optional) - username to authenticate with, default None password str (optional) - password to authenticate with, default None hostname str - hostname of MQ server port int (optional) - port on MQ server, default 1414 endpoint str - prefixed with either topic: or queue: and then the name of the endpoint to perform operations on wait int (optional) - number of seconds to wait for an message, default is to wait infinite (0 seconds) heartbeat int (optional) - number of seconds between heartbeats, default is 300 seconds QueueManager str - name of queue manager Channel str - name of channel to connect to KeyFile str (optional) - path to key repository for certificates needed to connect over TLS SslCipher str (optional) - SSL cipher to use for connection, default ECDHE_RSA_AES_256_GCM_SHA384 CertLabel str (optional) - label of certificate in key repository, default username HeaderType str (optional) - header type, can be RFH2 for sending gzip compressed messages using RFH2 header, default None MaxMessageSize int (optional) - maximum number of bytes a message can be for the client to accept it, default is None which implies that the client will throw MQRC_TRUNCATED_MSG_FAILED , adjust buffer and try again.","title":"endpoint"},{"location":"framework/usage/variables/environment-configuration/","text":"It is possible to make the feature file environment agnostic by providing a yaml file containing a dictionary with a root node named configuration . The environment configuration file can also be used to store credentials and other sensitive information that should not be under version control. Internally grizzly will check if the environment variable GRIZZLY_CONFIGURATION_FILE is set and contains a valid environment configuration file. When using grizzly-cli you specify the file with -e/--environment-file which then will be set as a value for GRIZZLY_CONFIGURATION_FILE . Format An example environment configuration file: configuration : frontend : host : https://www.example.com backend : host : https://backend.example.com auth : user : username : bob password : Who-the-f-is-alice The only rule for any nodes under configuration is that it must be a dictionary, since the path to a value will be flattened. Usage In a feature file the dictionary can then be used by prefixing the path of a node under configuration with $conf::<tree path to variable>$ . Example: Feature: application test Background: common configuration Given \" 1 \" users And spawn rate is \" 1 \" user per second And stop on first failure Scenario: frontend Given a user of type \" RestApi \" load testing \" $conf::frontend.host$ \" ... Scenario: backend Given a user of type \" RestApi \" load testing \" $conf::backend.host$ \" And set context variable \" auth.user.username \" to \" $conf::backend.auth.user.username$ \" And set context variable \" auth.user.password \" to \" $conf::backend.auth.user.password$ \" This feature can now be run against a different environment just by creating a new environment configuration file with different values.","title":"Environment configuration"},{"location":"framework/usage/variables/environment-configuration/#format","text":"An example environment configuration file: configuration : frontend : host : https://www.example.com backend : host : https://backend.example.com auth : user : username : bob password : Who-the-f-is-alice The only rule for any nodes under configuration is that it must be a dictionary, since the path to a value will be flattened.","title":"Format"},{"location":"framework/usage/variables/environment-configuration/#usage","text":"In a feature file the dictionary can then be used by prefixing the path of a node under configuration with $conf::<tree path to variable>$ . Example: Feature: application test Background: common configuration Given \" 1 \" users And spawn rate is \" 1 \" user per second And stop on first failure Scenario: frontend Given a user of type \" RestApi \" load testing \" $conf::frontend.host$ \" ... Scenario: backend Given a user of type \" RestApi \" load testing \" $conf::backend.host$ \" And set context variable \" auth.user.username \" to \" $conf::backend.auth.user.username$ \" And set context variable \" auth.user.password \" to \" $conf::backend.auth.user.password$ \" This feature can now be run against a different environment just by creating a new environment configuration file with different values.","title":"Usage"},{"location":"framework/usage/variables/templating/","text":"Templating grizzly has support for templating in both step expression variables (most) and request payload, with the templating backend Jinja2 , and also grizzly specific templating variables from environment variables or environment configuration files. The later is resolved before a test is started, while the former is resolved during run time. See Environment configuration on how to use $conf:: -variables. Request payload Request payload is treated as complete Jinja2 templates and has full support for any Jinja2 features. Request payload files must be stored in ./features/requests and are referenced in a feature file as a relative path to that directory. . \u2514\u2500\u2500 features \u251c\u2500\u2500 load-test.feature \u2514\u2500\u2500 requests \u2514\u2500\u2500 load-test \u2514\u2500\u2500 request.j2.json Consider that load-test.feature contains the following steps: Feature: templating example Background: common settings for all scenarios Given \" 1 \" user And spawn rate is \" 1 \" user per second And stop on first failure Scenario: example Given a user of type \" RestApi \" load testing \" https://localhost \" And repeat for \" 3 \" iterations And value for variable \" AtomicIntegerIncrementer.items \" is \" 1 | step=3 \" Then post request \" load-test/request.j2.json \" with name \" template-request \" to endpoint \" /api/v1/test \" request.j2.json is a full Jinja2 template which will be rendered before the request is sent. The reason for this is that testdata variables can be used in the template, and these can change for each request. If request.j2.json contains the following: [ { % - f or n i n ra n ge(A t omicI nte gerI n creme nter .i te ms) % } { \"item\" : {{ n }}, \"name\" : \"item-{{ n }}\" } { % - i f n < A t omicI nte gerI n creme nter .i te ms - 1 % },{ % - e n di f % } { % - e n d f or % } ] Since the scenario has been setup to run for 3 iterations with 1 user and assumed that we run it locally, or distributed with one worker node, the scenario will run three times. The first post request to /api/v1/test will have the following payload: [ { \"item\" : 0 , \"name\" : \"item-0\" } ] The second post request: [ { \"item\" : 0 , \"name\" : \"item-0\" }, { \"item\" : 1 , \"name\" : \"item-1\" }, { \"item\" : 2 , \"name\" : \"item-2\" }, { \"item\" : 3 , \"name\" : \"item-3\" } ] The third post request: [ { \"item\" : 0 , \"name\" : \"item-0\" }, { \"item\" : 1 , \"name\" : \"item-1\" }, { \"item\" : 2 , \"name\" : \"item-2\" }, { \"item\" : 3 , \"name\" : \"item-3\" }, { \"item\" : 4 , \"name\" : \"item-4\" }, { \"item\" : 5 , \"name\" : \"item-5\" }, { \"item\" : 6 , \"name\" : \"item-6\" } ] Step expression Most step expressions also support templating for their variables, for example: And set context variable \" auth.user.username \" to \" $conf::backend.auth.user.username$ \" And set context variable \" auth.refresh_time \" to \" {{ AtomicIntegerIncrementer.refresh_time }} \" And repeat for \" {{ iterations * 0.25 }} \" And save statistics to \" influxdb://$conf::statistics.username$:$conf::statistics.password$@{{ influxdb_host }}/$conf::statistics.database$ \" And ask for value of variable \" initial_id \" And value for variable \" AtomicIntegerIncrementer.id1 \" is \" {{ initial_id }} \" And value for variable \" AtomicIntegerIncrementer.id2 \" is \" {{ initial_id }} \" Then put request with name \" example-{{ initial_id }} \" to \" /api/v{{ initial_id }}/test \" \"\"\" { \"test\": { \"value\": \"{{ initial_id }}\" } } \"\"\"","title":"Templating"},{"location":"framework/usage/variables/templating/#templating","text":"grizzly has support for templating in both step expression variables (most) and request payload, with the templating backend Jinja2 , and also grizzly specific templating variables from environment variables or environment configuration files. The later is resolved before a test is started, while the former is resolved during run time. See Environment configuration on how to use $conf:: -variables.","title":"Templating"},{"location":"framework/usage/variables/templating/#request-payload","text":"Request payload is treated as complete Jinja2 templates and has full support for any Jinja2 features. Request payload files must be stored in ./features/requests and are referenced in a feature file as a relative path to that directory. . \u2514\u2500\u2500 features \u251c\u2500\u2500 load-test.feature \u2514\u2500\u2500 requests \u2514\u2500\u2500 load-test \u2514\u2500\u2500 request.j2.json Consider that load-test.feature contains the following steps: Feature: templating example Background: common settings for all scenarios Given \" 1 \" user And spawn rate is \" 1 \" user per second And stop on first failure Scenario: example Given a user of type \" RestApi \" load testing \" https://localhost \" And repeat for \" 3 \" iterations And value for variable \" AtomicIntegerIncrementer.items \" is \" 1 | step=3 \" Then post request \" load-test/request.j2.json \" with name \" template-request \" to endpoint \" /api/v1/test \" request.j2.json is a full Jinja2 template which will be rendered before the request is sent. The reason for this is that testdata variables can be used in the template, and these can change for each request. If request.j2.json contains the following: [ { % - f or n i n ra n ge(A t omicI nte gerI n creme nter .i te ms) % } { \"item\" : {{ n }}, \"name\" : \"item-{{ n }}\" } { % - i f n < A t omicI nte gerI n creme nter .i te ms - 1 % },{ % - e n di f % } { % - e n d f or % } ] Since the scenario has been setup to run for 3 iterations with 1 user and assumed that we run it locally, or distributed with one worker node, the scenario will run three times. The first post request to /api/v1/test will have the following payload: [ { \"item\" : 0 , \"name\" : \"item-0\" } ] The second post request: [ { \"item\" : 0 , \"name\" : \"item-0\" }, { \"item\" : 1 , \"name\" : \"item-1\" }, { \"item\" : 2 , \"name\" : \"item-2\" }, { \"item\" : 3 , \"name\" : \"item-3\" } ] The third post request: [ { \"item\" : 0 , \"name\" : \"item-0\" }, { \"item\" : 1 , \"name\" : \"item-1\" }, { \"item\" : 2 , \"name\" : \"item-2\" }, { \"item\" : 3 , \"name\" : \"item-3\" }, { \"item\" : 4 , \"name\" : \"item-4\" }, { \"item\" : 5 , \"name\" : \"item-5\" }, { \"item\" : 6 , \"name\" : \"item-6\" } ]","title":"Request payload"},{"location":"framework/usage/variables/templating/#step-expression","text":"Most step expressions also support templating for their variables, for example: And set context variable \" auth.user.username \" to \" $conf::backend.auth.user.username$ \" And set context variable \" auth.refresh_time \" to \" {{ AtomicIntegerIncrementer.refresh_time }} \" And repeat for \" {{ iterations * 0.25 }} \" And save statistics to \" influxdb://$conf::statistics.username$:$conf::statistics.password$@{{ influxdb_host }}/$conf::statistics.database$ \" And ask for value of variable \" initial_id \" And value for variable \" AtomicIntegerIncrementer.id1 \" is \" {{ initial_id }} \" And value for variable \" AtomicIntegerIncrementer.id2 \" is \" {{ initial_id }} \" Then put request with name \" example-{{ initial_id }} \" to \" /api/v{{ initial_id }}/test \" \"\"\" { \"test\": { \"value\": \"{{ initial_id }}\" } } \"\"\"","title":"Step expression"},{"location":"framework/usage/variables/testdata/","text":"This package contains special variables that can be used in a feature file and is synchronized between locust workers. Custom It is possible to implement custom testdata variables, the only requirement is that they inherit grizzly.testdata.variables.AtomicVariable . When initializing the variable, the full namespace has to be specified as name in the scenario step_setup_variable_value step. There are examples of this in the Example .","title":"Testdata"},{"location":"framework/usage/variables/testdata/#custom","text":"It is possible to implement custom testdata variables, the only requirement is that they inherit grizzly.testdata.variables.AtomicVariable . When initializing the variable, the full namespace has to be specified as name in the scenario step_setup_variable_value step. There are examples of this in the Example .","title":"Custom"},{"location":"framework/usage/variables/testdata/csv_row/","text":"This variable reads a CSV file and provides a new row from the CSV file each time it is accessed. The CSV files must have headers for each column, since these are used to reference the value. Format Value is the path, relative to requests/ , of an file ending with .csv . Arguments repeat bool (optional) - whether values should be reused, e.g. when reaching the end it should start from the beginning again (default: False ) random bool (optional) - if rows should be selected by random, instead of sequential from first to last (default: False ) Example requests/example.csv : username,password bob1,some-password alice1,some-other-password bob2,password And value for variable \" AtomicCsvRow.example \" is \" example.csv | random=False, repeat=True \" Then post request with name \" authenticate \" to endpoint \" /api/v1/authenticate \" \"\"\" { \"username\": \"{{ AtomicCsvRow.example.username }}\", \"password\": \"{{ AtomicCsvRow.example.password }}\" } \"\"\" First request the payload will be: { \"username\" : \"bob1\" , \"password\" : \"some-password\" } Second request: { \"username\" : \"alice1\" , \"password\" : \"some-other-password\" } etc.","title":"CSV Row"},{"location":"framework/usage/variables/testdata/csv_row/#format","text":"Value is the path, relative to requests/ , of an file ending with .csv .","title":"Format"},{"location":"framework/usage/variables/testdata/csv_row/#arguments","text":"repeat bool (optional) - whether values should be reused, e.g. when reaching the end it should start from the beginning again (default: False ) random bool (optional) - if rows should be selected by random, instead of sequential from first to last (default: False )","title":"Arguments"},{"location":"framework/usage/variables/testdata/csv_row/#example","text":"requests/example.csv : username,password bob1,some-password alice1,some-other-password bob2,password And value for variable \" AtomicCsvRow.example \" is \" example.csv | random=False, repeat=True \" Then post request with name \" authenticate \" to endpoint \" /api/v1/authenticate \" \"\"\" { \"username\": \"{{ AtomicCsvRow.example.username }}\", \"password\": \"{{ AtomicCsvRow.example.password }}\" } \"\"\" First request the payload will be: { \"username\" : \"bob1\" , \"password\" : \"some-password\" } Second request: { \"username\" : \"alice1\" , \"password\" : \"some-other-password\" } etc.","title":"Example"},{"location":"framework/usage/variables/testdata/date/","text":"This variable is used to format and use dates. Format Initial value can, other than a parseable datetime string, be now . Each time the variable is accessed the value will represent that date and time at the time of access. Arguments format str - a python strftime format string , this argument is required timezone str (optional) - a valid timezone name offset str (optional) - a time span string describing the offset, Y = years, M = months, D = days, h = hours, m = minutes, s = seconds, e.g. 1Y-2M10D Example And value for variable \" AtomicDate.arrival \" is \" now | format='%Y-%m-%dT%H:%M:%S.000Z', timezone=UTC \" This can then be used in a template: { \"arrival\" : \"{{ AtomicDate.arrival }}\" , \"location\" : \"Port of Shanghai\" }","title":"Date"},{"location":"framework/usage/variables/testdata/date/#format","text":"Initial value can, other than a parseable datetime string, be now . Each time the variable is accessed the value will represent that date and time at the time of access.","title":"Format"},{"location":"framework/usage/variables/testdata/date/#arguments","text":"format str - a python strftime format string , this argument is required timezone str (optional) - a valid timezone name offset str (optional) - a time span string describing the offset, Y = years, M = months, D = days, h = hours, m = minutes, s = seconds, e.g. 1Y-2M10D","title":"Arguments"},{"location":"framework/usage/variables/testdata/date/#example","text":"And value for variable \" AtomicDate.arrival \" is \" now | format='%Y-%m-%dT%H:%M:%S.000Z', timezone=UTC \" This can then be used in a template: { \"arrival\" : \"{{ AtomicDate.arrival }}\" , \"location\" : \"Port of Shanghai\" }","title":"Example"},{"location":"framework/usage/variables/testdata/directory_contents/","text":"This variable provides a list of files in the specified directory. Format Relative path of a directory under requests/ . Arguments repeat bool (optional) - wether values should be reused, e.g. when reaching the end it should start from the beginning again (default: False ) random bool (optional) - if files should be selected by random, instead of sequential from first to last (default: False ) Example With the following directory structure: . \u2514\u2500\u2500 requests \u2514\u2500\u2500 files \u251c\u2500\u2500 file1.bin \u251c\u2500\u2500 file2.bin \u251c\u2500\u2500 file3.bin \u251c\u2500\u2500 file4.bin \u2514\u2500\u2500 file5.bin And value for variable \" AtomicDirectoryContents.files \" is \" files/ | repeat=True, random=False \" And put request \" {{ AtomicDirectoryContents.files }} \" with name \" put-file \" to endpoint \" /tmp \" First request will provide file1.bin , second file2.bin etc.","title":"Directory Contents"},{"location":"framework/usage/variables/testdata/directory_contents/#format","text":"Relative path of a directory under requests/ .","title":"Format"},{"location":"framework/usage/variables/testdata/directory_contents/#arguments","text":"repeat bool (optional) - wether values should be reused, e.g. when reaching the end it should start from the beginning again (default: False ) random bool (optional) - if files should be selected by random, instead of sequential from first to last (default: False )","title":"Arguments"},{"location":"framework/usage/variables/testdata/directory_contents/#example","text":"With the following directory structure: . \u2514\u2500\u2500 requests \u2514\u2500\u2500 files \u251c\u2500\u2500 file1.bin \u251c\u2500\u2500 file2.bin \u251c\u2500\u2500 file3.bin \u251c\u2500\u2500 file4.bin \u2514\u2500\u2500 file5.bin And value for variable \" AtomicDirectoryContents.files \" is \" files/ | repeat=True, random=False \" And put request \" {{ AtomicDirectoryContents.files }} \" with name \" put-file \" to endpoint \" /tmp \" First request will provide file1.bin , second file2.bin etc.","title":"Example"},{"location":"framework/usage/variables/testdata/integer_incrementer/","text":"This variable provides an unique integer each time it is accessed. Useful to generate unique ID for each request. Format The first value of an integer that is going to be used. Arguments step int , (optional) - how much the value should increment each time (default 1 ) persist bool , (optional) - if the initial value should be persist and loaded from file (default False ) Example example.feature And value for variable \" AtomicIntegerIncrementer.unique_id \" is \" 100 | step=10 \" And value for variable \" AtomicIntegerIncrementer.persistent \" is \" 10 | step=5, persist=True \" This can then be used in a template: { \"id\" : {{ A t omicI nte gerI n creme nter .u n ique_id }} } Values of AtomicIntegerIncrementer.unique_id , per run and iteration: Run 100 110 120 ... Run 100 110 120 ... Values of AtomicIntegerIncrementer.persistent , per run and iteration: Run ( features/persistent/example.json missing) 5 15 20 ... Run ( features/persistent/example.json created by Run 1, due to persistent=True ), initial value 35 | step=5, persist=True will be read from the file and override what is written in example.feature 25 30 35 ...","title":"Integer Incrementer"},{"location":"framework/usage/variables/testdata/integer_incrementer/#format","text":"The first value of an integer that is going to be used.","title":"Format"},{"location":"framework/usage/variables/testdata/integer_incrementer/#arguments","text":"step int , (optional) - how much the value should increment each time (default 1 ) persist bool , (optional) - if the initial value should be persist and loaded from file (default False )","title":"Arguments"},{"location":"framework/usage/variables/testdata/integer_incrementer/#example","text":"example.feature And value for variable \" AtomicIntegerIncrementer.unique_id \" is \" 100 | step=10 \" And value for variable \" AtomicIntegerIncrementer.persistent \" is \" 10 | step=5, persist=True \" This can then be used in a template: { \"id\" : {{ A t omicI nte gerI n creme nter .u n ique_id }} } Values of AtomicIntegerIncrementer.unique_id , per run and iteration: Run 100 110 120 ... Run 100 110 120 ... Values of AtomicIntegerIncrementer.persistent , per run and iteration: Run ( features/persistent/example.json missing) 5 15 20 ... Run ( features/persistent/example.json created by Run 1, due to persistent=True ), initial value 35 | step=5, persist=True will be read from the file and override what is written in example.feature 25 30 35 ...","title":"Example"},{"location":"framework/usage/variables/testdata/random_integer/","text":"This variable provides an random integer between specified interval. Format Interval from which the integer should be generated from, in the format <min>..<max> . Arguments This variable does not have any arguments. Example And value for variable \" AtomicRandomInteger.weight \" is \" 10..30 \" This can then be used in a template: { \"weight_tons\" : {{ A t omicRa n domI nte ger.weigh t }} } AtomicRandomInteger.weight will then be anything between, and including, 10 and 30 .","title":"Random Integer"},{"location":"framework/usage/variables/testdata/random_integer/#format","text":"Interval from which the integer should be generated from, in the format <min>..<max> .","title":"Format"},{"location":"framework/usage/variables/testdata/random_integer/#arguments","text":"This variable does not have any arguments.","title":"Arguments"},{"location":"framework/usage/variables/testdata/random_integer/#example","text":"And value for variable \" AtomicRandomInteger.weight \" is \" 10..30 \" This can then be used in a template: { \"weight_tons\" : {{ A t omicRa n domI nte ger.weigh t }} } AtomicRandomInteger.weight will then be anything between, and including, 10 and 30 .","title":"Example"},{"location":"framework/usage/variables/testdata/random_string/","text":"This variable generates a specified number of unique strings, based on a string format pattern. The list is pre-populated to ensure that each string is unique. Format Initial value is a string pattern specified with %s and %d , or %g . %s represents one ASCII letter %d represents one digit between 0 and 9 %g represents one complete UUID, cannot be combined with other string patterns Parts of the string can be static, e.g. not random. Arguments count int (optional) - number of unique strings to generate (default: 1 ) upper bool (optional) - if the strings should be in upper case (default: False ) Example And value for variable \" AtomicRandomString.registration_plate_number \" is \" %s%sZ%d%d0 | upper=True, count=100 \" And value for variable \" AtomicRandomString.uuid \" is \" %g | count=100 \" This can then be used in a template: { \"registration_plate_number\" : \"{{ AtomicRandomString.registration_plate_number }}\" } AtomicRandomString.registration_plate_number will then be a string in the format [A-Z][A-Z]Z[0-9][0-9]0 and there will be 100 unique values for disposal.","title":"Random String"},{"location":"framework/usage/variables/testdata/random_string/#format","text":"Initial value is a string pattern specified with %s and %d , or %g . %s represents one ASCII letter %d represents one digit between 0 and 9 %g represents one complete UUID, cannot be combined with other string patterns Parts of the string can be static, e.g. not random.","title":"Format"},{"location":"framework/usage/variables/testdata/random_string/#arguments","text":"count int (optional) - number of unique strings to generate (default: 1 ) upper bool (optional) - if the strings should be in upper case (default: False )","title":"Arguments"},{"location":"framework/usage/variables/testdata/random_string/#example","text":"And value for variable \" AtomicRandomString.registration_plate_number \" is \" %s%sZ%d%d0 | upper=True, count=100 \" And value for variable \" AtomicRandomString.uuid \" is \" %g | count=100 \" This can then be used in a template: { \"registration_plate_number\" : \"{{ AtomicRandomString.registration_plate_number }}\" } AtomicRandomString.registration_plate_number will then be a string in the format [A-Z][A-Z]Z[0-9][0-9]0 and there will be 100 unique values for disposal.","title":"Example"},{"location":"framework/usage/variables/testdata/servicebus/","text":"Listens for messages on Azure Service Bus queue or topic. Use Transformer task to extract specific parts of the message. Format Initial value for a variable must have the prefix queue: or topic: followed by the name of the targeted type. When receiving messages from a topic, the argument subscription: is mandatory. The format of endpoint is: Where <expression> can be a XPath or jsonpath expression, depending on the specified content type. This argument is only allowed when receiving messages. See example below. Attention Do not use expression to filter messages unless you do not care about the messages that does not match the expression. If you do care about them, you should setup a subscription to do the filtering in Azure. Arguments support Templating for their value, but not the complete endpoint value. [queue|topic]:<endpoint name>[, subscription:<subscription name>][, expression:<expression>] Examples : queue:test-queue topic:test-topic, subscription:test-subscription queue:\"$conf::sb.endpoint.queue$\" topic:\"$conf::sb.endpoint.topic$\", subscription:\"$conf::sb.endpoint.subscription$\" queue:\"{{ queue_name }}\", expression=\"$.document[?(@.name=='TPM report')]\" ## Arguments repeat bool (optional) - if True , values read from the endpoint will be saved in a list and re-used if there are no new messages available url str - see format of url below. wait int - number of seconds to wait for a message on the queue content_type str (optional) - specify the MIME type of the message received on the queue, only mandatory when expression is specified in endpoint ### URL format [Endpoint=]sb://<hostname>/;SharedAccessKeyName=<shared key name>;SharedAccessKey=<shared key> The complete url has Templating support, but not parts of it. # valid $conf::sb.url # not valid Endpoint=sb://$conf::sb.hostname/;SharedAccessKeyName=$conf::sb.keyname;SharedAccessKey=$conf::sb.key$ ## Example And value for variable \" AtomicServiceBus.document_id \" is \" queue:documents-in | wait=120, url=$conf::sb.endpoint$, repeat=True \" ... Given a user of type \" RestApi \" load testing \" http://example.com \" ... Then get request \" fetch-document \" from \" /api/v1/document/{{ AtomicServiceBus.document_id }} \" When the scenario starts grizzly will wait up to 120 seconds until AtomicServiceBus.document_id has been populated from a message on the queue documents-in . If there are no messages within 120 seconds, and it is the first iteration of the scenario, it will fail. If there has been at least one message on the queue since the scenario started, it will use the oldest of those values, and then add it back in the end of the list again. ### Get message with expression When specifying an expression, the messages on the endpoint is first peeked on. If any message matches the expression, it is later consumed from the endpoint. If no matching messages was found when peeking, it is repeated again up until the specified wait seconds has elapsed. To use expression, a content type must be specified for the endpint, e.g. application/xml . And value for variable \" AtomicServiceBus.tpm_document \" is \" queue:documents-in | wait=120, url=$conf::sb.endpoint$, repeat=True, content_type=json, expression='$.document[?(@.name=='TPM Report')' \"","title":"Servicebus"},{"location":"framework/usage/variables/testdata/servicebus/#format","text":"Initial value for a variable must have the prefix queue: or topic: followed by the name of the targeted type. When receiving messages from a topic, the argument subscription: is mandatory. The format of endpoint is: Where <expression> can be a XPath or jsonpath expression, depending on the specified content type. This argument is only allowed when receiving messages. See example below. Attention Do not use expression to filter messages unless you do not care about the messages that does not match the expression. If you do care about them, you should setup a subscription to do the filtering in Azure. Arguments support Templating for their value, but not the complete endpoint value. [queue|topic]:<endpoint name>[, subscription:<subscription name>][, expression:<expression>] Examples : queue:test-queue topic:test-topic, subscription:test-subscription queue:\"$conf::sb.endpoint.queue$\" topic:\"$conf::sb.endpoint.topic$\", subscription:\"$conf::sb.endpoint.subscription$\" queue:\"{{ queue_name }}\", expression=\"$.document[?(@.name=='TPM report')]\" ## Arguments repeat bool (optional) - if True , values read from the endpoint will be saved in a list and re-used if there are no new messages available url str - see format of url below. wait int - number of seconds to wait for a message on the queue content_type str (optional) - specify the MIME type of the message received on the queue, only mandatory when expression is specified in endpoint ### URL format [Endpoint=]sb://<hostname>/;SharedAccessKeyName=<shared key name>;SharedAccessKey=<shared key> The complete url has Templating support, but not parts of it. # valid $conf::sb.url # not valid Endpoint=sb://$conf::sb.hostname/;SharedAccessKeyName=$conf::sb.keyname;SharedAccessKey=$conf::sb.key$ ## Example And value for variable \" AtomicServiceBus.document_id \" is \" queue:documents-in | wait=120, url=$conf::sb.endpoint$, repeat=True \" ... Given a user of type \" RestApi \" load testing \" http://example.com \" ... Then get request \" fetch-document \" from \" /api/v1/document/{{ AtomicServiceBus.document_id }} \" When the scenario starts grizzly will wait up to 120 seconds until AtomicServiceBus.document_id has been populated from a message on the queue documents-in . If there are no messages within 120 seconds, and it is the first iteration of the scenario, it will fail. If there has been at least one message on the queue since the scenario started, it will use the oldest of those values, and then add it back in the end of the list again. ### Get message with expression When specifying an expression, the messages on the endpoint is first peeked on. If any message matches the expression, it is later consumed from the endpoint. If no matching messages was found when peeking, it is repeated again up until the specified wait seconds has elapsed. To use expression, a content type must be specified for the endpint, e.g. application/xml . And value for variable \" AtomicServiceBus.tpm_document \" is \" queue:documents-in | wait=120, url=$conf::sb.endpoint$, repeat=True, content_type=json, expression='$.document[?(@.name=='TPM Report')' \"","title":"Format"}]}